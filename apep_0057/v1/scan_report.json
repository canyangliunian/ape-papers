{
  "paper_id": "apep_0057",
  "scan_date": "2026-02-06T12:37:48.652389+00:00",
  "scan_version": "2.0.0",
  "model": "openai/gpt-5.2",
  "overall_verdict": "SUSPICIOUS",
  "files_scanned": 7,
  "flags": [
    {
      "category": "HARD_CODED_RESULTS",
      "severity": "HIGH",
      "file": "06_figures_nosf.R",
      "lines": [
        209,
        217
      ],
      "evidence": "Figure 8's coefficient plot is built from manually entered point estimates/SEs/significance flags rather than being extracted from model objects produced in the analysis script. This creates a direct integrity risk: the plotted (and potentially paper-reported) coefficients can diverge from the actual regression output without detection.: coef_data <- data.frame(\n  model = c(\"Bivariate\", \"+ Controls\", \"+ Network\\nControls\", \"State FE\", \"Clustered SE\"),\n  estimate = c(0.283, 0.270, 0.258, 0.139, 0.139),\n  se = c(0.025, 0.025, 0.026, 0.030, 0.100),\n  significant = c(TRUE, TRUE, TRUE, TRUE, FALSE)\n)",
      "confidence": 0.9
    },
    {
      "category": "HARD_CODED_RESULTS",
      "severity": "MEDIUM",
      "file": "06_figures_nosf.R",
      "lines": [
        209,
        244
      ],
      "evidence": "Statistical significance (p<0.05) is hard-coded rather than computed from the regression results. Even if estimates/SEs were correct, the significance indicator could be incorrect (e.g., due to different df/cluster methods).: significant = c(TRUE, TRUE, TRUE, TRUE, FALSE)\n...\nscale_color_manual(values = c(\"TRUE\" = \"#2E86AB\", \"FALSE\" = \"#E94F37\"),\n                     labels = c(\"TRUE\" = \"p < 0.05\", \"FALSE\" = \"p \u2265 0.05\"),\n                     name = \"Significance\")",
      "confidence": 0.85
    },
    {
      "category": "DATA_PROVENANCE_MISSING",
      "severity": "HIGH",
      "file": "05_main_analysis.R",
      "lines": [
        9,
        25,
        33
      ],
      "evidence": "Key input data (the Meta/Facebook SCI TSV) is read from a local project path with no code to download/fetch it, no checksum, and no documentation of how it was obtained/licensed. Reproduction and provenance auditing therefore depend on an external manual step. The manuscript describes SCI as an external dataset, but the repository lacks a data acquisition script for it.: setwd(\"/Users/dyanag/auto-policy-evals\")\n...\nsci_raw <- fread(\n  \"output/paper_73/data/gadm1_nuts3_counties-gadm1_nuts3_counties - FB Social Connectedness Index - October 2021.tsv\",\n  sep = \"\\t\",\n  header = TRUE\n)",
      "confidence": 0.8
    },
    {
      "category": "DATA_PROVENANCE_MISSING",
      "severity": "MEDIUM",
      "file": "01_process_sci.R",
      "lines": [
        9,
        13,
        16
      ],
      "evidence": "Same provenance issue as in the main analysis: the raw SCI file is assumed to exist locally. This is not inherently misconduct, but it is a reproducibility and integrity weakness (no automated retrieval, version pinning, or validation that the file matches the stated 'October 2021' release).: setwd(\"/Users/dyanag/auto-policy-evals\")\n...\nsci_raw <- fread(\n  \"output/paper_73/data/gadm1_nuts3_counties-gadm1_nuts3_counties - FB Social Connectedness Index - October 2021.tsv\",\n  sep = \"\\t\",\n  header = TRUE\n)",
      "confidence": 0.8
    },
    {
      "category": "METHODOLOGY_MISMATCH",
      "severity": "MEDIUM",
      "file": "05_main_analysis.R",
      "lines": [
        191,
        270
      ],
      "evidence": "The manuscript reports a robustness table with additional specifications (population-weighted regression, trimming outliers at 1%/99%, and log exposure). Those specific robustness specifications are not implemented in the provided main analysis code (no weighting by population, no trimming step, no log exposure regression). Without code producing those results, the reported robustness table cannot be verified against computation.: # Model 4: State fixed effects\nmodel4 <- feols(unemp_shock ~ network_exposure_std + log_pop_std + college_share |\n                  state_fips, data = analysis)\n...\n# We partially address this with state FE and leave-out-state exposure\n# Additional robustness: within-state variation only\n...\nmodel_within <- feols(unemp_shock ~ network_exposure_std + log_pop_std + college_share |\n                        state_fips, data = analysis, cluster = ~state_fips)",
      "confidence": 0.75
    },
    {
      "category": "SELECTIVE_REPORTING",
      "severity": "MEDIUM",
      "file": "05_main_analysis.R",
      "lines": [
        178,
        275
      ],
      "evidence": "Multiple models are estimated, but there is no table-generation code that programmatically exports the exact coefficients/SEs used in paper.tex. Combined with the hard-coded coefficient plot in 06_figures_nosf.R, this creates a reporting pipeline where results can be selectively transcribed rather than automatically linked to model outputs.: model1 <- feols(unemp_shock ~ network_exposure_std, data = analysis)\n...\nmodel4 <- feols(unemp_shock ~ network_exposure_std + log_pop_std + college_share |\n                  state_fips, data = analysis)\n...\nmodel_within <- feols(unemp_shock ~ network_exposure_std + log_pop_std + college_share |\n                        state_fips, data = analysis, cluster = ~state_fips)",
      "confidence": 0.7
    }
  ],
  "file_verdicts": [
    {
      "file": "06_figures.R",
      "verdict": "CLEAN"
    },
    {
      "file": "06_figures_nosf.R",
      "verdict": "SUSPICIOUS"
    },
    {
      "file": "01_process_sci.R",
      "verdict": "CLEAN"
    },
    {
      "file": "05_main_analysis.R",
      "verdict": "SUSPICIOUS"
    },
    {
      "file": "04_shift_share_exploration.R",
      "verdict": "CLEAN"
    },
    {
      "file": "03_economic_correlations.R",
      "verdict": "CLEAN"
    },
    {
      "file": "02_explore_patterns.R",
      "verdict": "CLEAN"
    }
  ],
  "summary": {
    "verdict": "SUSPICIOUS",
    "counts": {
      "CRITICAL": 0,
      "HIGH": 2,
      "MEDIUM": 4,
      "LOW": 0
    },
    "one_liner": "hard-coded results; unclear provenance",
    "executive_summary": "The Figure 8 coefficient plot in `06_figures_nosf.R` is generated from manually typed point estimates, standard errors, and significance markers rather than being pulled from the fitted model objects used in the main analysis, making the plotted results easy to alter and not verifiably linked to the computations. In `05_main_analysis.R`, a key Meta/Facebook SCI TSV dataset is loaded from a local path with no code to obtain it, no checksum/version pinning, and no provenance or licensing documentation, preventing independent reproduction and validation of the results.",
    "top_issues": [
      {
        "category": "HARD_CODED_RESULTS",
        "severity": "HIGH",
        "short": "Figure 8's coefficient plot is built from manually entere...",
        "file": "06_figures_nosf.R",
        "lines": [
          209,
          217
        ],
        "github_url": "/apep_0057/code/06_figures_nosf.R#L209-L217"
      },
      {
        "category": "DATA_PROVENANCE_MISSING",
        "severity": "HIGH",
        "short": "Key input data (the Meta/Facebook SCI TSV) is read from a...",
        "file": "05_main_analysis.R",
        "lines": [
          9,
          25
        ],
        "github_url": "/apep_0057/code/05_main_analysis.R#L9-L33"
      }
    ],
    "full_report_url": "/tournament/corpus_scanner/scans/apep_0057_scan.json"
  },
  "error": null
}