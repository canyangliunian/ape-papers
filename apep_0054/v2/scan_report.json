{
  "paper_id": "apep_0146",
  "scan_date": "2026-02-06T12:51:42.935285+00:00",
  "scan_version": "2.0.0",
  "model": "openai/gpt-5.2",
  "overall_verdict": "CLEAN",
  "files_scanned": 9,
  "flags": [
    {
      "category": "METHODOLOGY_MISMATCH",
      "severity": "MEDIUM",
      "file": "01_fetch_data.R",
      "lines": [
        14,
        22
      ],
      "evidence": "The manuscript states: \u201cI use CPS ASEC surveys from 2016 through 2025, corresponding to income years 2015 through 2024.\u201d The code defines an IPUMS extract for CPS ASEC 2015\u20132024 (March supplements), which corresponds to income years 2014\u20132023 (consistent with df_raw[, income_year := YEAR - 1]). This is a sample window mismatch between paper and code that can change pre/post exposure and the set of post-treatment years available (notably for 2024 income year).: extract <- define_extract_cps(\n  description = \"Salary Transparency Laws - CPS ASEC 2015-2024\",\n  samples = paste0(\"cps\", 2015:2024, \"_03s\"),  # March ASEC supplements\n  variables = c(",
      "confidence": 0.85
    },
    {
      "category": "METHODOLOGY_MISMATCH",
      "severity": "MEDIUM",
      "file": "02_clean_data.R",
      "lines": [
        16,
        44
      ],
      "evidence": "The manuscript claims: \u201cI exclude observations with imputed wage data to ensure measurement quality.\u201d In the IPUMS extract and cleaning code shown, no imputation flags (e.g., CPS allocation flags for INCWAGE/UHRS/WKSWORK) are requested or filtered on, so imputed wage observations are not excluded as described.: df_raw <- readRDS(\"data/cps_asec_raw.rds\")\n...\ndf <- df_raw %>%\n  # 1. Working-age adults (25-64)\n  filter(AGE >= 25, AGE <= 64) %>%\n...\n  # 3. Positive wage income\n  filter(INCWAGE > 0, INCWAGE < 9999999) %>%\n...\n  # 5. Worked at least 13 weeks last year (quarterly)\n  filter(WKSWORK1 >= 13 | WKSWORK2 >= 2)",
      "confidence": 0.8
    },
    {
      "category": "DATA_PROVENANCE_MISSING",
      "severity": "MEDIUM",
      "file": "01_fetch_data.R",
      "lines": [
        117,
        155
      ],
      "evidence": "The manuscript states: \u201cI also incorporate state minimum wage data from the Department of Labor to control for concurrent policy changes.\u201d The repository code does not fetch minimum wage series from DOL (or Berkeley Labor Center), nor does it construct a state-year minimum wage panel here; it instead creates only a state FIPS\u2194abbr lookup and explicitly defers/minimizes controls (\u201csimplified approach with known minimum wages\u201d; unemployment rates not fetched). If minimum wage controls are part of identification/robustness claims, their provenance and implementation are currently missing in the provided code files.: # ---- State Minimum Wages ----\n# Source: DOL / UC Berkeley Labor Center\n# We'll use a simplified approach with known minimum wages\n\nstate_min_wage <- tibble(\n  statefip = 1:56,\n  state_abbr = c(\"AL\", \"AK\", \"AZ\", \"AR\", \"CA\", \"CO\", \"CT\", \"DE\", \"DC\", \"FL\",\n                 ...,\n                 \"WY\", NA, NA, NA, NA, NA)\n) %>%\n  filter(!is.na(state_abbr))\n\n# For now, we'll construct minimum wage data in the cleaning script\n# using known values for the analysis period\n\n# ---- State Unemployment Rates ----\n# Would fetch from BLS LAUS API\n# For now, we'll use state-year fixed effects which absorb this",
      "confidence": 0.8
    },
    {
      "category": "HARD_CODED_RESULTS",
      "severity": "MEDIUM",
      "file": "paper.tex",
      "lines": [],
      "evidence": "Key regression results (coefficients/SEs/stars) are directly embedded as literals in LaTeX tables in the manuscript rather than being included via \\input{} of code-generated tables. The codebase does generate LaTeX tables (e.g., tables/table2_main_results.tex), but paper.tex includes manually-typed numeric results, which creates an integrity risk of divergence between computed outputs and reported values unless the paper explicitly sources these tables from the generated files.: \\begin{table}[H]\n\\centering\n\\caption{Effect of Salary Transparency Laws on Log Wages}\n...\nTreated $\\times$ Post & -0.012** & -0.014** & -0.016*** & -0.018*** \\\\\n& (0.004) & (0.005) & (0.005) & (0.005) \\\\\n...",
      "confidence": 0.65
    },
    {
      "category": "SUSPICIOUS_TRANSFORMS",
      "severity": "LOW",
      "file": "05_robustness.R",
      "lines": [
        86,
        132
      ],
      "evidence": "The \u201ctreated_states\u201d list used to construct the \u201cexcluding border states\u201d robustness restriction includes many states that are not treated in the treatment file (e.g., 17=IL, 24=MD, 25=MA, 27=MN, 50=VT based on the provided transparency_laws). This can cause an ad hoc/non-reproducible control-group restriction and may unintentionally drop many controls (or the wrong controls). While labeled as \u201csimplified,\u201d it can meaningfully move robustness estimates and should be programmatically derived from transparency_laws (first_treat>0) rather than hard-coded.: # States bordering treated states may have spillovers\n# Define border states (states that border any treated state)\ntreated_states <- c(6, 8, 9, 15, 17, 24, 25, 27, 32, 34, 36, 44, 50, 53)\n...\n# Exclude border states\nstate_year_noborder <- state_year %>%\n  filter(!(statefip %in% border_states & g == 0))",
      "confidence": 0.75
    }
  ],
  "file_verdicts": [
    {
      "file": "01_fetch_data.R",
      "verdict": "CLEAN"
    },
    {
      "file": "07_tables.R",
      "verdict": "CLEAN"
    },
    {
      "file": "00_packages.R",
      "verdict": "CLEAN"
    },
    {
      "file": "06_figures.R",
      "verdict": "CLEAN"
    },
    {
      "file": "00_policy_data.R",
      "verdict": "CLEAN"
    },
    {
      "file": "02_clean_data.R",
      "verdict": "CLEAN"
    },
    {
      "file": "05_robustness.R",
      "verdict": "CLEAN"
    },
    {
      "file": "04_main_analysis.R",
      "verdict": "CLEAN"
    },
    {
      "file": "03_descriptives.R",
      "verdict": "CLEAN"
    }
  ],
  "summary": {
    "verdict": "CLEAN",
    "counts": {
      "CRITICAL": 0,
      "HIGH": 0,
      "MEDIUM": 4,
      "LOW": 1
    },
    "one_liner": "Minor issues only",
    "executive_summary": "Minor code quality issues detected, but no evidence of data fabrication or manipulation.",
    "top_issues": [],
    "full_report_url": "/tournament/corpus_scanner/scans/apep_0146_scan.json"
  },
  "error": null
}