{
  "paper_id": "apep_0119",
  "scan_date": "2026-02-06T12:46:36.500448+00:00",
  "scan_version": "2.0.0",
  "model": "openai/gpt-5.2",
  "overall_verdict": "CLEAN",
  "files_scanned": 7,
  "flags": [
    {
      "category": "HARD_CODED_RESULTS",
      "severity": "LOW",
      "file": "01_fetch_data.R",
      "lines": [
        18,
        78
      ],
      "evidence": "EERS adoption years and never-treated status are hard-coded in the script rather than being programmatically fetched from ACEEE/DSIRE/NCSL. This is not inherently inappropriate (treatment coding is often hand-curated), and the manuscript explicitly discloses these sources, but it creates a manual step that should be documented with a reproducible provenance trail (e.g., a CSV with citations/URLs per state-year, or a separate appendix file listing statute/PUC order references).: eers_treatment <- tribble(\n  ~state_abbr, ~state_name,           ~eers_year, ~eers_type,\n  \"AZ\",        \"Arizona\",              2010,       \"mandatory\",\n  ...\n  \"WI\",        \"Wisconsin\",           2005,       \"mandatory\"\n)\n\n# Never-treated states\nnever_treated <- tribble(\n  ~state_abbr, ~state_name,\n  \"AL\",        \"Alabama\",\n  ...\n  \"WY\",        \"Wyoming\"\n)\nnever_treated$eers_year <- 0L",
      "confidence": 0.78
    },
    {
      "category": "DATA_PROVENANCE_MISSING",
      "severity": "LOW",
      "file": "01_fetch_data.R",
      "lines": [
        250,
        314
      ],
      "evidence": "1990 state populations are embedded as literals (claimed to be official decennial counts). The manuscript explains why (1990 API not reliably served) and the interpolation method is transparently coded, which reduces severity. For full auditability, the project should cite the exact Census table/release and ideally store the 1990 counts as an external input file with a citation (or add code that fetches from an archived Census source).: census_1990 <- tribble(\n  ~state_fips, ~pop_1990,\n  \"01\", 4040587,   # Alabama\n  \"02\",  550043,   # Alaska\n  ...\n  \"56\",  453588    # Wyoming\n)\n...\n# Interpolate 1990-1999 using linear interpolation between 1990 and 2000 Census\npop_1990s_interp <- census_1990 %>%\n  left_join(pop_2000_base, by = \"state_fips\") %>%\n  ...\n  mutate(\n    population = as.numeric(round(pop_1990 + (pop_2000 - pop_1990) * (year - 1990) / 10))\n  )",
      "confidence": 0.74
    },
    {
      "category": "SUSPICIOUS_TRANSFORMS",
      "severity": "LOW",
      "file": "04_robustness.R",
      "lines": [
        38,
        47
      ],
      "evidence": "The robustness script drops observations with ind_elec_pc <= 0 before logging, which is standard for log transforms but can change the sample relative to the main outcome if zeros/negatives exist (they should not for these aggregates). Given the paper asserts a balanced panel with no missing values, this filter likely has no effect; still, it would be cleaner to assert/verify there are no nonpositive industrial values (stopifnot) rather than silently filtering.: placebo_data <- panel %>%\n  filter(!is.na(ind_elec_pc), ind_elec_pc > 0) %>%\n  mutate(\n    log_ind_elec_pc = log(ind_elec_pc),\n    first_treat = ifelse(eers_year == 0, 0L, as.integer(eers_year))\n  )",
      "confidence": 0.62
    },
    {
      "category": "SELECTIVE_REPORTING",
      "severity": "LOW",
      "file": "06_tables.R",
      "lines": [
        142,
        155
      ],
      "evidence": "The LaTeX table construction iterates over specifications and prints an 'EERS' row block each time without labeling which column/spec the estimate belongs to. Depending on how LaTeX renders this, it can produce repeated rows rather than a single row with five columns, which risks accidental misreporting/misalignment of results in the manuscript tables (even if underlying estimates are computed correctly). This is more of a reporting/format integrity risk than p-hacking, but it warrants checking the compiled PDF table.: for (i in 1:nrow(results_data)) {\n  if (!is.na(results_data$att[i])) {\n    tab2_tex <- paste0(tab2_tex,\n      \"EERS & \", results_data$att_str[i], \" \\\\\\\\\\n\",\n      \" & \", results_data$se_str[i], \" \\\\\\\\\\n\",\n      \" & \", results_data$ci_str[i], \" \\\\\\\\\\n\")\n  }\n}",
      "confidence": 0.7
    }
  ],
  "file_verdicts": [
    {
      "file": "01_fetch_data.R",
      "verdict": "CLEAN"
    },
    {
      "file": "06_tables.R",
      "verdict": "CLEAN"
    },
    {
      "file": "00_packages.R",
      "verdict": "CLEAN"
    },
    {
      "file": "04_robustness.R",
      "verdict": "CLEAN"
    },
    {
      "file": "02_clean_data.R",
      "verdict": "CLEAN"
    },
    {
      "file": "03_main_analysis.R",
      "verdict": "CLEAN"
    },
    {
      "file": "05_figures.R",
      "verdict": "CLEAN"
    }
  ],
  "summary": {
    "verdict": "CLEAN",
    "counts": {
      "CRITICAL": 0,
      "HIGH": 0,
      "MEDIUM": 0,
      "LOW": 4
    },
    "one_liner": "Minor issues only",
    "executive_summary": "Minor code quality issues detected, but no evidence of data fabrication or manipulation.",
    "top_issues": [],
    "full_report_url": "/tournament/corpus_scanner/scans/apep_0119_scan.json"
  },
  "error": null
}