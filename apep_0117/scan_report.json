{
  "paper_id": "apep_0117",
  "scan_date": "2026-02-06T12:45:59.792213+00:00",
  "scan_version": "2.0.0",
  "model": "openai/gpt-5.2",
  "overall_verdict": "SUSPICIOUS",
  "files_scanned": 7,
  "flags": [
    {
      "category": "METHODOLOGY_MISMATCH",
      "severity": "HIGH",
      "file": "03_main_analysis.R",
      "lines": [
        63,
        65,
        74,
        76,
        82,
        83,
        86,
        90
      ],
      "evidence": "The manuscript defines Pre-ACA as 2012 only and Post-ACA as 2017\u20132022, explicitly excluding 2014 as a transition year. The analysis code instead defines Pre-ACA as (2012, 2014) and Post-ACA as (2017, 2019, 2022), which directly contradicts the paper\u2019s pre/post design and changes the estimand. This affects Table 2/3-style comparisons and the triple-difference narrative.: # Pre-ACA (2012, 2014)\ndf_pre <- df_main %>% filter(YEAR %in% c(2012, 2014))\n# Post-ACA (2017, 2019, 2022)\ndf_post <- df_main %>% filter(YEAR %in% c(2017, 2019, 2022))\n...\ndd_se <- sqrt(coef_pre[\"Std. Error\"]^2 + coef_post[\"Std. Error\"]^2)\n...\ndf_placebo_pre <- df_placebo %>% filter(YEAR %in% c(2012, 2014))\ndf_placebo_post <- df_placebo %>% filter(YEAR %in% c(2017, 2019, 2022))",
      "confidence": 0.95
    },
    {
      "category": "METHODOLOGY_MISMATCH",
      "severity": "HIGH",
      "file": "03_main_analysis.R",
      "lines": [
        31,
        32,
        33,
        34,
        35,
        36,
        37
      ],
      "evidence": "The manuscript claims 'IPW-weighted OLS estimates' and 'Standard errors clustered at the state level'. The code\u2019s main reported period-specific effects used downstream in tables are OLS coefficients from unweighted lm() (coef_pre/coef_post and placebo analogs). The IPW ATT is computed only as a weighted mean difference (no regression adjustment, no clustered SE), and is not used for pre/post or placebo effects saved to main_results.rds. Thus the implemented estimator (unweighted OLS for the key reported pre/post/placebo effects) does not match the paper\u2019s described IPW-weighted regression with clustering.: ols_full <- lm(hours_weekly ~ self_employed + AGEP + female + married + \n                 college + has_disability, data = df_main)\n...\nps_model <- glm(self_employed ~ AGEP + female + married + college + has_disability,\n                data = df_main, family = binomial())\n...\n# IPW estimate (ATT)\nipw_treated <- weighted.mean(...)\nipw_control <- weighted.mean(...)\nipw_att <- ipw_treated - ipw_control",
      "confidence": 0.9
    },
    {
      "category": "METHODOLOGY_MISMATCH",
      "severity": "MEDIUM",
      "file": "03_main_analysis.R",
      "lines": [
        22,
        23,
        24,
        25,
        26
      ],
      "evidence": "The manuscript emphasizes 'doubly robust estimation'. The code conditionally uses AIPW but contains no subsequent AIPW estimation call; the actual computations shown are OLS and a simple IPW mean-difference ATT. If AIPW is intended, the code path is incomplete; if not, the paper overstates the estimator used.: use_aipw <- requireNamespace(\"AIPW\", quietly = TRUE) && \n            requireNamespace(\"SuperLearner\", quietly = TRUE)\n\nif (use_aipw) {\n  library(AIPW)\n  library(SuperLearner)\n  message(\"Using AIPW for doubly robust estimation\")\n} else {\n  message(\"AIPW not available, using OLS + IPW as fallback\")\n}",
      "confidence": 0.85
    },
    {
      "category": "METHODOLOGY_MISMATCH",
      "severity": "MEDIUM",
      "file": "04_robustness.R",
      "lines": [
        33,
        34,
        35,
        36,
        37,
        38,
        39,
        40
      ],
      "evidence": "Event-study/year-by-year estimates are unweighted OLS and use conventional lm() standard errors. The manuscript describes IPW-weighted regressions and clustering by state (and discusses two-way clustering). The figure/table built from robustness$yearly_effects (used in 05_figures.R for fig3_event_study.pdf) therefore does not reflect the paper\u2019s stated weighting/inference approach.: fit = purrr::map(data, ~lm(hours_weekly ~ self_employed + AGEP + female + \n                                 married + college + has_disability, data = .x)),\ncoef = purrr::map(fit, ~{\n  s <- summary(.x)$coefficients[\"self_employedTRUE\", ]\n  tibble(effect = s[\"Estimate\"], se = s[\"Std. Error\"])\n})",
      "confidence": 0.9
    },
    {
      "category": "SUSPICIOUS_TRANSFORMS",
      "severity": "LOW",
      "file": "02_clean_data.R",
      "lines": [
        55,
        56
      ],
      "evidence": "Income is transformed via log(pmax(PINCP, 1)), which replaces zero/negative incomes with 1 before logging. This can change the distribution and potentially attenuate differences if many observations have nonpositive PINCP (which can occur in self-employment). This is not inherently wrong, but it should be explicitly justified and sensitivity-checked (e.g., inverse hyperbolic sine, dropping nonpositive, or adding a constant).: log_income = log(pmax(PINCP, 1)),",
      "confidence": 0.75
    },
    {
      "category": "DATA_FABRICATION",
      "severity": "LOW",
      "file": "01_fetch_data.R",
      "lines": [
        12
      ],
      "evidence": "A random seed is set in the data-fetch script even though the script does not use randomness. This is not evidence of fabrication, but it is unnecessary and can raise audit questions; consider removing or documenting it as a project-wide reproducibility convention.: set.seed(20260130)",
      "confidence": 0.7
    },
    {
      "category": "DATA_FABRICATION",
      "severity": "LOW",
      "file": "00_packages.R",
      "lines": [
        110
      ],
      "evidence": "A global random seed is set. No simulated data generation is present in the provided code, so this is likely harmless; however, if any permutation/random-forest steps exist elsewhere, seeds should be tied to those steps and documented.: set.seed(20260130)",
      "confidence": 0.65
    }
  ],
  "file_verdicts": [
    {
      "file": "01_fetch_data.R",
      "verdict": "CLEAN"
    },
    {
      "file": "06_tables.R",
      "verdict": "CLEAN"
    },
    {
      "file": "00_packages.R",
      "verdict": "CLEAN"
    },
    {
      "file": "04_robustness.R",
      "verdict": "CLEAN"
    },
    {
      "file": "02_clean_data.R",
      "verdict": "CLEAN"
    },
    {
      "file": "03_main_analysis.R",
      "verdict": "SUSPICIOUS"
    },
    {
      "file": "05_figures.R",
      "verdict": "CLEAN"
    }
  ],
  "summary": {
    "verdict": "SUSPICIOUS",
    "counts": {
      "CRITICAL": 0,
      "HIGH": 2,
      "MEDIUM": 2,
      "LOW": 3
    },
    "one_liner": "method mismatch",
    "executive_summary": "The analysis code defines the Pre-ACA period as including both 2012 and 2014, even though the manuscript specifies Pre-ACA as 2012 only and explicitly treats 2014 as a transition year to be excluded; this misclassification can change the estimated pre/post contrast. The manuscript also describes IPW-weighted OLS with state-clustered standard errors, but the period-specific effects propagated into the main tables are based on unweighted OLS coefficients rather than the stated IPW specification and clustering.",
    "top_issues": [
      {
        "category": "METHODOLOGY_MISMATCH",
        "severity": "HIGH",
        "short": "The manuscript defines Pre-ACA as 2012 only and Post-ACA ...",
        "file": "03_main_analysis.R",
        "lines": [
          63,
          65
        ],
        "github_url": "https://github.com/SocialCatalystLab/ape-papers/blob/main/apep_0117/code/03_main_analysis.R#L63-L90"
      },
      {
        "category": "METHODOLOGY_MISMATCH",
        "severity": "HIGH",
        "short": "The manuscript claims 'IPW-weighted OLS estimates' and 'S...",
        "file": "03_main_analysis.R",
        "lines": [
          31,
          32
        ],
        "github_url": "https://github.com/SocialCatalystLab/ape-papers/blob/main/apep_0117/code/03_main_analysis.R#L31-L37"
      }
    ],
    "full_report_url": "https://github.com/SocialCatalystLab/ape-papers/blob/main/tournament/corpus_scanner/scans/apep_0117_scan.json"
  },
  "error": null
}