{
  "paper_id": "apep_0187",
  "scan_date": "2026-02-06T13:00:32.962997+00:00",
  "scan_version": "2.0.0",
  "model": "openai/gpt-5.2",
  "overall_verdict": "SUSPICIOUS",
  "files_scanned": 11,
  "flags": [
    {
      "category": "DATA_PROVENANCE_MISSING",
      "severity": "HIGH",
      "file": "01_fetch_data.R",
      "lines": [
        210,
        330
      ],
      "evidence": "If the Census QWI API returns no data (network errors, invalid query, rate limiting, API schema mismatch), the script silently substitutes an empty tibble as the outcome data source. Downstream scripts then proceed (02_clean_data.R constructs a panel without outcomes), which makes it possible to run later steps without realizing that the main dependent variables (employment/earnings) were never fetched. This is a provenance/integrity risk because a successful end-to-end run does not guarantee that results are based on the intended QWI data.: if (length(qwi_list) > 0) {\n  qwi_raw <- bind_rows(qwi_list)\n  ...\n} else {\n  cat(\"  WARNING: QWI API returned no data. Using fallback approach.\\n\")\n  qwi_raw <- tibble()\n}",
      "confidence": 0.85
    },
    {
      "category": "DATA_PROVENANCE_MISSING",
      "severity": "MEDIUM",
      "file": "01_fetch_data.R",
      "lines": [
        150,
        205
      ],
      "evidence": "The QWI API query encodes multiple industries as a comma-separated list in a single parameter (\"industry=00,44-45,72,52,54\"). Many Census APIs require separate requests or a different syntax for multi-valued parameters. If this syntax is invalid, it will systematically produce NULL results and trigger the empty-data fallback. Because the code does not validate that the intended industries and rows were actually returned (e.g., checking for expected columns/row counts per request), the effective data source for outcomes may be missing without a hard failure.: url <- paste0(\n    qwi_base,\n    \"?get=Emp,EarnS,HirA,Sep,FrmJbC,FrmJbD\",\n    \"&for=county:*\",\n    \"&in=state:\", state_fips,\n    \"&year=\", year,\n    \"&quarter=\", quarter,\n    \"&industry=00,44-45,72,52,54\",\n    \"&ownercode=A05\",\n    \"&agegrp=A00\"\n  )",
      "confidence": 0.7
    },
    {
      "category": "METHODOLOGY_MISMATCH",
      "severity": "HIGH",
      "file": "02_clean_data.R",
      "lines": [
        160,
        260
      ],
      "evidence": "The manuscript defines NetworkMW and GeoMW as SCI-/distance-weighted averages of minimum wages in levels (dollars per hour). The code instead constructs exposures as weighted averages of log(min_wage) and stores them as social_exposure / geo_exposure. This is a substantive methodological mismatch: averaging logs corresponds to a (weighted) geometric mean in levels, not the arithmetic mean described in the paper. It also changes interpretation of coefficients (semi-elasticity vs level effect).: state_mw_panel <- state_mw_panel %>%\n  mutate(log_min_wage = log(min_wage))\n...\n# SocialExposure_{ct} = \u03a3\u2c7c w_{cj} \u00d7 log(MinWage_{jt})\n...\nsummarise(\n  social_exposure = sum(w_sci * log_min_wage, na.rm = TRUE),\n  geo_exposure = sum(w_geo * log_min_wage, na.rm = TRUE),\n  .groups = \"drop\"\n)",
      "confidence": 0.9
    },
    {
      "category": "SUSPICIOUS_TRANSFORMS",
      "severity": "MEDIUM",
      "file": "paper.tex",
      "lines": [
        150,
        190
      ],
      "evidence": "The manuscript reports excluding county-quarter observations where network exposure < $7.00 as an 'anomalous value' filter. This is an outcome-adjacent transformation of a key constructed regressor that could affect results if those observations are systematically different. The justification is plausible, but the codebase provided does not show an implemented filter on social_exposure/NetworkMW corresponding to this rule (02_clean_data.R does not filter out low exposures). This creates an audit gap: the stated sample restriction is not traceable to code, and it is unclear whether reported results reflect the restriction.: After filtering county-quarter observations with anomalous exposure values (network exposure below \\$7.00, which removes observations affected by data construction issues), we retain 3,144 continental U.S. counties...",
      "confidence": 0.75
    },
    {
      "category": "HARD_CODED_RESULTS",
      "severity": "MEDIUM",
      "file": "01_fetch_data.R",
      "lines": [
        80,
        210
      ],
      "evidence": "State minimum wage histories are hard-coded via a manually curated tribble rather than programmatically fetched from a primary source. The manuscript explicitly discloses manual compilation and cites sources, which lowers suspicion, but this remains an integrity risk because (i) coverage appears incomplete (only a subset of states shown with changes), (ii) transcription errors can occur, and (iii) replication depends on this literal list. A stronger approach would include a machine-readable source file with checksums and/or a reconciliation script against DOL/NCSL/VZ data.: state_mw_changes <- tribble(\n  ~state_fips, ~state_abbr, ~date, ~min_wage,\n  # California\n  \"06\", \"CA\", \"2014-07-01\", 9.00,\n  ...\n  # Virginia\n  \"51\", \"VA\", \"2021-05-01\", 9.50,\n  \"51\", \"VA\", \"2022-01-01\", 11.00,\n  \"51\", \"VA\", \"2023-01-01\", 12.00\n)",
      "confidence": 0.8
    },
    {
      "category": "METHODOLOGY_MISMATCH",
      "severity": "MEDIUM",
      "file": "01b_fetch_qcew.R",
      "lines": [
        1,
        200
      ],
      "evidence": "The manuscript emphasizes QWI as the main quarterly employment source. This script constructs a pseudo-quarterly panel by repeating annual QCEW values across quarters (explicitly a proxy). If any main analysis uses this file (or merges it into analysis_panel) without fully accounting for the effective time frequency, it would conflict with the manuscript's claims about quarterly variation and could inflate nominal sample sizes and precision. The script is well-documented about the limitation, but the repo-level risk is that downstream scripts may inadvertently treat these as true quarterly observations unless guarded by checks.: # This script downloads ANNUAL QCEW averages from BLS and creates quarterly\n# observations by replicating each annual value across 4 quarters.\n...\nqcew_quarterly <- qcew_data %>%\n  crossing(quarter = 1:4) %>%\n  mutate(\n    yearq = year + (quarter - 1) / 4,\n    log_emp = log(pmax(emp, 1)),\n    is_annual_interpolation = TRUE\n  )",
      "confidence": 0.65
    },
    {
      "category": "DATA_FABRICATION",
      "severity": "LOW",
      "file": "00_packages.R",
      "lines": [
        45,
        70
      ],
      "evidence": "A global random seed is set at package load. No direct synthetic data generation is present in the provided scripts, but setting a seed globally can mask unintended randomness in downstream steps (e.g., sampling top SCI edges, permutation inference). This is not evidence of fabrication; it is a minor reproducibility note.: # Set seed for reproducibility\nset.seed(42)",
      "confidence": 0.55
    },
    {
      "category": "SELECTIVE_REPORTING",
      "severity": "MEDIUM",
      "file": "01_fetch_data.R",
      "lines": [
        220,
        240
      ],
      "evidence": "The comment claims the code fetches only a 'subset for demonstration,' yet the loops actually iterate over all states in centroids, all years 2012\u20132022, and all four quarters. This inconsistency suggests either (a) the intended production version differs from the provided code, or (b) the authors anticipated partial fetching but left full ranges in place. Either way, it complicates auditing whether the reported sample in the paper corresponds to what the code actually downloaded/used, especially given the silent empty-data fallback.: # Fetch QWI for sample of years (2012-2022) and quarters\n# Note: Full data would take long; fetching subset for demonstration\nyears_to_fetch <- 2012:2022\nquarters <- 1:4",
      "confidence": 0.7
    }
  ],
  "file_verdicts": [
    {
      "file": "01b_fetch_qcew.R",
      "verdict": "CLEAN"
    },
    {
      "file": "01_fetch_data.R",
      "verdict": "SUSPICIOUS"
    },
    {
      "file": "06_tables.R",
      "verdict": "CLEAN"
    },
    {
      "file": "00_packages.R",
      "verdict": "CLEAN"
    },
    {
      "file": "02b_construct_iv.R",
      "verdict": "CLEAN"
    },
    {
      "file": "03c_political_outcomes.R",
      "verdict": "CLEAN"
    },
    {
      "file": "04_robustness.R",
      "verdict": "CLEAN"
    },
    {
      "file": "02_clean_data.R",
      "verdict": "SUSPICIOUS"
    },
    {
      "file": "03b_iv_validation.R",
      "verdict": "CLEAN"
    },
    {
      "file": "03_main_analysis.R",
      "verdict": "CLEAN"
    },
    {
      "file": "05_figures.R",
      "verdict": "CLEAN"
    }
  ],
  "summary": {
    "verdict": "SUSPICIOUS",
    "counts": {
      "CRITICAL": 0,
      "HIGH": 2,
      "MEDIUM": 5,
      "LOW": 1
    },
    "one_liner": "unclear provenance; method mismatch",
    "executive_summary": "The data-fetching script (`01_fetch_data.R`) can fail quietly: when the Census QWI API returns no records (e.g., due to network errors, invalid queries, rate limits, or schema changes), it replaces the outcome data with an empty tibble and continues, risking downstream results being based on missing or incomplete data without any warning. The exposure construction in `02_clean_data.R` does not match the manuscript: NetworkMW and GeoMW are computed as weighted averages of **log(min_wage)** rather than weighted averages of minimum wages in **levels** (dollars per hour), changing the estimand and interpretation of the reported effects.",
    "top_issues": [
      {
        "category": "DATA_PROVENANCE_MISSING",
        "severity": "HIGH",
        "short": "If the Census QWI API returns no data (network errors, in...",
        "file": "01_fetch_data.R",
        "lines": [
          210,
          330
        ],
        "github_url": "https://github.com/SocialCatalystLab/ape-papers/blob/main/apep_0187/code/01_fetch_data.R#L210-L330"
      },
      {
        "category": "METHODOLOGY_MISMATCH",
        "severity": "HIGH",
        "short": "The manuscript defines NetworkMW and GeoMW as SCI-/distan...",
        "file": "02_clean_data.R",
        "lines": [
          160,
          260
        ],
        "github_url": "https://github.com/SocialCatalystLab/ape-papers/blob/main/apep_0187/code/02_clean_data.R#L160-L260"
      }
    ],
    "full_report_url": "https://github.com/SocialCatalystLab/ape-papers/blob/main/tournament/corpus_scanner/scans/apep_0187_scan.json"
  },
  "error": null
}