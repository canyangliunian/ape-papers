{
  "paper_id": "apep_0082",
  "scan_date": "2026-02-06T12:43:03.530080+00:00",
  "scan_version": "2.0.0",
  "model": "openai/gpt-5.2",
  "overall_verdict": "SUSPICIOUS",
  "files_scanned": 7,
  "flags": [
    {
      "category": "METHODOLOGY_MISMATCH",
      "severity": "HIGH",
      "file": "03_main_analysis.R",
      "lines": [
        35,
        46,
        55,
        61,
        68
      ],
      "evidence": "The manuscript repeatedly states that Callaway-Sant'Anna (CS) standard errors are computed via a bootstrap with 999 replications (e.g., abstract; Table 4 notes). However, the CS estimation calls (att_gt / aggte) do not specify bootstrap options (e.g., bstrap=TRUE and biters=999 in the did package). Without those arguments, did::att_gt typically uses its default inference (influence-function / asymptotic) rather than a 999-replication bootstrap. If the defaults are not bootstrap-based, then the reported SEs/CIs described as bootstrapped are not generated as claimed.: cs_main <- att_gt(\n  yname = \"log_apps_pc\",\n  tname = \"year\",\n  idname = \"state_id\",\n  gname = \"first_treat\",\n  data = state_year,\n  control_group = \"nevertreated\",\n  est_method = \"dr\",\n  base_period = \"universal\"\n)\n\n# Aggregate to overall ATT\ncs_agg <- aggte(cs_main, type = \"simple\")",
      "confidence": 0.86
    },
    {
      "category": "METHODOLOGY_MISMATCH",
      "severity": "HIGH",
      "file": "04_robustness.R",
      "lines": [
        18,
        31,
        49,
        86,
        111,
        168,
        192,
        233,
        274
      ],
      "evidence": "Same issue as the main CS specification: none of the robustness CS estimators specify bootstrap inference controls, yet the manuscript describes CS results as using bootstrapped standard errors with 999 replications. If did's defaults are not bootstrapping, then the robustness SEs/CIs are also not produced by the claimed procedure.: cs_hba <- att_gt(\n  yname = \"log_apps_pc\",\n  tname = \"year\",\n  idname = \"state_id\",\n  gname = \"first_treat\",\n  data = state_year_hba,\n  control_group = \"nevertreated\",\n  est_method = \"dr\",\n  base_period = \"universal\"\n)\ncs_hba_agg <- aggte(cs_hba, type = \"simple\")\n...\ncs_medical <- att_gt(...)\n...\ncs_nocovid <- att_gt(...)\n...\ncs_interior <- tryCatch({\n  att_gt(... ) %>% aggte(type = \"simple\")\n}, ...)",
      "confidence": 0.84
    },
    {
      "category": "DATA_PROVENANCE_MISSING",
      "severity": "MEDIUM",
      "file": "01_fetch_data.R",
      "lines": [
        49,
        60,
        63,
        68,
        74,
        79,
        100,
        106
      ],
      "evidence": "Key identifying data (treatment timing and medical-marijuana timing) are manually hard-coded as in-script tables. The manuscript cites sources in prose, but the code does not programmatically fetch/verify these dates from a reproducible source file, nor does it record exact URLs/versions for each state/date. This creates a provenance and auditability gap for the central treatment variable (retail_year) and the medical control (medical_year).: # First legal recreational retail sales dates\n# Sources: NCSL Cannabis Overview, MJBizDaily, Ballotpedia\ntreatment <- tribble(\n  ~state_abbr, ~legalization_date, ~first_retail_date, ~retail_year,\n  \"CO\", \"2012-12-10\", \"2014-01-01\", 2014,\n  ...\n)\n\n# Medical marijuana timing (for control variable)\n# Approximate year medical dispensaries opened\nmedical_mj <- tribble(\n  ~state_abbr, ~medical_year,\n  \"CA\", 1996, \"OR\", 1998, ...\n)",
      "confidence": 0.78
    },
    {
      "category": "SUSPICIOUS_TRANSFORMS",
      "severity": "LOW",
      "file": "02_clean_data.R",
      "lines": [
        132,
        133,
        134
      ],
      "evidence": "The log transform adds arbitrary constants (+1 for levels; +0.01 for per-capita). This is often acceptable to avoid log(0), but it can matter for small states/years where apps_per_100k is low. The manuscript does not justify the specific +0.01 offset or provide sensitivity to alternative offsets (e.g., log1p scaling or inverse hyperbolic sine).: bfs_annual <- bfs_annual %>%\n  mutate(\n    apps_per_100k = annual_applications / population * 100000,\n    log_apps = log(annual_applications + 1),\n    log_apps_pc = log(apps_per_100k + 0.01)\n  )",
      "confidence": 0.6
    },
    {
      "category": "DATA_PROVENANCE_MISSING",
      "severity": "LOW",
      "file": "03_main_analysis.R",
      "lines": [
        10
      ],
      "evidence": "The script attempts to load a file (panel_sector.csv) that is not created anywhere in the provided code. This is not direct evidence of fabrication, but it indicates a missing/unfinished data pipeline component and complicates full reproduction from the provided scripts alone.: sector_panel <- read_csv(file.path(DATA_DIR, \"panel_sector.csv\"), show_col_types = FALSE)",
      "confidence": 0.72
    }
  ],
  "file_verdicts": [
    {
      "file": "01_fetch_data.R",
      "verdict": "CLEAN"
    },
    {
      "file": "06_tables.R",
      "verdict": "CLEAN"
    },
    {
      "file": "00_packages.R",
      "verdict": "CLEAN"
    },
    {
      "file": "04_robustness.R",
      "verdict": "SUSPICIOUS"
    },
    {
      "file": "02_clean_data.R",
      "verdict": "CLEAN"
    },
    {
      "file": "03_main_analysis.R",
      "verdict": "SUSPICIOUS"
    },
    {
      "file": "05_figures.R",
      "verdict": "CLEAN"
    }
  ],
  "summary": {
    "verdict": "SUSPICIOUS",
    "counts": {
      "CRITICAL": 0,
      "HIGH": 2,
      "MEDIUM": 1,
      "LOW": 2
    },
    "one_liner": "method mismatch",
    "executive_summary": "The R scripts implementing the Callaway\u2013Sant\u2019Anna (CS) DiD estimates do not specify bootstrap inference settings, even though the manuscript repeatedly claims CS standard errors come from a 999-replication bootstrap (including the abstract and Table 4 notes). This mismatch appears both in the main analysis (`03_main_analysis.R`) and in the robustness checks (`04_robustness.R`), meaning the reported CS standard errors in the paper are not generated using the stated bootstrap procedure.",
    "top_issues": [
      {
        "category": "METHODOLOGY_MISMATCH",
        "severity": "HIGH",
        "short": "The manuscript repeatedly states that Callaway-Sant'Anna ...",
        "file": "03_main_analysis.R",
        "lines": [
          35,
          46
        ],
        "github_url": "/apep_0082/code/03_main_analysis.R#L35-L68"
      },
      {
        "category": "METHODOLOGY_MISMATCH",
        "severity": "HIGH",
        "short": "Same issue as the main CS specification",
        "file": "04_robustness.R",
        "lines": [
          18,
          31
        ],
        "github_url": "/apep_0082/code/04_robustness.R#L18-L274"
      }
    ],
    "full_report_url": "/tournament/corpus_scanner/scans/apep_0082_scan.json"
  },
  "error": null
}