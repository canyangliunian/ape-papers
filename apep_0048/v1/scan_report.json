{
  "paper_id": "apep_0048",
  "scan_date": "2026-02-06T12:35:58.611694+00:00",
  "scan_version": "2.0.0",
  "model": "openai/gpt-5.2",
  "overall_verdict": "SUSPICIOUS",
  "files_scanned": 11,
  "flags": [
    {
      "category": "DATA_FABRICATION",
      "severity": "HIGH",
      "file": "03_real_data.R",
      "lines": [
        146,
        147
      ],
      "evidence": "The key heterogeneity variable URBAN is not taken from the IPUMS microdata; it is stochastically generated via a Bernoulli draw using state-year urbanization rates. This injects simulated measurement error into a central regressor and makes results non-unique to the underlying data (depend on RNG), which is a major integrity concern unless explicitly framed as a simulation/imputation exercise and justified in the manuscript.: set.seed(52)\nanalysis_data$URBAN <- rbinom(nrow(analysis_data), 1, analysis_data$urban_rate)",
      "confidence": 0.95
    },
    {
      "category": "DATA_FABRICATION",
      "severity": "LOW",
      "file": "02_pilot_analysis.R",
      "lines": [
        1,
        8,
        58,
        86,
        125,
        126
      ],
      "evidence": "This script intentionally simulates data for a pilot/validation exercise. This is not inherently problematic, but it becomes an integrity issue if outputs from this script are presented as real-data results (see separate hard-coded/figure/table findings).: # Run quick validation using simulated data\n...\nset.seed(42)\n...\nurban = rbinom(n(), 1, urban_rate)\n...\nlfp_latent = ... + rnorm(n(), 0, 0.1),\nlabforce = as.integer(lfp_latent > runif(n()))",
      "confidence": 0.9
    },
    {
      "category": "HARD_CODED_RESULTS",
      "severity": "HIGH",
      "file": "05_tables.R",
      "lines": [
        16,
        18,
        68,
        71,
        122,
        125
      ],
      "evidence": "Multiple LaTeX tables are populated with literal coefficients/SEs/R-squared/observations and summary statistics rather than being computed from model objects or loaded result files. Unless the manuscript explicitly states these are illustrative placeholders (no paper.tex provided here), this is a major reproducibility and integrity risk: reported numerical results could be disconnected from the estimation code.: summary_data <- data.frame(\n  Variable = c(\"N (thousands)\", \"\", \"Labor Force Participation\", ...),\n  col1 = c(\"12,450\", \"\", \"12.6\\\\%\", \"(0.33)\", ...),\n  ...\n)\n...\nPost-Suffrage & 0.026*** & 0.012*** & 0.011*** & \\\\\n & (0.005) & (0.004) & (0.004) & \\\\\n...\nObservations & 28,690,000 & 28,690,000 & 28,690,000 & 28,690,000 \\\\\nR$^2$ & 0.005 & 0.019 & 0.042 & 0.005 \\\\",
      "confidence": 0.98
    },
    {
      "category": "HARD_CODED_RESULTS",
      "severity": "HIGH",
      "file": "04_figures.R",
      "lines": [
        52,
        57,
        120,
        121,
        171,
        172,
        240,
        241
      ],
      "evidence": "Figures for parallel trends, event studies, and robustness are built from manually entered coefficients/SEs and group means rather than computed from the analysis dataset/models. If these are used in the paper as empirical results, this constitutes hard-coded reporting and undermines auditability.: # Simulated pre-treatment trends data (based on pilot)\ntrends_data <- data.frame(\n  year = rep(c(1880, 1900, 1910, 1920), 4),\n  ...\n  lfp = c(\n    0.195, 0.199, 0.200, 0.229,\n    0.101, 0.105, 0.102, 0.115,\n    0.193, 0.195, 0.188, 0.191,\n    0.099, 0.100, 0.099, 0.102\n  )\n)\n...\nes_data <- data.frame(\n  event_time = c(-30, -20, -10, 0, 10),\n  coef = c(-0.002, 0.001, 0.007, 0.028, 0.025),\n  se = c(0.008, 0.006, 0.005, 0.006, 0.007)\n)\n...\nrobust_data <- data.frame(\n  estimator = c(\"TWFE\", \"Callaway-Sant'Anna\", \"Sun-Abraham\", \"did2s\", \"Excluding Early Adopters\"),\n  coef = c(0.026, 0.028, 0.027, 0.029, 0.025),\n  se = c(0.005, 0.006, 0.006, 0.007, 0.008)\n)",
      "confidence": 0.97
    },
    {
      "category": "DATA_PROVENANCE_MISSING",
      "severity": "HIGH",
      "file": "03_real_data.R",
      "lines": [
        96,
        97,
        100,
        104,
        109,
        147
      ],
      "evidence": "A core explanatory variable is built from an inline, undocumented state-year urbanization rate table, then converted to a micro-level URBAN indicator by random assignment. The source for the urbanization rates is not programmatically linked (no download/citation file), and the transformation from rates to individual URBAN is not grounded in observed microdata. This is especially concerning because the IPUMS extract script requests the URBAN variable directly (suggesting URBAN should exist in the raw data).: state_urban <- fread(\"\nstatefip,urban_1880,urban_1900,urban_1910,urban_1920\n1,0.05,0.12,0.18,0.22\n...\")\n...\nanalysis_data$URBAN <- rbinom(nrow(analysis_data), 1, analysis_data$urban_rate)",
      "confidence": 0.9
    },
    {
      "category": "DATA_PROVENANCE_MISSING",
      "severity": "MEDIUM",
      "file": "03_real_data.R",
      "lines": [
        45,
        46
      ],
      "evidence": "The primary microdata file is referenced via a relative path outside the repository (../paper_48/...). Without an included fetch/download step (beyond IPUMS submission) or clear repo structure documentation, reproduction by third parties is fragile.: dat_path <- \"../paper_48/data/usa_00135.dat.gz\"\n\nif (!file.exists(dat_path)) {\n  stop(\"IPUMS extract not found at: \", dat_path)\n}",
      "confidence": 0.8
    },
    {
      "category": "METHODOLOGY_MISMATCH",
      "severity": "HIGH",
      "file": "01_submit_extract.R",
      "lines": [
        22,
        29
      ],
      "evidence": "The extract explicitly includes IPUMS's URBAN variable, but the 'real data' processing script (03_real_data.R) does not parse URBAN from the fixed-width file and instead imputes it via random draws from state-year rates. This is a substantive mismatch between stated data design (use URBAN from IPUMS) and implemented analysis (simulate URBAN).: variables = c(\n  ...\n  # Key heterogeneity - URBAN is critical!\n  \"URBAN\",\n  ...\n)",
      "confidence": 0.9
    },
    {
      "category": "SUSPICIOUS_TRANSFORMS",
      "severity": "MEDIUM",
      "file": "03_real_data.R",
      "lines": [
        52,
        53,
        80,
        81
      ],
      "evidence": "The analysis is performed on a 10% subsample drawn separately within each read chunk, with a seed that changes by chunk. This is not equivalent to a uniform simple random sample of the full qualifying dataset unless chunk ordering is random/irrelevant. If the order of records correlates with geography/year or any variable, the resulting sample may be inadvertently biased. At minimum this needs justification and/or a true SRS mechanism (e.g., hash-based sampling on a stable ID).: sample_rate <- 0.10  # Keep 10% of qualifying records\n...\nset.seed(52 + chunk_num)  # Reproducible sampling\nn_sample <- ceiling(nrow(chunk_filtered) * sample_rate)\nchunk_sampled <- chunk_filtered[sample(nrow(chunk_filtered), n_sample), ]",
      "confidence": 0.78
    },
    {
      "category": "SELECTIVE_REPORTING",
      "severity": "MEDIUM",
      "file": "08_real_tables.R",
      "lines": [
        13,
        16
      ],
      "evidence": "The tables script loads a results object 'real_results_updated.rds', but the provided estimation script (03_real_data.R) saves 'data/real_results.rds'. This discrepancy can enable silent swapping of result files and makes it unclear which code produced the reported estimates. This is a reproducibility red flag and can facilitate selective reporting if multiple results files exist.: results <- readRDS(\"data/real_results_updated.rds\")",
      "confidence": 0.85
    },
    {
      "category": "STATISTICAL_IMPOSSIBILITY",
      "severity": "HIGH",
      "file": "07_real_figures.R",
      "lines": [
        118,
        119,
        145,
        146
      ],
      "evidence": "Figure construction includes a hard-coded standard error (se = 0.01) and introduces a reference-period row with Std. Error = 0. Exactly zero SEs are generally statistically invalid, and using arbitrary fixed SEs can create misleading confidence intervals and significance indicators. If these figures are used for inference in the manuscript, the inference is not credible.: event_study_data <- event_study_data %>%\n  mutate(\n    coef_adj = coef - pre_mean,\n    se = 0.01  # Approximate SE from regression\n  )\n...\nref_row <- data.frame(\n  Estimate = 0,\n  `Std. Error` = 0,\n  `t value` = 0,\n  `Pr(>|t|)` = NA,\n  event_time = ref_period,\n  ...\n)",
      "confidence": 0.93
    }
  ],
  "file_verdicts": [
    {
      "file": "03_real_data.R",
      "verdict": "SUSPICIOUS"
    },
    {
      "file": "00_packages.R",
      "verdict": "CLEAN"
    },
    {
      "file": "02_pilot_analysis.R",
      "verdict": "CLEAN"
    },
    {
      "file": "08_real_tables.R",
      "verdict": "CLEAN"
    },
    {
      "file": "07_real_figures.R",
      "verdict": "SUSPICIOUS"
    },
    {
      "file": "09_fix_event_study.R",
      "verdict": "CLEAN"
    },
    {
      "file": "01_submit_extract.R",
      "verdict": "SUSPICIOUS"
    },
    {
      "file": "05_tables.R",
      "verdict": "SUSPICIOUS"
    },
    {
      "file": "04_figures.R",
      "verdict": "SUSPICIOUS"
    },
    {
      "file": "03_main_analysis.R",
      "verdict": "CLEAN"
    },
    {
      "file": "06_updated_analysis.R",
      "verdict": "CLEAN"
    }
  ],
  "summary": {
    "verdict": "SUSPICIOUS",
    "counts": {
      "CRITICAL": 0,
      "HIGH": 6,
      "MEDIUM": 3,
      "LOW": 1
    },
    "one_liner": "fabricated data; hard-coded results",
    "executive_summary": "The code constructs the key heterogeneity variable **URBAN** by randomly assigning it via Bernoulli draws from an inline, undocumented state\u2013year urbanization-rate table rather than reading the **URBAN** field from the IPUMS microdata, despite the extract being specified to include IPUMS\u2019s URBAN variable. In addition, many reported coefficients, standard errors, R-squared values, sample sizes, and summary statistics in **tables and figures** are manually hard-coded into the LaTeX/plot scripts instead of being computed from model objects or saved results, making the reported empirical results non-reproducible and potentially disconnected from the underlying data and estimations.",
    "top_issues": [
      {
        "category": "DATA_FABRICATION",
        "severity": "HIGH",
        "short": "The key heterogeneity variable URBAN is not taken from th...",
        "file": "03_real_data.R",
        "lines": [
          146,
          147
        ],
        "github_url": "/apep_0048/code/03_real_data.R#L146-L147"
      },
      {
        "category": "HARD_CODED_RESULTS",
        "severity": "HIGH",
        "short": "Multiple LaTeX tables are populated with literal coeffici...",
        "file": "05_tables.R",
        "lines": [
          16,
          18
        ],
        "github_url": "/apep_0048/code/05_tables.R#L16-L125"
      },
      {
        "category": "HARD_CODED_RESULTS",
        "severity": "HIGH",
        "short": "Figures for parallel trends, event studies, and robustnes...",
        "file": "04_figures.R",
        "lines": [
          52,
          57
        ],
        "github_url": "/apep_0048/code/04_figures.R#L52-L241"
      }
    ],
    "full_report_url": "/tournament/corpus_scanner/scans/apep_0048_scan.json"
  },
  "error": null
}