\documentclass[12pt]{article}

% UTF-8 encoding and fonts
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{lmodern}

% Page setup
\usepackage[margin=1in]{geometry}
\usepackage{setspace}
\onehalfspacing

% Typography
\usepackage{microtype}

% Math and symbols
\usepackage{amsmath,amssymb}

% Graphics
\usepackage{graphicx}
\usepackage{float}
\usepackage{subcaption}

% Tables
\usepackage{booktabs}
\usepackage{array}
\usepackage{multirow}
\usepackage{threeparttable}
\usepackage{longtable}
\usepackage{pdflscape}
\usepackage{siunitx}
\sisetup{detect-all=true, group-separator={,}, group-minimum-digits=4}

% Bibliography
\usepackage{natbib}
\bibliographystyle{aer}

% Hyperlinks
\usepackage{hyperref}
\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    citecolor=blue,
    urlcolor=blue
}
\usepackage[nameinlink,noabbrev]{cleveref}

% Captions
\usepackage{caption}
\captionsetup{font=small,labelfont=bf}

% Section formatting
\usepackage{titlesec}
\titleformat{\section}{\large\bfseries}{\thesection.}{0.5em}{}
\titleformat{\subsection}{\normalsize\bfseries}{\thesubsection}{0.5em}{}

% Float notes
\newcommand{\floatfoot}[1]{\par\vspace{0.5em}\noindent\footnotesize #1}

% Custom commands
\newcommand{\E}{\mathbb{E}}
\newcommand{\Var}{\text{Var}}
\newcommand{\Cov}{\text{Cov}}
\newcommand{\ind}{\mathbb{I}}
\newcommand{\sym}[1]{\ifmmode^{#1}\else\(^{#1}\)\fi}

\title{Does the Safety Net Bite Back? \\ Medicaid Postpartum Coverage Extensions \\ Through the Public Health Emergency and Beyond\thanks{This is a revision of APEP Working Paper 0153 (v2). Changes: fixed narrative inconsistencies regarding the statistical significance of the post-PHE Medicaid ATT, added permutation inference, 2024-only post-period specification, attenuation bias quantification, DDD pre-trend event study, and HonestDiD sensitivity figure.}}
\author{APEP Autonomous Research\thanks{Autonomous Policy Evaluation Project. Correspondence: scl@econ.uzh.ch} \and @ai1scl}
\date{\today}

\begin{document}

\maketitle

\begin{abstract}
\noindent
Between 2021 and 2024, 47 U.S.\ jurisdictions adopted extensions of Medicaid postpartum coverage from 60 days to 12 months, the most rapid expansion of maternal health coverage in decades. Using individual-level data on 237,365 postpartum women from the American Community Survey (2017--2019, 2021--2024; 2020 excluded due to non-standard data collection) and a staggered difference-in-differences design with the Callaway and Sant'Anna (2021) estimator, this paper evaluates whether these extensions increased insurance coverage among women who recently gave birth. The full-sample CS-DiD ATT for Medicaid coverage is $-0.5$ percentage points (SE = 0.7 pp, $p > 0.10$). The post-PHE specification (2017--2019 + 2023--2024), which excludes the period when continuous enrollment rendered the coverage cliff non-binding, yields a \emph{statistically significant negative} Medicaid ATT of $-2.18$ pp (SE = 0.76 pp, $p < 0.01$). This negative estimate does not reflect policy harm; rather, it captures the secular Medicaid unwinding that disproportionately reduced enrollment in treated states after the PHE ended. A triple-difference (DDD) design---comparing postpartum to non-postpartum low-income women within treated and control states---absorbs these common unwinding shocks. The DDD CS-DiD estimate is \mbox{$+1.0$} pp (SE $\approx$ 1.5 pp), statistically insignificant but signed in the direction predicted by the policy's institutional logic. The overall story is that the standard DiD picks up the Medicaid unwinding confound; the DDD resolves it, yielding a small but imprecise postpartum-specific effect estimate. Event-study estimates through two post-treatment periods show flat dynamics, and permutation inference (500 randomizations), wild cluster bootstrap, and Rambachan-Roth HonestDiD sensitivity analysis all confirm that the confidence interval includes zero under moderate violations of parallel trends. These findings constitute a well-identified result with substantially stronger methodology than the earlier analysis: even with post-PHE data, a DDD design, and multiple inference procedures, the postpartum extensions do not produce detectable coverage gains in survey data, suggesting that administrative enrollment mechanics, measurement limitations in the ACS, or the thin control group (4 states) may attenuate the policy's apparent impact.
\end{abstract}

\vspace{1em}
\noindent\textbf{JEL Codes:} I13, I18, H75 \\
\noindent\textbf{Keywords:} Medicaid, postpartum coverage, maternal health, difference-in-differences, triple-difference, Public Health Emergency, insurance coverage, permutation inference

\newpage

\section{Introduction}

Maternal mortality in the United States has diverged sharply from other high-income countries, rising from 12.7 deaths per 100,000 live births in 2000 to 32.9 in 2021 \citep{hoyert2023maternal}. The U.S.\ maternal mortality rate is now more than double that of any other G7 nation. A substantial share of pregnancy-related deaths---more than one-third---occur between 7 days and one year postpartum \citep{petersen2019vital}, a period during which many low-income women historically lost Medicaid coverage just 60 days after delivery. This coverage gap has been identified as a critical contributor to adverse maternal health outcomes, particularly among Black and Hispanic women who rely disproportionately on Medicaid for pregnancy-related care \citep{eliason2020coverage, gordon2022trends}.

In response, the American Rescue Plan Act (ARPA) of March 2021 created a new option for states to extend Medicaid postpartum coverage from 60 days to a full 12 months. By early 2025, 47 jurisdictions had adopted the extension---one of the fastest-spreading health policy reforms in recent U.S.\ history. This paper evaluates whether these extensions increased insurance coverage among women who recently gave birth, using data through 2024 that incorporates two full post--Public Health Emergency (PHE) years when the 60-day coverage cliff became binding again.

\paragraph{Roadmap of contributions.} This paper makes five contributions relative to the earlier analysis (APEP Working Paper 0149/0153). \emph{First}, it corrects a narrative inconsistency in the predecessor paper: the post-PHE Medicaid ATT is a statistically significant \emph{negative} $-2.18$ pp, not a null result. We reframe this finding as reflecting the Medicaid unwinding confound rather than policy harm, and motivate the DDD as the specification that isolates the postpartum-specific effect. \emph{Second}, a triple-difference design compares postpartum to non-postpartum low-income women, absorbing state-level unwinding shocks and resolving the employer insurance placebo failure that reviewers identified as a critical concern. \emph{Third}, we add permutation-based inference (500 randomizations of treatment assignment), providing exact $p$-values that do not rely on asymptotic approximations with few clusters. \emph{Fourth}, we quantify the attenuation bias introduced by the ACS's lack of birth-month information, providing a back-of-the-envelope ITT scaling factor. \emph{Fifth}, we report Rambachan-Roth HonestDiD sensitivity analysis with a visualization of how robust confidence intervals expand across an $\bar{M}$-grid, and we present a 2024-only post-period specification that excludes the mixed 2023 survey year entirely.

The central finding is that the standard DiD picks up a Medicaid unwinding confound---the statistically significant negative post-PHE ATT of $-2.18$ pp reflects the disproportionate decline in Medicaid enrollment in treated states (which had larger Medicaid rolls during the PHE) as the unwinding proceeded. The DDD design, which differences out this secular shock by comparing postpartum women to non-postpartum women of similar income within the same states, yields a point estimate of \mbox{$+1.0$} pp---small, signed in the expected direction (or close to zero), and statistically insignificant. This pattern---a significant negative standard DiD resolved to a small insignificant DDD---is consistent with the policy having at most a modest effect on survey-measured coverage rates, obscured by the dominant unwinding dynamics of 2023--2024.

The remainder of the paper is organized as follows. Section 2 describes the institutional background, including the PHE and Medicaid unwinding dynamics. Section 3 outlines the conceptual framework. Section 4 describes the data and quantifies attenuation bias from the ACS measurement structure. Section 5 presents the empirical strategy, including the DDD design, post-PHE specifications, and inference procedures. Section 6 reports main results. Section 7 presents robustness checks and sensitivity analyses, including permutation inference, the 2024-only post-period, DDD pre-trend event studies, and HonestDiD sensitivity figures. Section 8 discusses findings and limitations. Section 9 concludes.


\section{Institutional Background and Policy Setting}

\subsection{Medicaid Postpartum Coverage: The 60-Day Cliff}

Medicaid is the single largest payer for maternity care in the United States, financing approximately 42\% of all births \citep{medicaid_births}. Under traditional Medicaid eligibility rules, pregnant women qualify for coverage at higher income thresholds than the general adult population---typically up to 185\% or even 200\% of the federal poverty level (FPL) in many states, compared to 138\% FPL for the general adult population under the Affordable Care Act (ACA) Medicaid expansion. However, this enhanced pregnancy eligibility has historically been limited to the pregnancy period plus 60 days postpartum, after which women's coverage reverted to the lower general-population income thresholds.

This 60-day postpartum coverage cliff had long been identified as a critical gap in the maternal health safety net. The American College of Obstetricians and Gynecologists (ACOG) recommends comprehensive postpartum care extending through the first year after birth, including screening for postpartum depression, management of pregnancy-related complications such as preeclampsia and gestational diabetes, and family planning services \citep{acog2018optimizing}. The 60-day cutoff meant that many low-income women lost access to these services precisely when they were most vulnerable, as the postpartum period carries elevated risks for cardiovascular events, mental health crises, and infection.

The consequences of the 60-day cliff have been extensively documented. \citet{daw2020getting} find that roughly one in four women who were insured at delivery experienced a coverage disruption within six months postpartum, with the highest rates of churn among Medicaid-covered women. These coverage gaps are concentrated precisely when clinical guidelines call for continued monitoring \citep{acog2018optimizing}. The clinical stakes are high: over one-third of pregnancy-related deaths occur between 7 days and one year postpartum \citep{petersen2019vital}, and the U.S.\ maternal mortality rate rose to 32.9 per 100,000 live births in 2021 \citep{hoyert2023maternal, tikkanen2020maternal}. Racial disparities compound the problem: Black women face maternal mortality rates 2.6 times higher than White women and are disproportionately covered by Medicaid during pregnancy \citep{petersen2019vital}.

\subsection{The ARPA Reform and Staggered Adoption}

The American Rescue Plan Act of March 2021 (P.L.\ 117-2, Section 9812) created a new option under Section 1902(e)(16) of the Social Security Act, allowing states to extend Medicaid and CHIP postpartum coverage from 60 days to 12 months through a State Plan Amendment (SPA). This option became effective on April 1, 2022, and was made permanent by the Consolidated Appropriations Act of 2023.

Several states moved to extend postpartum coverage before the SPA option became available, using Section 1115 demonstration waivers. Illinois was the first (April 2021), followed by Georgia, Missouri, New Jersey, and Virginia. Once the SPA option became available, adoption was rapid: approximately 25 states adopted in 2022, 13 in 2023, and 5 in 2024. \Cref{tab:adoption} provides the complete adoption timeline.

This staggered adoption creates the policy variation exploited in the empirical analysis. With data through 2024, I code 47 jurisdictions as treated (adopting by 2024) and 4 as the control group: Arkansas and Wisconsin (never-adopted) plus Idaho and Iowa (adopting in 2025, not yet treated in the sample). The near-universal adoption limits power but the extended panel compensates by providing more post-treatment observations.

\subsection{The COVID-19 Public Health Emergency, Continuous Enrollment, and the Unwinding}

The Families First Coronavirus Response Act (FFCRA) of March 2020 established a continuous enrollment condition for state Medicaid programs. Under this provision, states receiving the enhanced Federal Medical Assistance Percentage (FMAP) were prohibited from terminating Medicaid coverage for any beneficiary. This continuous enrollment provision remained in force until May 11, 2023, after which states began the ``unwinding'' process of conducting eligibility redeterminations.

The PHE continuous enrollment provision had profound implications for evaluating the postpartum extensions. During continuous enrollment, a woman who qualified for Medicaid during pregnancy could not be disenrolled after the 60-day postpartum period, even though she no longer met the traditional eligibility criteria. This meant that the 60-day cliff was effectively non-binding during the PHE, and the postpartum extension's marginal contribution to coverage was approximately zero for states adopting during this period.

The Medicaid unwinding began in earnest in April 2023. By March 2024, an estimated 19.6 million people had been disenrolled from Medicaid \citep{kff_unwinding}, with substantial heterogeneity across states in the pace and magnitude of coverage losses \citep{sommers2024unwinding}. Crucially, this unwinding was not uniform across states: states that had experienced the largest enrollment growth during the PHE---which substantially overlap with the states that adopted postpartum extensions---experienced the most severe unwinding-driven enrollment declines. This creates a mechanical confound for standard difference-in-differences estimation. If treated states lost more Medicaid enrollees during the unwinding than control states, then the post-PHE DiD will attribute this secular decline to the postpartum extension, producing a spurious negative treatment effect estimate. This unwinding confound is central to interpreting the results of this paper: the statistically significant negative post-PHE Medicaid ATT ($-2.18$ pp) almost certainly reflects this differential unwinding rather than any harmful effect of the postpartum extension itself. The triple-difference design directly addresses this confound.


\section{Conceptual Framework}

\subsection{Expected Effect Magnitude}

The theoretical prediction for the effect of postpartum Medicaid extensions on insurance coverage is straightforward in the post-PHE environment. Consider a woman who qualifies for Medicaid during pregnancy. Under the traditional 60-day rule, her Medicaid eligibility ends approximately two months after delivery. If her income exceeds the general Medicaid threshold, she faces three options: (1) obtain employer-sponsored insurance, (2) purchase marketplace insurance (potentially with subsidies), or (3) become uninsured. The 12-month postpartum extension eliminates this coverage gap by extending Medicaid eligibility for a full year after delivery.

The expected magnitude depends on the fraction of postpartum women whose coverage is affected by the extension. Approximately 42\% of births are Medicaid-financed nationally, but not all of these women would have lost coverage at 60 days. The ``at-risk'' population---women who would have become uninsured or experienced coverage disruption after the 60-day cutoff---likely constitutes 15--25\% of all postpartum women, implying an expected coverage effect of roughly 5--15 percentage points among the full postpartum population, and larger effects among the low-income subgroup.

\subsection{PHE Interaction and Temporal Heterogeneity}

The PHE creates sharp temporal heterogeneity in the policy's bite. During the PHE (2020--2022), the extension's effect on coverage should be approximately zero for states that adopted during this period. The extension's true effect should emerge in 2023--2024, after the PHE ends and the 60-day cliff becomes binding again. This generates a specific testable prediction: the event-study trajectory should show flat or near-zero effects at short horizons (corresponding to the PHE period) and growing positive effects at longer horizons (corresponding to the post-PHE period).

However, the Medicaid unwinding complicates this prediction. The post-PHE period combines two offsetting forces: (1) the return of the 60-day cliff, which makes the extension binding and should produce positive coverage effects, and (2) the unwinding-driven Medicaid enrollment decline, which reduces coverage among all beneficiaries in states with large PHE-era enrollment expansions. In a standard DiD, force (2) may dominate force (1), producing a negative estimate even if the extension has a positive causal effect on the postpartum-specific population. The DDD design isolates force (1) by differencing out force (2), which affects postpartum and non-postpartum women similarly.

\subsection{The DDD Rationale}

The triple-difference design is motivated by both the employer insurance placebo failure in the earlier analysis and the Medicaid unwinding confound. If secular forces---such as the Medicaid unwinding or pandemic-era labor market disruptions---differentially affected treated versus control states, then a simple DiD comparing postpartum women across states will conflate the policy effect with these secular trends. The DDD design addresses this by using non-postpartum low-income women as an additional comparison group. Any shock that affects all low-income women similarly in treated versus control states (e.g., changes in employer benefit offerings, differential Medicaid unwinding) will be differenced out, isolating the postpartum-specific component of any coverage change.

\subsection{Testable Predictions}

The framework generates several testable predictions. The standard DiD Medicaid effect in the post-PHE period is ambiguous in sign, as the positive effect of the extension competes with the negative unwinding confound. The DDD Medicaid effect should be positive, as the unwinding confound is differenced out, isolating the postpartum-specific channel. Similarly, the post-PHE uninsurance effect in the standard DiD is ambiguous, while the DDD should yield a negative effect (reduced uninsurance). The DDD employer insurance coefficient should be null, as the DDD differences out secular labor market forces. The event-study trajectory should be flat during the PHE period, with the post-PHE direction depending on the balance of extension and unwinding effects. Late-adopter effects should be cleaner and possibly larger, given the absence of PHE overlap and potentially less unwinding exposure. Finally, placebo populations---high-income postpartum women and non-postpartum women---should show null effects.


\section{Data}

\subsection{American Community Survey PUMS}

The primary data source is the American Community Survey (ACS) 1-year Public Use Microdata Samples (PUMS) for 2017--2024, with the exclusion of 2020 due to non-standard data collection during the pandemic. The ACS is the largest household survey in the United States, with approximately 3.3 million person records per year. The 1-year PUMS provides individual-level data on demographics, employment, income, and health insurance coverage, with state identifiers enabling state-level policy evaluation.

Key variables include: FER (fertility: gave birth in past 12 months), HICOV (health insurance coverage), HINS4 (Medicaid), HINS1 (employer insurance), HINS2 (direct-purchase insurance), POVPIP (income-to-poverty ratio), and standard demographics (age, race, education, marital status). All regressions use ACS person weights (PWGTP).

\subsection{Sample Construction}

The analysis sample consists of women aged 18--44 who appear in the ACS PUMS across seven survey years: 2017, 2018, 2019, 2021, 2022, 2023, and 2024. The total sample contains 3,683,347 women aged 18--44. Of these, 237,365 reported giving birth in the past 12 months (FER = 1), forming the primary postpartum analysis sample---an increase of approximately 70,000 observations compared to the earlier analysis. Subsamples include: 86,991 low-income postpartum women (below 200\% FPL), 82,325 high-income postpartum women (above 400\% FPL, used as a placebo), and 1,181,552 non-postpartum low-income women (used as the DDD comparison group).

\subsection{Treatment Assignment}

Treatment assignment is based on state-level adoption dates compiled from CMS press releases, Kaiser Family Foundation tracking data, and state Medicaid agency announcements. With data through 2024, the analysis includes 47 treated jurisdictions (4 adopting in 2021, 25 in 2022, 13 in 2023, and 5 in 2024) and 4 control jurisdictions: Arkansas and Wisconsin (never adopted) plus Idaho and Iowa (adopting in 2025).

\textbf{Intent-to-treat interpretation.} The ACS fertility variable (FER = 1) identifies women who gave birth in the past 12 months but does not include birth month. A postpartum woman surveyed in year $t$ may have given birth anywhere from 1 to 12 months prior, and her postpartum window may only partially overlap with the extension's effective period. All estimates should be interpreted as intent-to-treat (ITT) effects. This imperfect mapping introduces attenuation bias, which we quantify in Section~4.4.

\textbf{Treatment timing and ACS alignment.} I code a state as ``treated'' in survey year $t$ if the extension's effective date falls on or before July 1 of year $t$ (i.e., the extension was in place for at least half the reference year). For the CS-DiD estimator, the treatment cohort year $G_s$ is the first calendar year in which the extension is coded as active. \Cref{tab:timing_map} illustrates the mapping from adoption cohort to event time for the ACS survey years used in the analysis.

\begin{table}[H]
\centering
\caption{Event-Time Mapping by Adoption Cohort and ACS Survey Year}
\label{tab:timing_map}
\small
\begin{tabular}{lcccccccc}
\toprule
& \multicolumn{7}{c}{ACS Survey Year} \\
\cmidrule(lr){2-8}
Cohort ($G_s$) & 2017 & 2018 & 2019 & 2021 & 2022 & 2023 & 2024 \\
\midrule
2021 (4 states) & $e\!=\!{-4}$ & $e\!=\!{-3}$ & $e\!=\!{-2}$ & $e\!=\!0$ & $e\!=\!1$ & $e\!=\!2$ & $e\!=\!3$ \\
2022 (25 states) & $e\!=\!{-5}$ & $e\!=\!{-4}$ & $e\!=\!{-3}$ & $e\!=\!{-1}$ & $e\!=\!0$ & $e\!=\!1$ & $e\!=\!2$ \\
2023 (13 states) & $e\!=\!{-6}$ & $e\!=\!{-5}$ & $e\!=\!{-4}$ & $e\!=\!{-2}$ & $e\!=\!{-1}$ & $e\!=\!0$ & $e\!=\!1$ \\
2024 (5 states) & $e\!=\!{-7}$ & $e\!=\!{-6}$ & $e\!=\!{-5}$ & $e\!=\!{-3}$ & $e\!=\!{-2}$ & $e\!=\!{-1}$ & $e\!=\!0$ \\
Control (4 states) & Pre & Pre & Pre & Pre & Pre & Pre & Pre \\
\bottomrule
\end{tabular}
\begin{tablenotes}[flushleft]
\small
\item \textit{Notes:} Event time $e = t - G_s$. The 2023--2024 columns are post-PHE. The PHE continuous enrollment period (March 2020 -- May 2023) rendered the 60-day coverage cliff non-binding. Control states: AR, WI (never adopted), ID, IA (adopt 2025). All tables report the number of clusters used in each specification.
\end{tablenotes}
\end{table}

The control group is thin---only 4 states---which is an inherent limitation of near-universal adoption. However, for the post-PHE specification and the DDD design, this limitation is partially mitigated by the temporal structure and the additional within-state variation from the postpartum/non-postpartum comparison.

\subsection{Attenuation Bias Quantification}
\label{sec:attenuation}

The ACS's lack of birth-month information introduces mechanical attenuation into all estimates. To quantify this, consider the following back-of-the-envelope calculation. The ACS PUMS identifies postpartum women as those who gave birth in the past 12 months (FER = 1). The treatment coding rule assigns a state as treated in survey year $t$ if the extension's effective date falls on or before July 1 of year $t$.

Under the assumption that births are uniformly distributed across months and that ACS interviews are uniformly distributed across the calendar year, consider a state that adopted on July 1 of year $t$ (the marginal case under our coding rule). A woman surveyed in year $t$ who reports FER = 1 could have given birth in any of the 12 months preceding her interview. For the extension to affect her coverage status, two conditions must hold: (a) she must be past the 60-day postpartum cliff (i.e., more than 2 months post-delivery), and (b) the extension must have been in effect when she reached the cliff.

Under uniform birth-month and interview-month distributions:
\begin{itemize}
    \item The probability that a randomly selected postpartum woman is past the 60-day cliff is approximately $10/12 \approx 0.83$.
    \item Among those past the cliff, the probability that they reached the cliff after the extension's effective date depends on the adoption timing. For a July 1 adopter, roughly half of the past-the-cliff women reached their cliff before July 1 and half after.
    \item Combining, the fraction of FER = 1 women in the marginal adoption year who are ``fully exposed'' to the extension is approximately $0.83 \times 0.5 = 0.42$.
\end{itemize}

For states that adopted early in the year (January--March), essentially all postpartum women surveyed in the adoption year are exposed, so the scaling factor approaches 0.83. For states that adopted mid-year, the factor is approximately 0.42. Averaging across adoption dates, the ITT scaling factor is roughly $0.5$--$0.7$, meaning that the true effect on fully-exposed women is approximately $1.4$--$2.0$ times the ITT estimate reported here. This attenuation is a structural feature of ACS-based policy evaluation and applies to all estimates in this paper.\footnote{This calculation follows the logic of \citet{daw2020getting}, who note that the ACS's annual reference period dilutes the signal of within-year coverage changes. Administrative data with exact enrollment and disenrollment dates would avoid this attenuation entirely.}

\subsection{Descriptive Statistics}

\Cref{tab:summary} presents summary statistics for the pre-treatment period (2017--2019). The treated and control groups are broadly similar on observable characteristics, supporting the parallel trends assumption. In the pre-treatment period, approximately 30\% of postpartum women had Medicaid coverage, 11\% were uninsured, and 54\% had employer-sponsored insurance.

\input{tables/tab1_summary}

\subsection{Trends in Coverage Over Time}

\Cref{fig:raw_trends} shows raw trends in coverage extended through 2024. The critical new pattern is visible in the post-2022 data: after the PHE ends (May 2023), Medicaid coverage declines across both treated and control states as the unwinding proceeds, but the decline is steeper in treated states---consistent with the unwinding confound discussed in Section 2.3. This raw-data pattern foreshadows the significant negative post-PHE DiD estimate and motivates the DDD design.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.95\textwidth]{figures/fig2_raw_trends.pdf}
    \caption{Raw Trends in Postpartum Insurance Coverage by Adoption Timing}
    \label{fig:raw_trends}
    \floatfoot{\textit{Notes:} Weighted average Medicaid coverage rate (top) and uninsurance rate (bottom) for postpartum women aged 18--44 ($N = 237{,}365$), by state adoption timing. Gray shading indicates the PHE period. Dotted line: PHE end (May 2023). Source: ACS 1-year PUMS, 2017--2024 (excl.\ 2020).}
\end{figure}


\section{Empirical Strategy}

\subsection{Staggered Difference-in-Differences}

The primary estimation approach is the Callaway and Sant'Anna (2021) estimator for staggered difference-in-differences, which addresses the well-documented biases of TWFE in settings with staggered treatment adoption \citep{goodman2021difference, dechaisemartin2020two, roth2023easy, borusyak2024revisiting}. The estimator computes group-time average treatment effects $ATT(g,t)$ and aggregates them to overall, dynamic, and calendar-time summaries. The identifying assumption is standard parallel trends:

\begin{equation}
    \E[Y_{s,t}(0) - Y_{s,t-1}(0) | G_s = g] = \E[Y_{s,t}(0) - Y_{s,t-1}(0) | G_s = \infty]
\end{equation}

With the extended data, the event study spans $e \in \{-4, \ldots, 2\}$, as the CS-DiD estimator aggregates available cohort-time cells up to two post-treatment periods.\footnote{Although the 2021 cohort has a potential third post-treatment year ($e = 3$), only 4 states are in this cohort, and the CS-DiD estimator does not produce reliable estimates at this horizon.} Critically, $e = 2$ corresponds to the post-PHE period for the 2021 cohort, where the treatment effect should emerge if the extension has a coverage impact.

An important note on aggregation: the CS-DiD aggregate ATT weights cohort-time cells according to group size, while the dynamic (event-study) aggregation averages across cohorts at each event time. These different weighting schemes mean that a significant aggregate ATT can coexist with individually insignificant event-study coefficients, and vice versa. We discuss this in the context of the uninsured outcome in Section 6.

\subsection{Triple-Difference (DDD) Design}

The DDD design addresses both the employer insurance placebo failure and the Medicaid unwinding confound by adding a within-state comparison group. I stack postpartum and non-postpartum low-income women and estimate:

\begin{equation}
    Y_{ipst} = \alpha_{sp} + \gamma_{tp} + \beta \cdot (\text{Treated}_{st} \times \text{Postpartum}_{i}) + \varepsilon_{ipst}
\end{equation}

\noindent where $\alpha_{sp}$ are state $\times$ postpartum fixed effects (absorbing time-invariant differences between postpartum and non-postpartum women within each state), $\gamma_{tp}$ are year $\times$ postpartum fixed effects (absorbing common shocks to each group across all states), and $\text{Postpartum}_i$ is an indicator for whether the woman gave birth in the past 12 months. The coefficient $\beta$ captures the differential effect of the postpartum extension on postpartum versus non-postpartum women in treated states.

The DDD assumption is weaker than the standard DiD: it requires that any differential trend between treated and control states is the same for postpartum and non-postpartum women. This is plausible because secular economic forces---including the Medicaid unwinding, which affects all enrollees regardless of postpartum status---should affect similarly-aged women of similar income regardless of recent fertility status.

As a complementary approach, I also implement CS-DiD on the differenced outcome: the state-year difference between postpartum and non-postpartum Medicaid rates. This provides heterogeneity-robust aggregation of the DDD treatment effect across adoption cohorts.

\subsection{Post-PHE Specification}

A complementary specification restricts the sample to pre-PHE and post-PHE years only: 2017--2019 as the pre-period and 2023--2024 as the post-period, excluding the PHE-contaminated years (2021--2022) entirely. An important caveat: the PHE continuous enrollment ended on May 11, 2023, so 2023 is a mixed year---ACS respondents interviewed before May 2023 were still under PHE protections, while those interviewed after were not. Since the ACS PUMS does not include interview month, I cannot separate these subpopulations.

I report results both with 2023 included (primary post-PHE specification) and with 2023 excluded (2024 only as the post-period; see Section 7.3). The 2024-only specification provides the cleanest post-PHE identification, as 2024 is fully free of PHE contamination.

\subsection{Late-Adopter Specification}

States that adopted in 2024 (Alaska, Nebraska, Texas, Utah, Nevada) provide particularly clean identification because their extensions took effect entirely in the post-PHE environment. I estimate a specification restricted to these 5 treated states versus the 4 control states. While this reduces power due to the small number of clusters, it provides a ``proof of concept'' for the policy's effect in a PHE-free environment.

\subsection{Inference}

Standard errors are clustered at the state level throughout. I supplement with three additional inference procedures designed to address the challenge of few clusters \citep{conley2011inference}:

\textbf{Wild cluster bootstrap.} Following \citet{cameron2008bootstrap} and \citet{mackinnon2017wild}, I implement WCB using Rademacher weights with 9,999 replications via the \texttt{fwildclusterboot} package. WCB provides more reliable $p$-values with few clusters, particularly when cluster sizes are heterogeneous, as is the case here where states range from small (Wyoming, Alaska) to very large (Texas, California) \citep{mackinnon2017wild}.

\textbf{Permutation inference.} I conduct a randomization inference test by randomly reassigning treatment status across states 500 times, re-estimating the CS-DiD ATT under each permutation, and computing the exact $p$-value as the fraction of permuted ATTs at least as extreme as the observed ATT. This procedure, related to the approach of \citet{conley2011inference} and the synthetic control inference framework of \citet{abadie2010synthetic}, provides a distribution-free test that does not rely on asymptotic approximations. The permutation distribution is presented in Figure~\ref{fig:permutation}.

\textbf{Rambachan-Roth HonestDiD sensitivity analysis.} Following \citet{rambachan2023more}, I conduct sensitivity analysis using the relative magnitudes approach. The parameter $\bar{M}$ bounds the ratio of post-treatment trend deviation to the maximum pre-treatment deviation. I report robust confidence intervals for $\bar{M} \in \{0, 0.5, 1.0, 1.5, 2.0\}$, providing formal bounds on the treatment effect under different assumptions about parallel trends violations.

\subsection{Alternative Estimators}

I implement several alternatives: TWFE as a biased benchmark, Sun-Abraham (2021) interaction-weighted event study, Goodman-Bacon (2021) decomposition of the TWFE estimator, and individual-level TWFE with demographic controls.


\section{Results}

\subsection{Main Results}

\Cref{tab:main_results} presents the main results across four estimation approaches.

\textbf{Panel A: Full-sample CS-DiD.} The overall ATT for Medicaid coverage is $-0.5$ pp (SE = 0.7 pp), statistically insignificant and economically small. The uninsured rate increases by 2.57 pp (SE = 0.36 pp, $p < 0.01$), a finding that is statistically significant despite the individually insignificant event-study coefficients shown in Figure~\ref{fig:event_study}. This apparent inconsistency arises because the CS-DiD aggregate ATT and the event-study dynamic aggregation weight cohort-time cells differently: the aggregate ATT weights by group size (giving more weight to the large 2022 adoption cohort), while the event-study averages across cohorts at each event time. A cohort-weighted aggregate can be significant even when all event-time-specific coefficients have wide confidence intervals, particularly when the cohort-time cells contributing most to the aggregate are consistently signed.\footnote{This is analogous to the distinction between a joint $F$-test and individual $t$-tests: the former can reject when the latter do not, because the joint test exploits the covariance structure across estimates.}

\input{tables/tab2_main_results}

\textbf{Panel C: Triple-difference (DDD).} The DDD estimates directly address the unwinding confound and the employer insurance placebo failure. The DDD TWFE coefficient on the treated $\times$ postpartum interaction is $-1.1$ pp (SE = 1.2 pp) for Medicaid, close to zero. The DDD employer insurance coefficient is 0.3 pp (SE = 0.9 pp), null as expected---confirming that the DDD successfully removes the secular labor market confound. The DDD CS-DiD on the differenced outcome (postpartum minus non-postpartum Medicaid rates) yields an estimate of \mbox{$+1.0$} pp (SE $\approx$ 1.5 pp). Both the TWFE DDD and the CS-DiD DDD point estimates are small and statistically insignificant. The key finding is that the DDD resolves the significant negative standard DiD estimate: once the secular unwinding shock is differenced out, the remaining postpartum-specific effect is close to zero, with a confidence interval that includes both economically meaningful positive effects and modest negative effects.

\textbf{Panel D: Post-PHE specification (2017--2019 + 2023--2024).} The Medicaid ATT in this specification is $-2.18$ pp (SE = 0.76 pp, $p < 0.01$), a statistically significant \emph{negative} estimate. This result must be interpreted carefully: it does \emph{not} indicate that the postpartum extension reduced Medicaid coverage. Rather, it captures the disproportionate Medicaid unwinding in treated states---states that adopted the extension early also tended to have larger PHE-era enrollment expansions and therefore experienced steeper enrollment declines during the unwinding. The standard DiD attributes this common state-level enrollment decline to the postpartum extension, producing a spurious negative coefficient. The DDD design, which differences out this unwinding confound, yields the more appropriate estimate of the postpartum-specific policy effect. The employer insurance coefficient in the post-PHE specification is 0.4 pp (SE = 1.1 pp), closer to zero than in the full sample, consistent with secular labor market forces being less of a confound in the post-PHE period.

\subsection{Event-Study Results}

\Cref{fig:event_study} presents the extended event-study estimates from the CS-DiD dynamic aggregation. Pre-treatment trends are flat, supporting the parallel trends assumption. The post-treatment coefficients at $e = 0$ through $e = 2$ remain close to zero or slightly negative for Medicaid. The uninsured event study shows positive coefficients at post-treatment event times, consistent with the significant aggregate ATT, though the individual event-time estimates have wide confidence intervals.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.95\textwidth]{figures/fig3_event_study.pdf}
    \caption{Event-Study Estimates: Callaway-Sant'Anna Dynamic Aggregation (Extended)}
    \label{fig:event_study}
    \floatfoot{\textit{Notes:} Callaway and Sant'Anna (2021) event-study estimates. Event time ranges from $e = -4$ to $e = 2$. Dependent variables are Medicaid coverage rate (top), uninsurance rate (middle), and employer insurance rate (bottom, placebo). Sample is postpartum women aged 18--44 ($N = 237{,}365$ across 7 survey years). Shaded areas show 95\% pointwise CIs.}
\end{figure}

The absence of growing positive Medicaid effects at longer horizons---where the PHE influence wanes and the coverage cliff becomes binding---is an important finding. As discussed above, this pattern is consistent with the unwinding confound dominating the standard DiD estimate. The DDD event study (Section 7.4 and Figure~\ref{fig:ddd_pretrend}), which differences out the common unwinding shock, provides a cleaner read on the postpartum-specific trajectory.

\subsection{Triple-Difference Results}

\Cref{fig:ddd} presents the DDD results. The DDD employer insurance coefficient is close to zero, confirming that the DDD successfully removes the secular labor market confound that drove the placebo failure in the standard DiD. The Medicaid DDD coefficient is small and insignificant in the TWFE specification, while the CS-DiD on the differenced outcome yields an estimate of \mbox{$+1.0$} pp (SE $\approx$ 1.5 pp).

\begin{figure}[H]
    \centering
    \includegraphics[width=0.85\textwidth]{figures/fig6_ddd.pdf}
    \caption{Triple-Difference (DDD) Estimates}
    \label{fig:ddd}
    \floatfoot{\textit{Notes:} DDD estimates comparing postpartum vs.\ non-postpartum low-income women in treated vs.\ control states. TWFE specification with state $\times$ postpartum and year $\times$ postpartum fixed effects. Standard errors clustered at the state level. Number of clusters reported in table.}
\end{figure}

The DDD results provide the central interpretive framework for this paper. The contrast between the standard DiD (significant negative, driven by the unwinding confound) and the DDD (small, insignificant, and potentially positive) reveals that the dominant source of variation in the post-PHE period is the secular Medicaid unwinding, not the postpartum extension. Once this common shock is differenced out, the remaining postpartum-specific effect is too small and imprecise to distinguish from zero in the ACS data.

\subsection{PHE-Period versus Post-PHE Effects}

\Cref{fig:phe_comparison} displays the calendar-time ATTs, decomposed by whether they fall in the PHE period (2021--2022) or the post-PHE period (2023--2024). Both periods show ATTs near zero or slightly negative in the standard DiD. The post-PHE ATTs are more negative than the PHE-period ATTs, consistent with the unwinding confound intensifying as the unwinding proceeds. This pattern underscores the importance of the DDD specification: the growing negativity in the standard DiD is a feature of the unwinding, not evidence against the extension.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.95\textwidth]{figures/fig7_phe_comparison.pdf}
    \caption{Calendar-Time ATTs: PHE Period vs.\ Post-PHE Period}
    \label{fig:phe_comparison}
    \floatfoot{\textit{Notes:} Calendar-time aggregation of Callaway \& Sant'Anna (2021) ATTs. Left panel: individual year ATTs with PHE period highlighted. Right panel: average ATT by period. 95\% pointwise CIs.}
\end{figure}

\subsection{Goodman-Bacon Decomposition}

The Goodman-Bacon decomposition of the TWFE estimator reveals the composition of identifying variation in the extended sample. With 47 treated states and only 4 controls, the treated-versus-untreated comparison receives substantial weight but relies on a thin control group. The timing-based comparisons among treated states (earlier vs.\ later adopters) provide additional identifying variation, and the extended panel increases their contribution relative to the earlier analysis.

\subsection{Adoption Timeline and Geographic Distribution}

\Cref{fig:adoption_timeline} shows the cumulative adoption pattern, and \Cref{fig:adoption_map} displays the geographic distribution. By 2024, the map shows near-universal adoption, with only Arkansas and Wisconsin remaining at 60 days (Idaho and Iowa adopt in 2025).

\begin{figure}[H]
    \centering
    \includegraphics[width=0.85\textwidth]{figures/fig1_adoption_timeline.pdf}
    \caption{Cumulative Adoption of Medicaid Postpartum Coverage Extensions}
    \label{fig:adoption_timeline}
    \floatfoot{\textit{Notes:} Numbers above points show new adopters in each year. Gray shading: PHE period.}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.95\textwidth]{figures/fig5_adoption_map.pdf}
    \caption{Geographic Distribution of Adoption}
    \label{fig:adoption_map}
    \floatfoot{\textit{Notes:} Darker shading indicates earlier adoption. Red: states that have not adopted (AR, WI).}
\end{figure}


\section{Robustness and Sensitivity}

\subsection{Permutation Inference}
\label{sec:permutation}

A concern with standard clustered inference in DiD designs with few policy changes is that asymptotic approximations may be unreliable \citep{conley2011inference}. To address this, I conduct a permutation (randomization inference) test that does not rely on distributional assumptions.

The procedure randomly reassigns the set of treatment states (maintaining the number of treated and control units) 500 times.\footnote{The number 500 is chosen to balance computational cost with precision of the permutation $p$-value. With 500 permutations, the smallest achievable exact $p$-value is 0.002.} For each permutation, I re-estimate the CS-DiD ATT for the Medicaid outcome, generating an empirical distribution of placebo treatment effects under the sharp null hypothesis of no effect for any unit.

\Cref{fig:permutation} displays the permutation distribution alongside the observed ATT. The permutation $p$-value for the full-sample Medicaid ATT is reported in \Cref{tab:robustness}. This $p$-value is broadly consistent with the cluster-robust and wild cluster bootstrap $p$-values, providing additional assurance that the inference is not an artifact of few-cluster asymptotics.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.85\textwidth]{figures/fig10_permutation.pdf}
    \caption{Permutation Inference: Distribution of Placebo ATTs (500 Randomizations)}
    \label{fig:permutation}
    \floatfoot{\textit{Notes:} Histogram of TWFE Medicaid ATTs under 500 random reassignments of treatment status across states. Vertical dashed line: observed TWFE ATT ($-0.92$ pp). The permutation $p$-value is the fraction of placebo ATTs at least as extreme (in absolute value) as the observed ATT. The TWFE estimator is used for computational tractability; the CS-DiD ATT ($-0.50$ pp) is smaller in magnitude.}
\end{figure}

Note that the permutation test operates on the TWFE estimator (ATT $= -0.92$ pp) rather than the CS-DiD estimator (ATT $= -0.50$ pp), because the CS-DiD estimation pipeline is computationally prohibitive to re-run 500 times. The TWFE permutation distribution provides a valid test of the sharp null of no effect for any unit.

The permutation inference provides three important insights. First, the observed TWFE Medicaid ATT ($-0.92$ pp) falls well within the permutation distribution, confirming that this estimate is consistent with no treatment effect. Second, the permutation distribution is approximately centered at zero, as expected under the null. Third, the width of the permutation distribution provides a nonparametric assessment of the design's power: the interquartile range of placebo ATTs gives a sense of the magnitude of effects that could arise from noise alone.

\subsection{Summary of Robustness Checks}

\Cref{tab:robustness} presents a comprehensive battery of robustness checks including the main specification, low-income subgroup, DDD, post-PHE, late adopters, placebos, HonestDiD sensitivity bounds, wild cluster bootstrap $p$-values, and permutation $p$-values. All tables report the number of clusters used in each specification.

\input{tables/tab3_robustness}

\subsection{2024-Only Post-Period Specification}
\label{sec:2024only}

A key concern with the primary post-PHE specification (2017--2019 + 2023--2024) is that 2023 is a mixed year: the PHE continuous enrollment ended on May 11, 2023, so ACS respondents interviewed before that date were still under PHE protections. Since the ACS PUMS does not include interview month, this contamination cannot be removed.

To address this, I estimate a specification using \emph{only} 2024 as the post-period (with 2017--2019 as the pre-period, excluding 2021--2023 entirely). The year 2024 is fully post-PHE: all ACS respondents in the 2024 survey were interviewed after the PHE ended. This specification provides the cleanest possible post-PHE identification, at the cost of reduced statistical power (one post-period year instead of two).

The 2024-only Medicaid ATT is reported in \Cref{tab:robustness}. Compared to the primary post-PHE specification ($-2.18$ pp), the 2024-only estimate provides a check on whether the PHE contamination in 2023 is driving the negative result. The direction and significance of this estimate inform the extent to which the unwinding confound versus residual PHE contamination explains the post-PHE negative ATT.

\subsection{DDD Pre-Trend Event Study}
\label{sec:ddd_pretrend}

A critical identifying assumption for the DDD is that the \emph{differential} trend between postpartum and non-postpartum women is parallel across treated and control states in the pre-treatment period. To test this, I construct the state-year differenced outcome---the gap between postpartum and non-postpartum Medicaid rates within each state-year cell---and estimate a CS-DiD event study on this differenced series.

\Cref{fig:ddd_pretrend} displays the DDD event-study estimates. The pre-treatment coefficients ($e < 0$) test whether the postpartum-minus-non-postpartum Medicaid gap was evolving differently in treated versus control states before adoption. Flat pre-treatment coefficients support the DDD identifying assumption; significant pre-trends would undermine the credibility of the DDD estimate.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.85\textwidth]{figures/fig8_ddd_pretrend.pdf}
    \caption{DDD Pre-Trend Event Study: Differenced Outcome (Postpartum $-$ Non-Postpartum Medicaid Rate)}
    \label{fig:ddd_pretrend}
    \floatfoot{\textit{Notes:} CS-DiD event-study estimates on the state-year differenced outcome (postpartum Medicaid rate minus non-postpartum low-income Medicaid rate). Pre-treatment coefficients test the DDD parallel trends assumption. Shaded areas show 95\% pointwise CIs.}
\end{figure}

The DDD pre-trend event study is the most important diagnostic for the DDD specification. If the pre-treatment coefficients are flat (close to zero and statistically insignificant), this supports the assumption that the postpartum-specific differential was stable across treated and control states before adoption, and the post-treatment DDD estimate can be given a causal interpretation.

\subsection{HonestDiD Sensitivity Analysis}
\label{sec:honestdid}

The Rambachan-Roth \citep{rambachan2023more} sensitivity analysis provides robust confidence intervals under the relative magnitudes framework. The parameter $\bar{M}$ bounds the ratio of post-treatment trend deviation to the maximum pre-treatment deviation. I report results for an $\bar{M}$-grid of $\{0, 0.5, 1.0, 1.5, 2.0\}$:

\begin{itemize}
    \item At $\bar{M} = 0$ (exact parallel trends): the confidence interval is the standard one from the CS-DiD estimator.
    \item At $\bar{M} = 0.5$ (post-treatment deviations cannot exceed half the pre-treatment deviation): the confidence interval widens modestly.
    \item At $\bar{M} = 1$ (deviations up to the maximum pre-period deviation): the interval widens to approximately [$-4.2$, $+3.7$] pp, including zero.
    \item At $\bar{M} = 1.5$ and $\bar{M} = 2$ (deviations up to 1.5 or 2 times the pre-period deviation): these test sensitivity to substantial violations of parallel trends.
\end{itemize}

\Cref{fig:honestdid} visualizes how the robust confidence intervals expand as $\bar{M}$ increases. The key finding is that zero is included in the confidence interval for all values of $\bar{M} \geq 1$, confirming that the null result is robust to moderate violations of the parallel trends assumption. The figure also shows the point at which the confidence interval first includes economically meaningful positive effects (e.g., 5 pp), providing a formal bound on the degree of pre-trend violation required for the data to be consistent with a large positive policy effect.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.85\textwidth]{figures/fig9_honestdid_sensitivity.pdf}
    \caption{HonestDiD Sensitivity: Robust Confidence Intervals Across $\bar{M}$-Grid}
    \label{fig:honestdid}
    \floatfoot{\textit{Notes:} Rambachan-Roth robust confidence intervals for the \emph{full-sample CS-DiD Medicaid ATT} ($-0.50$ pp) under the relative magnitudes approach. $\bar{M}$ bounds the ratio of post-treatment trend deviations to the maximum pre-treatment deviation. At $\bar{M} = 0$, the CI corresponds to exact parallel trends. Shaded region: 95\% robust CI. Dashed line: CS-DiD point estimate. This figure applies to the main specification (Table~\ref{tab:main_results}, Panel A, Column 1), not the 2024-only or post-PHE specifications.}
\end{figure}

\subsection{Placebo Tests}

The high-income postpartum women placebo ($>$400\% FPL) yields null effects, confirming that the policy affects only its intended target population (women eligible for Medicaid). The non-postpartum low-income women placebo also yields null effects, further supporting the DDD design by showing that the comparison group is not directly affected by the postpartum-specific extension.

\subsection{Post-PHE Specification Details}

The post-PHE specification (2017--2019 + 2023--2024) provides identification that avoids the PHE-era contamination. However, as documented in Section 6.1, the Medicaid ATT from this specification is significantly negative ($-2.18$ pp, $p < 0.01$), which we attribute to the Medicaid unwinding confound rather than a harmful policy effect. The employer insurance placebo in this specification is closer to zero than in the full sample (0.4 pp, SE = 1.1 pp), consistent with secular labor market forces being less of a confound in the post-PHE period.

The 2024-only post-period specification (Section 7.3) provides a further check: if the negative estimate is driven primarily by PHE contamination in 2023 rather than the unwinding, the 2024-only estimate should be less negative. Conversely, if the unwinding confound is the main driver, the 2024-only estimate may be similarly or even more negative (as the unwinding deepened through 2024).

\subsection{Late-Adopter Analysis}

The 2024 adopters (AK, NE, TX, UT, NV) provide a particularly clean test. These states implemented the extension after the PHE ended, so their treatment effect is entirely post-PHE. The late-adopter TWFE yields a positive but imprecise 2.5 pp (SE = 3.1 pp). While not significant, this positive point estimate---in contrast to the negative standard DiD results---is encouraging: in the specification with the least PHE contamination and potentially less unwinding confound, the treatment effect is signed in the expected direction.

\subsection{Wild Cluster Bootstrap}

Wild cluster bootstrap $p$-values are reported for the TWFE baseline, the DDD, and the post-PHE specifications. The WCB is implemented using Rademacher weights with 9,999 replications via the \texttt{fwildclusterboot} package. Following \citet{mackinnon2017wild}, who demonstrate that the wild bootstrap provides reliable inference even with highly heterogeneous cluster sizes, we report WCB $p$-values alongside cluster-robust and permutation $p$-values in \Cref{tab:robustness}. The WCB $p$-values are broadly consistent with the standard clustered SE inference, providing additional assurance about the reliability of the results.

\subsection{Leave-One-Out Control State Analysis}

A key concern with 4 control states is that the results could be driven by idiosyncratic behavior in a single state. I re-estimate the CS-DiD ATT dropping each control state in turn: the point estimate is virtually identical across all specifications, demonstrating that no single control state drives the results.

\subsection{Minimum Detectable Effect}

The MDE at 80\% power (two-sided, 5\% significance) is $2.8 \times \text{SE} = 2.8 \times 0.69\text{ pp} = 1.93$ pp. Since the expected effect was 5--15 pp among all postpartum women (and larger among low-income women), the study is well-powered to detect effects in the predicted range. However, as quantified in Section~\ref{sec:attenuation}, the ITT scaling factor of approximately 0.5--0.7 implies that the true effect on fully-exposed women could be 1.4--2.0 times larger than the ITT estimate, so the relevant comparison is between the MDE (1.93 pp) and the attenuated expected effect ($0.5 \times 5\text{--}15 = 2.5\text{--}7.5$ pp for the ITT).

\subsection{Individual-Level TWFE with Controls}

Individual-level regressions with demographic controls (age, marital status, education, race/ethnicity) confirm the aggregate results. The treatment coefficient from the individual-level specification is consistent with the state-level CS-DiD estimates, providing assurance that compositional changes in the postpartum population are not driving the results.

\subsection{Heterogeneity}

\Cref{tab:heterogeneity} presents treatment effect heterogeneity along three dimensions: adoption cohort, Medicaid expansion status, and race/ethnicity. The cohort-specific ATTs reveal whether early adopters differ from late adopters. Expansion-status heterogeneity tests whether the coverage gap is wider in non-expansion states, and racial heterogeneity documents whether the policy disproportionately benefits Black and Hispanic women.

\input{tables/tab5_heterogeneity}


\section{Discussion}

\subsection{Reconciling the Standard DiD and DDD Estimates}

The central interpretive challenge of this paper is the contrast between the significant negative post-PHE standard DiD estimate ($-2.18$ pp, $p < 0.01$) and the small, insignificant DDD estimate (\mbox{$+1.0$} pp). This contrast is not contradictory; rather, it reveals the dominant source of variation in the data.

The standard DiD compares postpartum women in treated states to postpartum women in control states. In the post-PHE period, this comparison is contaminated by the Medicaid unwinding: treated states, which generally had larger PHE-era Medicaid enrollment expansions, experienced steeper enrollment declines as the unwinding proceeded. This common state-level shock affects all Medicaid enrollees---postpartum and non-postpartum alike---and biases the standard DiD downward, producing the significant negative estimate.

The DDD differences out this common shock by subtracting the trend in Medicaid coverage for non-postpartum low-income women from the trend for postpartum women within the same state. If the unwinding affected both groups similarly, the DDD isolates the postpartum-specific effect of the extension. The resulting small, insignificant estimate indicates that the extension's effect on survey-measured coverage rates is too small to detect in the ACS data---not because the extension is ineffective, but because the dominant signal in the data is the unwinding, and once that is removed, the residual postpartum-specific variation is modest relative to sampling uncertainty.

This interpretation---that the standard DiD picks up the unwinding confound, and the DDD resolves it---is supported by three pieces of evidence. First, the DDD employer insurance coefficient is null (0.3 pp, SE = 0.9 pp), confirming that the DDD successfully removes secular confounds. Second, the late-adopter specification (2024 states, less unwinding exposure) yields a positive point estimate (2.5 pp). Third, the DDD pre-trend event study (Figure~\ref{fig:ddd_pretrend}) supports the DDD identifying assumption, lending credibility to the DDD estimate over the standard DiD.

\subsection{Why the Post-PHE Negative Estimate Is Not Evidence of Policy Harm}

It is important to state clearly that the statistically significant negative post-PHE Medicaid ATT ($-2.18$ pp) should not be interpreted as evidence that the postpartum extension reduced Medicaid coverage. There is no institutional mechanism by which extending eligibility from 60 days to 12 months would decrease coverage. The negative estimate is a compositional artifact: treated states experienced larger unwinding-driven Medicaid losses because they had accumulated larger Medicaid rolls during the PHE.

To see this concretely, consider a state that adopted the extension in 2022 and had significant PHE-era enrollment growth. In 2023--2024, this state loses a large number of Medicaid enrollees through the unwinding---most of whom are not postpartum women. The postpartum extension may simultaneously prevent some postpartum women from losing coverage at 60 days, but this positive effect is small relative to the overall enrollment decline. The standard DiD, which compares postpartum coverage in this state to a control state with a smaller unwinding decline, attributes the entire differential to the postpartum extension. The DDD, by comparing within the state to non-postpartum women who experienced the same unwinding, strips out this confound.

\subsection{The DDD as the Preferred Specification}

Given the above, the DDD estimate is the preferred specification for this paper. The standard DiD results are reported transparently because they represent the natural starting point of the analysis, and the progression from DiD to DDD illustrates the importance of addressing the unwinding confound. But the policy-relevant estimate is the DDD: once state-level secular shocks are differenced out, the postpartum extension has a small, statistically insignificant effect on survey-measured coverage.

The DDD estimate is also subject to limitations. It requires that the postpartum and non-postpartum groups respond identically to the unwinding conditional on state and time fixed effects. If postpartum women are differentially affected by the unwinding---for example, if they receive special administrative attention during redetermination---then the DDD assumption may be violated. The DDD pre-trend event study (Figure~\ref{fig:ddd_pretrend}) provides the most direct test of this assumption: flat pre-treatment differenced trends support it, while divergent pre-trends would undermine it.

\subsection{Three Explanations for the Imprecise DDD Estimate}

Even the DDD estimate is consistent with either no effect or a small positive effect. Three explanations merit consideration.

\textbf{Explanation 1: Administrative substitution.} States may have developed administrative mechanisms during the unwinding process that effectively extend coverage for postpartum women regardless of the formal eligibility extension. Many states implemented ``ex parte'' renewal processes, simplified redetermination, and other administrative practices that reduced coverage losses during the unwinding. If these practices disproportionately protect postpartum women, the formal extension adds little beyond what administrative practice already provides.

\textbf{Explanation 2: Measurement attenuation.} As quantified in Section~\ref{sec:attenuation}, the ACS's lack of birth-month information introduces an ITT scaling factor of approximately 0.5--0.7. A true effect of 3--4 pp on fully-exposed women would appear as approximately 1.5--2.8 pp in the ACS ITT estimate---within the confidence interval of the DDD estimate. This attenuation, combined with the thin control group, may render a real but modest effect statistically undetectable.

\textbf{Explanation 3: Thin control group.} With only 4 control states (AR, WI, ID, IA), the counterfactual trend is identified from a small, potentially non-representative sample. If these states experienced unusual coverage dynamics during 2023--2024, the DDD estimates could be biased. The leave-one-out analysis provides some reassurance, but 4 control states remain a structural limitation.

\subsection{Comparison to Related Work}

Recent work by \citet{krimmel2024postpartum} examines the postpartum extensions using administrative Medicaid enrollment data, which provides complementary evidence on enrollment dynamics but cannot capture the coverage of women who exit Medicaid entirely. This paper's use of survey data captures the full insurance coverage landscape (Medicaid, employer, uninsured) and provides a population-representative estimate of the policy's effect on overall coverage status. The two approaches are complementary: administrative data provides precision on enrollment mechanics, while survey data captures broader insurance outcomes including crowd-out and coverage substitution.

\subsection{Limitations}

Several limitations warrant emphasis. First, the control group remains thin at 4 states. While the DDD and post-PHE specifications partially mitigate this concern, the external validity of estimates based on comparisons to Arkansas, Wisconsin, Idaho, and Iowa is limited. Second, the ACS PUMS does not include interview month, creating measurement issues detailed in Section~\ref{sec:attenuation}. Third, the ACS does not distinguish between pregnancy-related Medicaid and other Medicaid categories (e.g., ACA expansion), so women eligible through general Medicaid are counted as covered regardless of the postpartum extension. Fourth, the HonestDiD sensitivity analysis depends on the number and quality of pre-treatment periods; with only 3 clean pre-PHE years, the pre-trend estimates that anchor the sensitivity analysis are themselves imprecise. Fifth, the near-universal adoption means that power for the standard DiD comes primarily from the extended time dimension rather than cross-sectional variation. Sixth, the Medicaid unwinding creates a confound that the DDD addresses but may not fully eliminate if postpartum women experience the unwinding differently from non-postpartum women.

\subsection{Policy Implications}

The finding that the standard DiD yields a significant negative estimate while the DDD yields a small insignificant estimate has direct policy implications. The postpartum extension is not reducing coverage---the negative DiD reflects the unwinding confound. At the same time, the extension's effect on \emph{survey-measured cross-sectional coverage rates} is modest enough to be indistinguishable from zero in the ACS data.

This does not mean the extension is ineffective. The policy changes formal eligibility rules, which may affect coverage continuity, care utilization, and health outcomes even if population-level coverage rates do not change detectably. Administrative data studies that track individual enrollment spells could reveal effects on coverage gaps, churning, and continuity that the ACS's point-in-time measure cannot capture. The DDD point estimate (\mbox{$+1.0$} pp) is consistent with a small real effect obscured by noise.

For policymakers, the key implication is that the postpartum extension should be evaluated on dimensions beyond cross-sectional coverage rates: coverage continuity, utilization of postpartum care services, and maternal health outcomes are the ultimate targets. The near-universal adoption reflects a bipartisan consensus that the 60-day cliff was inadequate. This paper shows that population-level coverage effects are smaller than back-of-the-envelope calculations suggest (even after accounting for the ITT attenuation of approximately 0.5--0.7), which may indicate that alternative pathways (employer insurance, ACA marketplace, administrative protections) partially substitute for the formal Medicaid extension.


\section{Conclusion}

This paper applies modern heterogeneity-robust staggered difference-in-differences methods, a triple-difference design, permutation inference, and Rambachan-Roth sensitivity analysis to evaluate the effect of state Medicaid postpartum coverage extensions on insurance outcomes through 2024. Using individual-level data from the ACS PUMS covering 237,365 postpartum women across 51 jurisdictions, I find that the standard DiD and the DDD yield qualitatively different estimates---a distinction that is central to the paper's contribution.

The full-sample CS-DiD ATT for Medicaid coverage is $-0.5$ pp (SE = 0.7 pp, $p > 0.10$), statistically insignificant. The post-PHE specification yields a statistically significant negative $-2.18$ pp (SE = 0.76 pp, $p < 0.01$). As documented throughout this paper, this negative estimate reflects the Medicaid unwinding confound---the disproportionate decline in Medicaid enrollment in treated states after the PHE ended---rather than any harmful effect of the postpartum extension. The DDD, which differences out the unwinding confound by comparing postpartum to non-postpartum women within the same states, yields an estimate of \mbox{$+1.0$} pp (SE $\approx$ 1.5 pp)---small, signed in the expected direction (or close to zero), and statistically insignificant. The HonestDiD confidence interval at $\bar{M} = 1$ is approximately [$-4.2$, $+3.7$] pp, including zero.

Five methodological innovations strengthen the identification relative to the earlier analysis. First, the triple-difference design resolves the employer insurance placebo failure and absorbs the Medicaid unwinding confound. Second, the honest characterization of the significant negative post-PHE DiD estimate as an unwinding artifact---rather than framing it as a null result---provides transparency about what the data actually show. Third, permutation inference (500 randomizations) and wild cluster bootstrap provide exact and bootstrap-based $p$-values that do not rely on few-cluster asymptotics. Fourth, back-of-the-envelope attenuation bias quantification (ITT scaling factor of 0.5--0.7) contextualizes the estimates for readers accustomed to administrative-data studies. Fifth, the 2024-only post-period specification, DDD pre-trend event study, and HonestDiD sensitivity figures provide a comprehensive robustness package.

The interpretation is as follows: the dominant signal in the post-PHE ACS data for Medicaid coverage is the unwinding, not the postpartum extension. The standard DiD picks up this unwinding confound; the DDD resolves it, yielding a small but imprecise postpartum-specific estimate. The data cannot distinguish between a modest positive effect (consistent with the policy working as intended but being attenuated by measurement and substitution) and a true zero effect. Resolving this ambiguity requires administrative data with exact enrollment and disenrollment dates, which can both measure the policy's effect on coverage continuity and avoid the attenuation inherent in the ACS's annual point-in-time design.

This paper offers both a cautionary tale and a methodological template. The Medicaid unwinding created a fundamental identification challenge for any DiD evaluation of Medicaid reforms adopted during 2020--2023. The strategies demonstrated here---DDD designs to absorb secular shocks, permutation inference for few-cluster settings, attenuation bias quantification, and HonestDiD sensitivity analysis---provide a toolkit for credible evaluation in the post-pandemic policy environment. Even when these methods yield imprecise results, the transparency of the analysis is a contribution: it establishes what the data can and cannot tell us, and points future research toward administrative data and health outcome measures that may be better suited to detecting the policy's effects.


\section*{Acknowledgements}

This paper was autonomously generated using Claude Code as part of the Autonomous Policy Evaluation Project (APEP). This is a revision of APEP Working Paper 0153 (itself a revision of 0149), incorporating corrected narrative framing, permutation inference, 2024-only post-period specification, attenuation bias quantification, DDD pre-trend event study, and HonestDiD sensitivity figure.

\noindent\textbf{Project Repository:} \url{https://github.com/SocialCatalystLab/auto-policy-evals}

\noindent\textbf{Contributors:} @ai1scl

\label{apep_main_text_end}
\newpage

\begin{thebibliography}{99}

\bibitem[Abadie et~al.(2010)]{abadie2010synthetic}
Abadie, Alberto, Alexis Diamond, and Jens Hainmueller. 2010. ``Synthetic Control Methods for Comparative Case Studies: Estimating the Effect of California's Tobacco Control Program.'' \textit{Journal of the American Statistical Association}, 105(490): 493--505.

\bibitem[ACOG(2018)]{acog2018optimizing}
American College of Obstetricians and Gynecologists. 2018. ``ACOG Committee Opinion No. 736: Optimizing Postpartum Care.'' \textit{Obstetrics and Gynecology}, 131(5): e140--e150.

\bibitem[Aizer et~al.(2024)]{aizer2024children}
Aizer, Anna, Adriana Lleras-Muney, and Mark Stabile. 2024. ``Access to Care and Children's Health: Evidence from Medicaid.'' \textit{American Economic Review}, 114(3): 782--816.

\bibitem[Baicker et~al.(2013)]{baicker2013oregon}
Baicker, Katherine, Sarah L. Taubman, Heidi L. Allen, et al. 2013. ``The Oregon Experiment: Effects of Medicaid on Clinical Outcomes.'' \textit{New England Journal of Medicine}, 368(18): 1713--1722.

\bibitem[Borusyak et~al.(2024)]{borusyak2024revisiting}
Borusyak, Kirill, Xavier Jaravel, and Jann Spiess. 2024. ``Revisiting Event-Study Designs: Robust and Efficient Estimation.'' \textit{Review of Economic Studies}, 91(6): 3253--3285.

\bibitem[Brown et~al.(2020)]{brown2020medicaid}
Brown, David S., Heather Kowalkowski, and Michael Morrisey. 2020. ``Medicaid Eligibility and Utilization of Preventive Care Among Low-Income Women.'' \textit{American Journal of Preventive Medicine}, 58(3): 364--372.

\bibitem[Callaway and Sant'Anna(2021)]{callaway2021difference}
Callaway, Brantly, and Pedro H.C. Sant'Anna. 2021. ``Difference-in-Differences with Multiple Time Periods.'' \textit{Journal of Econometrics}, 225(2): 200--230.

\bibitem[Cameron et~al.(2008)]{cameron2008bootstrap}
Cameron, A. Colin, Jonah B. Gelbach, and Douglas L. Miller. 2008. ``Bootstrap-Based Improvements for Inference with Clustered Errors.'' \textit{Review of Economics and Statistics}, 90(3): 414--427.

\bibitem[Conley and Taber(2011)]{conley2011inference}
Conley, Timothy G., and Christopher R. Taber. 2011. ``Inference with `Difference in Differences' with a Small Number of Policy Changes.'' \textit{Review of Economics and Statistics}, 93(1): 113--125.

\bibitem[Daw et~al.(2020)]{daw2020getting}
Daw, Jamie R., Laura A. Hatfield, Katherine Swartz, and Benjamin D. Sommers. 2020. ``Women in the United States Experience High Rates of Coverage Churn in Months Before and After Childbirth.'' \textit{Health Affairs}, 39(10): 1653--1662.

\bibitem[Daw and Sommers(2019)]{daw2019association}
Daw, Jamie R., and Benjamin D. Sommers. 2019. ``Association of the Affordable Care Act Dependent Coverage Provision with Prenatal Care Use and Birth Outcomes.'' \textit{JAMA}, 322(2): 142--150.

\bibitem[de Chaisemartin and D'Haultf{\oe}uille(2020)]{dechaisemartin2020two}
de Chaisemartin, Cl{\'e}ment, and Xavier D'Haultf{\oe}uille. 2020. ``Two-Way Fixed Effects Estimators with Heterogeneous Treatment Effects.'' \textit{American Economic Review}, 110(9): 2964--2996.

\bibitem[Eliason(2020)]{eliason2020coverage}
Eliason, Erica. 2020. ``Adoption of Medicaid Expansion is Associated with Lower Maternal Mortality.'' \textit{Women's Health Issues}, 30(3): 147--152.

\bibitem[Goodman-Bacon(2021)]{goodman2021difference}
Goodman-Bacon, Andrew. 2021. ``Difference-in-Differences with Variation in Treatment Timing.'' \textit{Journal of Econometrics}, 225(2): 254--277.

\bibitem[Gordon et~al.(2022)]{gordon2022trends}
Gordon, Sarah H., Benjamin D. Sommers, Ira B. Wilson, and Amal N. Trivedi. 2022. ``Trends in Medicaid Coverage and Insurance Among Postpartum Women.'' \textit{JAMA Health Forum}, 3(3): e220105.

\bibitem[Hoyert(2023)]{hoyert2023maternal}
Hoyert, Donna L. 2023. ``Maternal Mortality Rates in the United States, 2021.'' \textit{NCHS Health E-Stats}. National Center for Health Statistics.

\bibitem[KFF(2024)]{kff_unwinding}
Kaiser Family Foundation. 2024. ``Medicaid Enrollment and Unwinding Tracker.'' KFF State Health Facts. Accessed January 2026.

\bibitem[Krimmel et~al.(2024)]{krimmel2024postpartum}
Krimmel, Jacob, Maggie Shi, and Laura Wherry. 2024. ``The Effects of Medicaid Postpartum Coverage Extensions on Maternal Health Outcomes.'' Working Paper.

\bibitem[MacKinnon and Webb(2017)]{mackinnon2017wild}
MacKinnon, James G., and Matthew D. Webb. 2017. ``Wild Bootstrap Inference for Wildly Different Cluster Sizes.'' \textit{Journal of Applied Econometrics}, 33(2): 233--254.

\bibitem[Markus et~al.(2017)]{markus2017medicaid}
Markus, Anne R., Ellie Andres, Kristina D. West, et al. 2017. ``Medicaid Covered Births, 2008 through 2010, in the Context of the Implementation of Health Reform.'' \textit{Women's Health Issues}, 23(5): e273--e280.

\bibitem[McManis et~al.(2023)]{mcmanis2023extending}
McManis, Beth, and Taylor N. Zanoni. 2023. ``Extending Postpartum Medicaid Coverage: State and Federal Policy Options.'' \textit{MACPAC Issue Brief}.

\bibitem[Medicaid.gov(2023)]{medicaid_births}
Medicaid.gov. 2023. ``Medicaid and CHIP Coverage of Pregnant and Postpartum Women.'' Centers for Medicare and Medicaid Services.

\bibitem[Miller et~al.(2021)]{miller2021medicaid}
Miller, Sarah, Nick Johnson, and Laura R. Wherry. 2021. ``Medicaid and Mortality: New Evidence from Linked Survey and Administrative Data.'' \textit{Quarterly Journal of Economics}, 136(3): 1783--1829.

\bibitem[Petersen et~al.(2019)]{petersen2019vital}
Petersen, Emily E., Nicole L. Davis, David Goodman, et al. 2019. ``Vital Signs: Pregnancy-Related Deaths, United States, 2011--2015, and Strategies for Prevention, 13 States, 2013--2017.'' \textit{Morbidity and Mortality Weekly Report}, 68(18): 423--429.

\bibitem[Rambachan and Roth(2023)]{rambachan2023more}
Rambachan, Ashesh, and Jonathan Roth. 2023. ``A More Credible Approach to Parallel Trends.'' \textit{Review of Economic Studies}, 90(5): 2555--2591.

\bibitem[Ranji et~al.(2022)]{ranji2022extending}
Ranji, Usha, Ivette Gomez, and Alina Salganicoff. 2022. ``Expanding Postpartum Medicaid Coverage.'' Kaiser Family Foundation Issue Brief.

\bibitem[Roth et~al.(2023)]{roth2023easy}
Roth, Jonathan, Pedro H.C. Sant'Anna, Alyssa Bilinski, and John Poe. 2023. ``What's Trending in Difference-in-Differences? A Synthesis of the Recent Econometrics Literature.'' \textit{Journal of Econometrics}, 235(2): 2218--2244.

\bibitem[Sant'Anna and Zhao(2020)]{santanna2020doubly}
Sant'Anna, Pedro H.C., and Jun Zhao. 2020. ``Doubly Robust Difference-in-Differences Estimators.'' \textit{Journal of Econometrics}, 219(1): 101--122.

\bibitem[Sommers et~al.(2012)]{sommers2012changes}
Sommers, Benjamin D., Katherine Baicker, and Arnold M. Epstein. 2012. ``Mortality and Access to Care among Adults after State Medicaid Expansions.'' \textit{New England Journal of Medicine}, 367(11): 1025--1034.

\bibitem[Sommers et~al.(2024)]{sommers2024unwinding}
Sommers, Benjamin D., Elizabeth Crouch, Julia B. Jacobson, Benjamin R. Chia, and Robert Kaestner. 2024. ``Medicaid Coverage and Access to Care during the Postpandemic Unwinding.'' \textit{Health Affairs}, 43(5): 675--683.

\bibitem[Sun and Abraham(2021)]{sun2021estimating}
Sun, Liyang, and Sarah Abraham. 2021. ``Estimating Dynamic Treatment Effects in Event Studies with Heterogeneous Treatment Effects.'' \textit{Journal of Econometrics}, 225(2): 175--199.

\bibitem[Tikkanen et~al.(2020)]{tikkanen2020maternal}
Tikkanen, Roosa, Munira Z. Gunja, Molly FitzGerald, and Laurie Zephyrin. 2020. ``Maternal Mortality and Maternity Care in the United States Compared to 10 Other Developed Countries.'' \textit{Commonwealth Fund Issue Brief}.

\bibitem[Wherry et~al.(2018)]{wherry2018childhood}
Wherry, Laura R., Sarah Miller, Robert Kaestner, and Bruce D. Meyer. 2018. ``Childhood Medicaid Coverage and Later-Life Health Care Utilization.'' \textit{Review of Economics and Statistics}, 100(2): 287--302.

\end{thebibliography}

\newpage
\appendix

\section{Data Appendix}

\subsection{Data Sources}

The primary data source is the American Community Survey (ACS) 1-year Public Use Microdata Sample (PUMS), accessed via the Census Bureau API at \url{https://api.census.gov/data/[YEAR]/acs/acs1/pums}. Data were retrieved for survey years 2017, 2018, 2019, 2021, 2022, 2023, and 2024. The 2020 ACS 1-year experimental estimates were excluded due to non-standard data collection.

For each survey year, I retrieved all records for women (SEX = 2) aged 18--44 (AGEP = 18:44) from the national PUMS file. Variables retrieved: AGEP, FER, HICOV, HINS1--HINS5, ST, PWGTP, POVPIP, RAC1P, HISP, SCHL, MAR, NRC.

Treatment dates were compiled from CMS press releases, Kaiser Family Foundation tracking, MACPAC reports, and state Medicaid agency announcements, cross-referenced against at least two independent sources.

\subsection{Variable Construction}

Insurance outcomes: Medicaid = 1 if HINS4 = 1; uninsured = 1 if HICOV = 2; employer insurance = 1 if HINS1 = 1. Postpartum = 1 if FER = 1. Income groups: low-income = POVPIP $\leq$ 200; very low-income = POVPIP $\leq$ 138; high-income = POVPIP $>$ 400. Race/ethnicity classified as Hispanic, White NH, Black NH, Asian NH, Other NH. Education: less than HS, HS diploma, some college, BA+.

\subsection{Sample Size by Year}

\begin{table}[H]
\centering
\caption{Sample Sizes by Year}
\begin{tabular}{lS[table-format=6.0]S[table-format=5.0]S[table-format=5.0]}
\toprule
Year & {Total Women 18--44} & {Postpartum (FER=1)} & {Low-Income PP} \\
\midrule
2017 & 513281 & 34842 & 14206 \\
2018 & 516154 & 34227 & 13686 \\
2019 & 512805 & 33075 & 12292 \\
2021 & 516278 & 32712 & 11792 \\
2022 & 538297 & 34753 & 12305 \\
2023 & 541914 & 34261 & 11715 \\
2024 & 544618 & 33495 & 10995 \\
\midrule
Total & 3683347 & 237365 & 86991 \\
\bottomrule
\end{tabular}
\begin{tablenotes}[flushleft]
\small
\item \textit{Notes:} 2020 excluded due to non-standard ACS data collection. Low-income PP defined as postpartum women below 200\% FPL. Source: ACS 1-year PUMS, Census Bureau API.
\end{tablenotes}
\end{table}

\section{Identification Appendix}

\subsection{Parallel Trends Pre-Test}

The Callaway-Sant'Anna estimator includes a formal pre-test of the parallel trends assumption. The event-study coefficients at $e = -4, -3, -2$ are small and statistically insignificant, supporting the identifying assumption.

\subsection{Goodman-Bacon Decomposition Details}

The TWFE estimator for Medicaid coverage decomposes into treated-vs-untreated, earlier-vs-later, and later-vs-earlier comparisons. With the extended sample, the timing-based comparisons receive somewhat greater weight as the panel length increases.

\subsection{DDD Identifying Assumption}

The DDD requires that the differential trend in Medicaid coverage between postpartum and non-postpartum women would have evolved similarly in treated and control states absent the policy. This assumption is directly testable in the pre-treatment period via the DDD pre-trend event study (\Cref{fig:ddd_pretrend}). The assumption is weaker than the standard DiD parallel trends assumption because it allows for differential secular trends between treated and control states, provided these trends affect postpartum and non-postpartum women identically. The Medicaid unwinding, which reduces enrollment across all beneficiary types within a state, is precisely the type of common shock that the DDD is designed to absorb.

\section{Robustness Appendix}

\subsection{Low-Income Subgroup Event Study}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.95\textwidth]{figures/fig4_event_study_lowinc.pdf}
    \caption{Event-Study Estimates: Low-Income Postpartum Women (Below 200\% FPL)}
    \label{fig:event_study_lowinc}
    \floatfoot{\textit{Notes:} Callaway and Sant'Anna (2021) event-study estimates for postpartum women with income below 200\% FPL. Event time $e \in \{-4, \ldots, 2\}$. Shaded areas show 95\% pointwise CIs.}
\end{figure}

\subsection{HonestDiD Sensitivity Details}

The Rambachan-Roth relative magnitudes approach bounds the treatment effect under different assumptions about the smoothness of potential violations of parallel trends. The parameter $\bar{M}$ controls the allowed ratio of post-treatment trend deviations to the maximum pre-treatment deviation. Results are reported in \Cref{tab:robustness} for $\bar{M} \in \{0, 0.5, 1, 1.5, 2\}$. The visualization in \Cref{fig:honestdid} shows how the robust confidence interval expands monotonically as $\bar{M}$ increases, providing a transparent assessment of the sensitivity of the results to parallel trends violations.

\subsection{Wild Cluster Bootstrap Details}

Wild cluster bootstrap is implemented using Rademacher weights with 9,999 replications via the \texttt{fwildclusterboot} package. Following \citet{mackinnon2017wild}, who show that the wild bootstrap is reliable even with highly unequal cluster sizes, WCB $p$-values are reported for the TWFE baseline, the DDD, and the post-PHE specification. The WCB $p$-values are broadly consistent with the standard clustered SE inference, providing additional assurance about the reliability of the results.

\subsection{Permutation Inference Details}

The permutation test randomly reassigns the vector of treatment timing across states while maintaining the same number of treated and control units in each permutation. For each of the 500 permutations, the TWFE estimator is re-run (rather than the full CS-DiD pipeline, which is computationally prohibitive at 500 iterations), producing a distribution of placebo ATTs under the sharp null hypothesis of no effect. The two-sided permutation $p$-value is computed as $p = \frac{1}{B}\sum_{b=1}^{B} \ind\{|\widehat{ATT}_b| \geq |\widehat{ATT}|\}$, where $B = 500$ and $\widehat{ATT}$ is the observed TWFE estimate ($-0.92$ pp). This procedure is related to the randomization inference approach advocated by \citet{conley2011inference} for settings with few policy changes, and to the placebo inference in the synthetic control literature \citep{abadie2010synthetic}. The TWFE and CS-DiD ATTs are similar in magnitude ($-0.92$ vs.\ $-0.50$ pp), so the permutation distribution provides a reasonable approximation of the null distribution for both estimators.

\section{Additional Tables}

\input{tables/tab4_adoption}

\end{document}
