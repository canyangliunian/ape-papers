{
  "paper_id": "apep_0058",
  "scan_date": "2026-02-06T12:38:00.998649+00:00",
  "scan_version": "2.0.0",
  "model": "openai/gpt-5.2",
  "overall_verdict": "SUSPICIOUS",
  "files_scanned": 9,
  "flags": [
    {
      "category": "DATA_PROVENANCE_MISSING",
      "severity": "HIGH",
      "file": "02_process_nohss.R",
      "lines": [
        10,
        14
      ],
      "evidence": "Key outcome data are read from a local CSV (nohss_adult_indicators.csv) with no corresponding download/fetch script in the Paper 74 pipeline. The manuscript cites NOHSS on healthdata.gov, but the repo does not show how this CSV was obtained or constructed (versioning, filters, extraction query), which prevents independent reproduction and audit of the primary outcome.: nohss <- read_csv(\"output/paper_74/data/nohss_adult_indicators.csv\",\n                  show_col_types = FALSE)",
      "confidence": 0.85
    },
    {
      "category": "METHODOLOGY_MISMATCH",
      "severity": "MEDIUM",
      "file": "03_main_analysis.R",
      "lines": [
        28,
        73
      ],
      "evidence": "The manuscript\u2019s design is explicitly 2012\u20132020 even-year (biannual) NOHSS/BRFSS with N=245 state-years (49 states \u00d7 5 periods) and Minnesota excluded. In code, the analysis relies on whatever years are present in output/paper_74/data/analysis_data.rds and does not explicitly restrict to {2012,2014,2016,2018,2020}. If the underlying NOHSS CSV includes other years (common for NOHSS/CDI), the estimation window, cohort mapping, event-time support, and N will differ from what the paper states. This is a mismatch risk because the restriction is only asserted in comments/manuscript, not enforced in code.: # Note: Data is bi-annual (2012, 2014, 2016, 2018, 2020)\n# Treatment years need to map to these periods\n...\ndid_data <- analysis_data %>%\n  filter(state != \"MN\") %>%  # DROP Minnesota entirely\n  mutate(\n    first_treat_adj = case_when(\n      treatment_year == 0 ~ 0L,\n      treatment_year == 2014 ~ 2014L,\n      treatment_year <= 2016 ~ 2016L,\n      treatment_year <= 2018 ~ 2018L,\n      treatment_year <= 2020 ~ 2020L,\n      TRUE ~ 0L\n    )\n  )",
      "confidence": 0.75
    },
    {
      "category": "HARD_CODED_RESULTS",
      "severity": "MEDIUM",
      "file": "paper.tex",
      "lines": [
        188,
        214
      ],
      "evidence": "Main quantitative results (ATT/SE/p-value/CI) are manually embedded as literals in the LaTeX table rather than being programmatically produced from model objects. The code does compute these quantities (03_main_analysis.R saves results_summary.csv), but there is no visible automated linkage ensuring the manuscript table matches the computed outputs. This creates a transcription/hand-editing integrity risk (even if unintentional).: \\begin{table}[H]\n\\centering\n\\caption{Effect of Dental Therapy Authorization on Dental Visit Rates}\n\\label{tab:main_results}\n\\begin{tabular}{lcccc}\n\\toprule\nSpecification & ATT & SE & $p$-value & 95\\% CI \\\\\n\\midrule\nNot-yet-treated comparison & $-$0.013 & 0.006 & 0.041 & [$-$0.025, $-$0.001] \\\\\nUntreated through 2020 & $-$0.011 & 0.006 & 0.080 & [$-$0.023, 0.001] \\\\\n\\bottomrule\n\\end{tabular}\n...",
      "confidence": 0.8
    },
    {
      "category": "DATA_PROVENANCE_MISSING",
      "severity": "LOW",
      "file": "01_treatment_timing.R",
      "lines": [
        14,
        63
      ],
      "evidence": "Treatment timing is manually encoded in the script (not pulled from a verifiable external file/API). The manuscript states legislative records/OHWRC as sources, so manual entry can be legitimate, but for auditability it would be stronger to include a citation-by-state source table (URLs or bill IDs) or a raw source file committed to the repo.: dental_therapy_treatment <- tibble(\n  state = c(\n    \"Minnesota\",\n    \"Maine\",\n    \"Vermont\",\n    \"Arizona\",\n    \"Michigan\",\n    \"New Mexico\",\n    \"Nevada\",\n    \"Idaho\",\n    \"Washington\",\n    \"Oregon\",\n    \"Connecticut\",\n    \"Colorado\",\n    \"Wisconsin\",\n    ...\n  ),\n  treatment_year = c(\n    2009, 2014, 2016, 2018, 2018, 2018, 2019, 2019, 2020, 2020, 2021, 2022, 2024,\n    rep(0, 37)\n  )\n)",
      "confidence": 0.7
    }
  ],
  "file_verdicts": [
    {
      "file": "01_fetch_data.R",
      "verdict": "CLEAN"
    },
    {
      "file": "00_packages.R",
      "verdict": "CLEAN"
    },
    {
      "file": "02_fetch_brfss.R",
      "verdict": "CLEAN"
    },
    {
      "file": "03_analysis.R",
      "verdict": "CLEAN"
    },
    {
      "file": "02_clean_data.R",
      "verdict": "CLEAN"
    },
    {
      "file": "02_fetch_brfss_api.R",
      "verdict": "CLEAN"
    },
    {
      "file": "01_treatment_timing.R",
      "verdict": "CLEAN"
    },
    {
      "file": "02_process_nohss.R",
      "verdict": "SUSPICIOUS"
    },
    {
      "file": "03_main_analysis.R",
      "verdict": "CLEAN"
    }
  ],
  "summary": {
    "verdict": "SUSPICIOUS",
    "counts": {
      "CRITICAL": 0,
      "HIGH": 1,
      "MEDIUM": 2,
      "LOW": 1
    },
    "one_liner": "unclear provenance",
    "executive_summary": "The pipeline reads key outcome indicators from a local file (`nohss_adult_indicators.csv`) inside `02_process_nohss.R` without providing any script or instructions to download, fetch, or reproduce that dataset as part of the Paper 74 workflow. Although the manuscript cites NOHSS data from healthdata.gov, the repository does not include a provenance trail linking that source to the exact CSV used, making the results non-reproducible and the data origin unverifiable.",
    "top_issues": [
      {
        "category": "DATA_PROVENANCE_MISSING",
        "severity": "HIGH",
        "short": "Key outcome data are read from a local CSV (nohss_adult_i...",
        "file": "02_process_nohss.R",
        "lines": [
          10,
          14
        ],
        "github_url": "/apep_0058/code/02_process_nohss.R#L10-L14"
      }
    ],
    "full_report_url": "/tournament/corpus_scanner/scans/apep_0058_scan.json"
  },
  "error": null
}