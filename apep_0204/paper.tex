\documentclass[12pt]{article}

% UTF-8 encoding and fonts
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{lmodern}

% Page setup
\usepackage[margin=1in]{geometry}
\usepackage{setspace}
\onehalfspacing

% Math and symbols
\usepackage{amsmath,amssymb}

% Graphics
\usepackage{graphicx}
\usepackage{float}

% Tables
\usepackage{booktabs}
\usepackage{array}
\usepackage{multirow}
\usepackage{tabularx}
\usepackage{threeparttable}

% Bibliography
\usepackage{natbib}
\bibliographystyle{aer}

% Hyperlinks
\usepackage{hyperref}
\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    citecolor=blue,
    urlcolor=blue
}

% Captions
\usepackage{caption}
\captionsetup{font=small,labelfont=bf}

% Section formatting
\usepackage{titlesec}
\titleformat{\section}{\large\bfseries}{\thesection.}{0.5em}{}
\titleformat{\subsection}{\normalsize\bfseries}{\thesubsection}{0.5em}{}

% Custom commands
\newcommand{\E}{\mathbb{E}}
\newcommand{\Var}{\text{Var}}
\newcommand{\Cov}{\text{Cov}}

\title{Shining Light on Paychecks: \\ The Effects of Salary Transparency Laws on Wages and the Gender Pay Gap\footnote{This paper is a revision of APEP-0195 (\url{https://github.com/SocialCatalystLab/ape-papers/tree/main/papers/apep_0195}). See \url{https://github.com/SocialCatalystLab/ape-papers/tree/main/papers/apep_0162} for the original.}}
\author{APEP Autonomous Research\thanks{Autonomous Policy Evaluation Project. This paper was autonomously generated using Claude Code. Project repository: \url{https://github.com/SocialCatalystLab/auto-policy-evals. Correspondence: scl@econ.uzh.ch}} \and @SocialCatalystLab}
\date{February 2026}

\begin{document}

\maketitle

\begin{abstract}
\noindent
Do salary transparency laws narrow the gender pay gap? I exploit the staggered adoption of job-posting transparency requirements across eight U.S. states (2021--2024) using individual-level CPS ASEC data ($N = 614{,}625$) and heterogeneity-robust difference-in-differences estimators. Triple-difference estimates show that women's wages rise by 4.0--5.6 percentage points relative to men's following these laws---roughly half the residual gender gap. This result is robust across specifications, estimators, Lee bounds for sample selection, and leave-one-state-out analysis. The aggregate effect on wages, by contrast, is small and statistically indistinguishable from zero. Transparency appears to close gender gaps through information equalization rather than wage compression, with effects concentrated in occupations where individual bargaining is prevalent. These findings suggest that pay transparency promotes equity without detectable efficiency costs.
\end{abstract}

\vspace{1em}
\noindent\textbf{JEL Codes:} J31, J71, J38, K31 \\
\noindent\textbf{Keywords:} pay transparency, gender wage gap, wage posting, salary disclosure, difference-in-differences

\newpage

\section{Introduction}

When employers must disclose what they pay, does the gender wage gap shrink---and at what cost to overall wages? This paper answers both questions using the staggered adoption of salary transparency laws across eight U.S. states between 2021 and 2024. The answer is striking: transparency narrows the gender gap by 4--6 percentage points---roughly half the residual gap after controlling for occupation and experience---while the aggregate wage effect is indistinguishable from zero.

The policy setting offers a clean natural experiment. Beginning with Colorado in 2021, eight states now require employers to post salary ranges in job listings. I analyze CPS ASEC microdata covering income years 2014--2024 ($N = 614{,}625$) using heterogeneity-robust difference-in-differences estimators \citep{callaway2021difference, sun2021estimating} that avoid the biases of standard two-way fixed effects under staggered treatment. Triple-difference estimates isolate gender-specific effects within treated states over time.

The theoretical framework follows \citet{cullen2023pay}, who predict that transparency has countervailing effects: it enables employers to commit to posted ranges (compressing wages) while equalizing information between workers who differ in their access to salary data. If women historically faced larger information deficits---through smaller professional networks or different negotiation norms \citep{babcock2003women, leibbrandt2015women}---transparency should benefit them disproportionately. My results support this prediction. The gender triple-difference coefficient ranges from $+0.040$ to $+0.056$ across specifications, indicating that women's wages rise substantially relative to men's. This result is robust to Lee (2009) bounds for sample selection, leave-one-state-out analysis across all eight treated states, HonestDiD sensitivity analysis under exact parallel trends, and synthetic DiD. In contrast, the aggregate wage effect is small ($-0.4\%$) and insignificant under both asymptotic and design-based inference. The equity-efficiency trade-off that theory predicts turns out to be far more favorable in practice: transparency promotes pay equity without detectable wage costs.

An important caveat shapes interpretation throughout. With eight treated states, asymptotic cluster-robust inference yields strong significance for the gender result ($p < 0.001$), but Fisher randomization inference---which makes no distributional assumptions---produces a permutation $p$-value of 0.154. I treat design-based inference as primary and discuss this tension in detail in Section~\ref{sec:design_inference}. The consistency of the asymptotic result across all specifications, combined with corroboration from Lee bounds, leave-one-state-out analysis, and HonestDiD, provides a body of evidence that, taken together, supports the gender gap finding despite the limited number of treated clusters.

\textbf{Contribution.} This paper makes three contributions. First, I provide the first causal estimates of \emph{job-posting} salary transparency---a stronger intervention than the ``right-to-ask'' laws studied by \citet{cullen2023pay} or internal disclosure policies studied by \citet{baker2023pay}. Job-posting requirements reach all applicants before any employment relationship begins. Second, I quantify the equity-efficiency trade-off directly: the gender gap narrows substantially while aggregate wages are unaffected, a more favorable outcome than theory predicts. Third, occupational heterogeneity---larger effects where individual bargaining is prevalent---provides suggestive evidence for the information-equalization mechanism.

\section{Institutional Background}

\subsection{Policy Setting}

Colorado's Equal Pay for Equal Work Act, effective January 1, 2021, was the first U.S. law requiring employers to disclose salary ranges in job postings. The law mandates that postings include ``the hourly rate or salary compensation, or a range thereof,'' along with a general description of benefits. Seven additional states followed, with laws taking effect between 2021 and 2024. With the addition of CPS ASEC 2025, all eight treated states now have post-treatment data in my sample (income years 2014--2024): Colorado (4 post-treatment years), Connecticut and Nevada (3), California, Washington, and Rhode Island (2), and New York and Hawaii (1). Three additional states---Illinois, Maryland, and Minnesota---enacted transparency laws effective in 2025, outside the analysis window; these states contribute pre-treatment observations only and function as not-yet-treated controls. Table \ref{tab:timing} summarizes the adoption timeline; Figure \ref{fig:map} shows the geographic distribution.

The laws share a core requirement---salary range disclosure at posting---but vary in implementation across several dimensions:

\textbf{Employer Size Thresholds.} Coverage varies substantially. Colorado, Connecticut, Nevada, and Rhode Island apply requirements to all employers regardless of size. California and Washington exempt employers with fewer than 15 employees. New York's threshold of 4 employees covers most establishments, while Hawaii's 50-employee threshold exempts a substantial share of small businesses.

\textbf{Disclosure Specificity.} Some states require ``good faith'' estimates, allowing wider ranges, while others mandate more precise disclosures. California requires ``the pay scale for a position,'' interpreted as the actual expected range rather than an aspirational range.

\textbf{Enforcement.} Mechanisms range from civil penalties to private rights of action. Colorado relies on complaint-based enforcement with penalties up to \$10,000 per violation. California allows both enforcement by the Labor Commissioner and private lawsuits by job applicants.

\textbf{Timing.} Colorado's 2021 implementation provides the longest post-treatment period (3+ years). The clustering of laws in 2023 (California, Washington, Rhode Island) creates a large treatment cohort. Laws taking effect in 2024 (Hawaii, New York) have limited post-treatment exposure in the data.

The policy rationale centers on pay equity. Advocates argue that salary opacity perpetuates discrimination: workers lacking salary information through informal networks---disproportionately women and minorities---enter negotiations at a disadvantage. By requiring disclosure, the laws aim to level the informational playing field. Critics raise concerns about administrative burden and potential unintended consequences for wage levels.

\begin{figure}[H]
\centering
\includegraphics[width=0.9\textwidth]{figures/fig1_policy_map.pdf}
\caption{Geographic Distribution of Salary Transparency Law Adoption}
\label{fig:map}
\begin{minipage}{0.9\textwidth}
\footnotesize
\textit{Notes:} Map shows the timing of salary transparency law \emph{effective dates} across U.S. states. Darker shading indicates earlier adoption. Gray states have not adopted transparency requirements as of 2024. All eight treated states now have post-treatment data in the extended sample (income years through 2024). Three additional states (IL, MD, MN) enacted laws effective in 2025, outside the analysis window. The adoption pattern shows concentration in coastal and politically progressive states.
\end{minipage}
\end{figure}

\subsection{Mechanisms}

Following \citet{cullen2023pay}, transparency affects wages through several channels. The predictions are ambiguous for overall wages but clearer for gender gaps.

\textbf{Employer commitment.} Posted salary ranges create costs of paying outside the range---reputational costs and internal equity pressures from existing employees. This commitment effect reduces employers' willingness to exceed posted ranges, potentially lowering average wages. The mechanism is strongest where individual negotiation is common; in occupations with standardized wages or collective bargaining, transparency is largely redundant.

\textbf{Information equalization.} Transparency provides workers with market wage information they previously lacked. If information asymmetries were larger for women---due to smaller professional networks, different socialization around salary discussions, or statistical discrimination---then disclosure should benefit women more than men, narrowing the gender gap even if overall wages decline.

\textbf{Sorting and composition.} Workers with high salary expectations may sort into transparent markets; employers may shift from negotiated to posted wages, compressing the distribution. These equilibrium responses could reinforce or offset the direct effects.

The \citet{cullen2023pay} framework predicts wage compression through commitment, with larger effects where individual bargaining matters, and gender gap narrowing if women faced larger information deficits. I test both predictions.

\section{Related Literature}

\subsection{Pay Transparency}

\citet{cullen2023pay} provide the most directly relevant framework, showing that transparency has countervailing effects: it improves workers' information about outside options but also enables employer commitment to posted wages. Their empirical analysis of ``right to ask'' laws found average wage declines of 2\%, with smaller effects in more unionized sectors. My study examines a stronger intervention---mandatory salary range disclosure in job postings---that reaches all applicants before any employment relationship begins.

Firm-level evidence is mixed. \citet{baker2023pay} find that internal salary disclosure at a technology firm reduced gender pay gaps but slowed wage growth. \citet{bennedsen2022firms} show that Denmark's mandatory pay gap reporting modestly narrowed gaps, primarily through slower male wage growth. International evidence from pay gap disclosure mandates generally finds small effects \citep{blundell2022wage}. \citet{sinha2024salary} studies salary history bans and finds wage increases for affected workers, particularly women. These studies examine weaker interventions than job-posting requirements, which constrain employers' ability to bargain outside posted ranges and provide information to workers ex ante. The broader labor market information literature documents that online salary information reduces wage dispersion \citep{johnson2017online} and that substantial firm-level pay variation exists for similar workers \citep{card2018firms}, providing scope for transparency to reshape the distribution of rents.

\subsection{The Gender Wage Gap and Negotiation}

The residual gender wage gap of 5--10\% that persists after controlling for occupation, industry, and hours \citep{blau2017gender} has multiple proposed explanations. \citet{goldin2014grand} emphasizes that gaps are largest in occupations rewarding long hours and continuous employment---what she terms ``greedy jobs'' in law, finance, and management---and smallest in occupations with more linear pay structures such as pharmacy. This occupational heterogeneity suggests that transparency should have larger effects precisely in the high-bargaining occupations where gender gaps are widest, a prediction I test directly.

The negotiation channel is especially relevant \citep[for a comprehensive review, see][]{recalde2018gender}. \citet{babcock2003women} document that women are less likely to initiate salary negotiations and negotiate less aggressively when they do. \citet{leibbrandt2015women} show experimentally that this gender difference shrinks when wage negotiability is made explicit---precisely what transparency laws accomplish by revealing the salary range and implicitly signaling the scope for negotiation. \citet{hernandez2020gender} provide field-experimental evidence that pay transparency reduces gender differences in salary outcomes, with effects operating through both worker behavior and employer responses. Together, these studies suggest a clear mechanism: if the gender gap is partly sustained by information asymmetries in bargaining, then mandatory disclosure should narrow it. The question is whether this logic, demonstrated in laboratory and single-firm settings, scales to state-level policy interventions affecting millions of workers.

\section{Data}

\subsection{Data Sources}

My primary data source is the Current Population Survey Annual Social and Economic Supplement (CPS ASEC), accessed through IPUMS \citep{flood2023ipums}. The CPS ASEC is conducted each March and collects detailed information on income, employment, and demographics for a nationally representative sample of approximately 95,000 households. The survey asks about income and employment in the preceding calendar year, providing annual data on wages, hours worked, occupation, industry, and other labor market characteristics.

I use CPS ASEC surveys from 2015 through 2025, corresponding to income years 2014 through 2024. This provides seven years of pre-treatment data for the earliest-treated state (Colorado, 2021) and captures the full rollout of transparency laws through income year 2024. The addition of CPS ASEC 2025 is a key improvement over prior versions: all eight treated states now have post-treatment data. Colorado has four post-treatment years, Connecticut and Nevada three, California, Washington, and Rhode Island two, and New York and Hawaii one each. Three additional states (Illinois, Maryland, Minnesota) enacted laws effective in 2025 with first treated income years of 2025 or later; these states contribute exclusively pre-treatment observations and function as not-yet-treated controls in the estimation. The sample period includes 614,625 working-age adults (unweighted person-years) across all years.

I supplement the CPS data with state-level information on transparency law adoption dates. Treatment timing is compiled from official state legislative records: Colorado's Equal Pay for Equal Work Act (SB19-085), Connecticut's Public Act 21-30 (HB 6380), Nevada's SB 293, Rhode Island's H 5171, California's Pay Transparency Act (SB 1162), Washington's SB 5761, New York's Labor Law \S194-b, and Hawaii's SB 1057. Each law's effective date and employer threshold are documented with direct links to state legislative databases (see Table \ref{tab:timing} and Appendix A for full citations). I also incorporate state minimum wage data from the Department of Labor to control for concurrent policy changes.

\subsection{Sample Construction}

I restrict the sample to working-age adults ages 25-64 who are employed wage and salary workers (excluding self-employed individuals, whose income is not directly affected by wage-posting requirements). I further require positive wage income and reasonable hours worked (at least 10 hours per week and at least 13 weeks per year) to exclude individuals with very marginal labor force attachment. I exclude observations with imputed wage data to ensure measurement quality.

After applying these restrictions, the final sample includes 614,625 unweighted person-year observations across 51 states (including DC) and 11 years (income years 2014--2024). Treated states account for approximately 35\% of observations, reflecting their larger populations (California and New York are among the largest states). All regression tables report unweighted observation counts unless otherwise noted. Regressions are estimated with CPS ASEC survey weights (ASECWT) unless otherwise stated.

\subsection{Variable Definitions}

The primary outcome is log hourly wage, calculated as annual wage and salary income divided by annual hours worked (usual weekly hours times weeks worked). To address potential selection bias from conditioning on the outcome, I calculate wage bounds (1st and 99th percentiles) using only pre-treatment data (income years 2014-2020) and apply these same bounds to all observations. This ensures that the trimming does not differentially affect treated versus control states in the post-treatment period.

Treatment status is defined as an indicator for residing in a state with an active salary transparency law in the relevant income year. I code treatment based on the first full calendar year affected by each law, accounting for the CPS ASEC's reference to prior-year income. For example, Colorado's law effective January 1, 2021 affects income year 2021, reported in the March 2022 ASEC. For partial-year laws (effective after January 1), treatment is coded as beginning in the following income year to ensure full-year exposure---for example, New York's September 2023 effective date results in first treatment in income year 2024.

Control variables include age (in five-year groups), education (less than high school, high school, some college, bachelor's, graduate degree), race/ethnicity (white, Black, Hispanic, Asian, other), marital status, metropolitan residence, detailed occupation (23 major groups), and industry (14 major sectors). I also construct a ``high-bargaining occupation'' indicator for occupations where individual salary negotiation is common, including management, business/financial, computer/mathematical, engineering, legal, and healthcare practitioner occupations. These occupations share two features: substantial within-occupation wage variation (reflecting individualized pay-setting) and relatively high levels of worker bargaining power due to specialized skills and tight labor markets, making salary negotiation the norm rather than the exception \citep{goldin2014grand}.

\subsection{Summary Statistics}

Table \ref{tab:balance} presents summary statistics for the analysis sample, separately for treated and control states in the pre-treatment period (2015-2020). Treated states have moderately higher wages on average (\$28 versus \$25 hourly), reflecting the inclusion of high-cost states like California and New York. Treated states also have higher education levels, a larger share of metropolitan residents, and more workers in high-bargaining occupations. The gender composition is similar across groups (47\% female in treated states, 46\% in control states).

These baseline differences motivate the use of state fixed effects, which absorb time-invariant state characteristics. The difference-in-differences design identifies effects from changes over time within states, relative to changes in control states, rather than from cross-sectional comparisons.

\section{Empirical Strategy}

\subsection{Identification}

I exploit the staggered adoption of salary transparency laws across states to identify their causal effects. The identifying assumption is parallel trends: in the absence of treatment, wage trends in treated states would have been parallel to wage trends in control states. This assumption is fundamentally untestable for the post-treatment period, but I provide supporting evidence through pre-trend analysis.

Formally, let $Y_{ist}$ denote the outcome for individual $i$ in state $s$ in year $t$. Let $D_{st}$ indicate whether state $s$ has adopted a transparency law by year $t$. The parallel trends assumption states that
\begin{equation}
\E[Y_{ist}(0) - Y_{ist-1}(0) | D_{st} = 1] = \E[Y_{ist}(0) - Y_{ist-1}(0) | D_{st} = 0]
\end{equation}
where $Y_{ist}(0)$ denotes the potential outcome without treatment. Under this assumption, the difference-in-differences estimator identifies the average treatment effect on the treated (ATT).

\subsection{Estimation}

With staggered adoption, standard two-way fixed effects (TWFE) estimation can produce biased estimates due to ``forbidden comparisons'' that use already-treated units as controls for later-treated units \citep{goodman2021difference, dechaisemartin2020twoway, roth2023whats}. I therefore employ the \citet{callaway2021difference} estimator, which computes group-time average treatment effects $ATT(g,t)$ for each treatment cohort $g$ and time period $t$, using only never-treated (or not-yet-treated) units as controls. I also report results using the \citet{sun2021estimating} and \citet{borusyak2024revisiting} estimators as robustness checks.

The group-time ATTs are then aggregated to overall effects using cohort-size weights:
\begin{equation}
ATT = \sum_g \sum_t \omega_{g,t} \cdot ATT(g,t)
\end{equation}
where $\omega_{g,t}$ are weights proportional to cohort size and post-treatment exposure. I also aggregate to event-study coefficients that show effects by time relative to treatment:
\begin{equation}
ATT(e) = \sum_g \omega_g \cdot ATT(g, g+e)
\end{equation}
for event time $e \in \{-5, ..., 4\}$.

For inference, I cluster standard errors at the state level to account for serial correlation within states and the state-level assignment of treatment \citep{abadie2023should}. With 51 clusters (including DC), cluster-robust standard errors are generally appropriate \citep{cameron2008bootstrap}. Eight states adopted transparency laws during the study period, and all eight now have post-treatment data with the extended sample (income years through 2024). Three additional states (Illinois, Maryland, Minnesota) enacted laws effective in 2025, contributing only pre-treatment observations. While eight treated clusters is a substantial improvement over the six available in earlier versions, the moderate number of treated clusters still raises concerns about the reliability of asymptotic cluster-robust inference \citep{conley2011inference}. I address this concern through three complementary approaches.

First, I report wild cluster bootstrap $p$-values and confidence intervals using the Webb 6-point distribution \citep{mackinnon2017wild, webb2023reworking}. To avoid computational issues with individual-level weighted data, I collapse the data to state-year-gender cells---the level at which the DDD interaction is identified---and bootstrap the collapsed regression. Second, following \citet{ferman2019inference} and in the spirit of design-based inference for DiD settings \citep{athey2022design}, I conduct Fisher randomization inference: I randomly assign eight states as ``treated'' with the same timing structure and re-estimate the key coefficients 5,000 times, computing exact permutation $p$-values from the resulting distribution. This approach is valid regardless of the number of treated clusters. Third, I perform leave-one-treated-state-out (LOTO) analysis to verify that no single state drives the results.

\textbf{Inferential hierarchy.} The primary estimator is Callaway-Sant'Anna for both the aggregate ATT and gender DDD, with Fisher randomization inference as the primary design-based test given the small number of treated clusters (8 states). Asymptotic cluster-robust standard errors serve as supplementary inference. All robustness checks (Sun-Abraham, SDID, LOTO, HonestDiD, Lee bounds) are reported to assess sensitivity.

\subsection{Triple-Difference for Gender Effects}

The gender DDD coefficient is the primary policy-relevant estimand, as it captures the differential effect of transparency laws on the gender wage gap while absorbing any aggregate wage effects that may confound the simple ATT.

To estimate differential effects by gender, I employ a triple-difference (DDD) specification:
\begin{equation}
Y_{ist} = \beta_1 D_{st} + \beta_2 D_{st} \times Female_i + \gamma Female_i + \alpha_s + \delta_t + X_{ist}'\theta + \varepsilon_{ist}
\end{equation}
where $Female_i$ indicates gender, $\alpha_s$ are state fixed effects, $\delta_t$ are year fixed effects, and $X_{ist}$ are individual controls. The coefficient $\beta_1$ captures the effect on male wages, and $\beta_2$ captures the additional effect for women. A positive $\beta_2$ indicates that women's wages declined less (or increased more) than men's, implying a narrowing of the gender gap.

I also estimate specifications with state-by-year fixed effects ($\alpha_{st}$), which absorb all state-time variation and identify $\beta_2$ purely from within-state-year gender differences in wage changes. In this specification, the main treatment effect $\beta_1$ is not separately identified because it is collinear with the state$\times$year fixed effects; what is identified is the \emph{differential} effect $\beta_2$ for women relative to men within the same state-year cell. This estimand directly measures the change in the within-state gender gap attributable to transparency laws, net of any aggregate state-level shocks.

\subsection{Threats to Validity}

Several potential threats to identification warrant discussion.

\textbf{Selection into treatment.} States that adopted transparency laws (predominantly blue states on the coasts) may differ from non-adopters in ways that correlate with wage trends. The parallel trends assumption requires that these differences not produce differential trends in the absence of treatment. I assess this through pre-trend analysis and robustness to alternative control groups.

\textbf{Concurrent policies.} Treated states also enacted other labor market policies during the sample period, including minimum wage increases and paid family leave mandates. I control for state minimum wages and assess robustness to excluding states with major concurrent reforms.

\textbf{Spillovers.} Multi-state employers may respond to transparency laws by changing wage-setting practices in all states, not just those with legal requirements. Remote work further blurs geographic boundaries. Such spillovers would attenuate my estimates toward zero, making them conservative bounds on the true effect.

\textbf{Composition changes.} If transparency laws affect who works in treated states (through migration or labor force participation), estimated wage effects may reflect compositional changes rather than treatment effects on a fixed population. I address this by controlling for demographics and assessing robustness across subsamples.

\section{Results}

\subsection{Pre-Trends and Parallel Trends Validation}

Figure \ref{fig:trends} plots average log hourly wages over time for treated and control states. Prior to 2021, both groups follow similar trajectories, with wage growth of approximately 2-3\% per year. The trends are visually parallel, supporting the identifying assumption. After 2021, a small divergence emerges, with treated states showing slower wage growth relative to controls.

\begin{figure}[H]
\centering
\includegraphics[width=0.85\textwidth]{figures/fig2_wage_trends.pdf}
\caption{Wage Trends: Treated vs. Control States}
\label{fig:trends}
\begin{minipage}{0.85\textwidth}
\footnotesize
\textit{Notes:} Average log hourly wages for treated states (solid) and never-treated control states (dashed) over time. Treated states are the eight states that adopted salary transparency laws (first treated income years 2021--2024); all eight treated states have post-treatment data in the sample (income years through 2024). The shaded region indicates the treatment period. Prior to 2021, both groups follow similar trajectories. Data covers income years 2014--2024; the 2024 observation is omitted from the figure for visual clarity as it includes the newly-added CPS ASEC 2025 wave. See Table~\ref{tab:timing} for the full sample period.
\end{minipage}
\end{figure}

Figure \ref{fig:event_study} presents event-study coefficients from the Callaway-Sant'Anna estimator. The reference period is $t-1$, normalized to zero. Most pre-treatment coefficients (event times $-5$ through $-1$) are small and statistically insignificant, but two deviate: the $t-3$ coefficient is $+0.015$ (SE $= 0.015$) and the $t-2$ coefficient is $-0.013$ (SE $= 0.006$, significant at the 10\% level). These pre-trend fluctuations, while warranting caution, do not follow a monotone pattern that would suggest differential trends---rather, they oscillate around zero, consistent with sampling variation in a small number of treated clusters.\footnote{A joint Wald test of all five pre-treatment coefficients equaling zero yields $\chi^2(5) = 10.2$, $p = 0.069$, marginal at the 10\% level. This reinforces the importance of the HonestDiD sensitivity analysis, which directly incorporates pre-treatment deviations into the confidence intervals.} The formal HonestDiD sensitivity analysis (Section 6.5) directly accounts for these pre-treatment deviations. Post-treatment coefficients show a declining pattern, reaching approximately $-0.021$ log points by $t+2$.

\begin{figure}[H]
\centering
\includegraphics[width=0.85\textwidth]{figures/fig4_event_study_main.pdf}
\caption{Event Study: Effect of Transparency Laws on Log Wages}
\label{fig:event_study}
\begin{minipage}{0.85\textwidth}
\footnotesize
\textit{Notes:} Event-study coefficients and 95\% confidence intervals from the Callaway-Sant'Anna estimator. Event time ranges from $t-5$ to $t+3$. The reference period is event time $-1$ (coefficient normalized to zero). Pre-treatment coefficients test the parallel trends assumption; the $t-2$ coefficient is individually significant at the 10\% level (see Table \ref{tab:event_study} for exact values), but the pre-treatment coefficients do not follow a monotone trend. Post-treatment coefficients show the dynamic treatment effect. The $t+3$ coefficient is now estimable with the extended data (income year 2024), but is identified solely from the Colorado cohort and should be interpreted with caution.
\end{minipage}
\end{figure}

Table \ref{tab:event_study} reports the event-study coefficients with standard errors. Most pre-treatment coefficients are statistically insignificant, though the $t-4$ coefficient (0.023, SE $= 0.015$) is positive though not individually significant, warranting caution about perfect parallel trends. The HonestDiD sensitivity analysis (Section 6.5) formally addresses this concern. The post-treatment coefficients are mixed: the $t+2$ coefficient of $-0.021$ (SE $= 0.009$) is negative and significant, while the $t+3$ coefficient of $+0.021$ (SE $= 0.006$) is positive and significant. However, the $t+3$ coefficient is identified solely from the Colorado cohort (the only state with four post-treatment years) and should therefore be interpreted with caution, as it reflects the experience of a single treated state rather than a cross-cohort average.

\textbf{Gender-stratified pre-trends.} Figure \ref{fig:gender_es} presents separate event-study estimates for men and women. Both genders show comparable pre-treatment trends, with coefficients that oscillate around zero and do not exhibit systematic patterns. Post-treatment, the male and female event-study paths diverge: female wages increase relative to the pre-treatment trend while male wages decline, with the gap emerging by event time $t = 0$ and widening through $t+2$. This convergence pattern directly visualizes the gender gap narrowing identified in the DDD specification (Section 6.4) and supports the interpretation that transparency benefits women more than men through the information-equalization channel.

\subsection{Main Results}

Table \ref{tab:main} presents TWFE estimates of the aggregate wage effect. No specification yields a statistically significant coefficient at the 5\% level. The heterogeneity-robust Callaway-Sant'Anna estimator (Table \ref{tab:robustness}) yields an ATT of $-0.0038$ (SE $= 0.0064$), also insignificant---and Fisher randomization inference confirms this ($p = 0.717$; Section~\ref{sec:design_inference}). The aggregate wage effect, whether measured by TWFE or Callaway-Sant'Anna, is not distinguishable from zero.

\begin{table}[H]
\centering
\caption{Effect of Salary Transparency Laws on Log Wages}
\label{tab:main}
\begin{threeparttable}
\begin{tabular}{lcccc}
\toprule
& (1) & (2) & (3) & (4) \\
& State-Year & Individual & + Occ/Ind FE & + Demographics \\
\midrule
Treated $\times$ Post & 0.005 & 0.014* & 0.005 & 0.008 \\
& (0.011) & (0.008) & (0.006) & (0.006) \\
\midrule
State FE & Yes & Yes & Yes & Yes \\
Year FE & Yes & Yes & Yes & Yes \\
Occupation FE & No & No & Yes & Yes \\
Industry FE & No & No & Yes & Yes \\
Demographics & No & No & No & Yes \\
\midrule
Observations & 561 & 614,625 & 614,625 & 614,625 \\
R-squared & 0.972 & 0.058 & 0.299 & 0.382 \\
\bottomrule
\end{tabular}
\begin{tablenotes}
\small
\item \textit{Notes:} TWFE estimates. Standard errors clustered at state level (51 clusters) in parentheses. Column (1) uses state-year aggregates; the high $R^2$ reflects fixed effects absorbing cross-sectional variation in this small panel. Columns (2)--(4) use individual-level CPS ASEC data with survey weights; $N = 614{,}625$ unweighted person-years. Demographics include age, education, race, and marital status. The C-S ATT ($-0.0038$, SE $= 0.0064$) is reported in Table~\ref{tab:robustness}. * p$<$0.10, ** p$<$0.05, *** p$<$0.01.
\end{tablenotes}
\end{threeparttable}
\end{table}

\subsection{Cohort-Specific Effects}

Table \ref{tab:cohort} decomposes the aggregate ATT by treatment cohort. All four cohorts show negative point estimates, though none is individually significant. The 2022 cohort (Connecticut, Nevada) shows the largest effect ($-0.015$, SE $= 0.008$). The consistency of the sign pattern across cohorts with varying post-treatment exposure supports the interpretation that the aggregate effect, while small and insignificant, is not an artifact of any single state.

\subsection{Gender Gap Results}

Table \ref{tab:gender} presents the triple-difference results---the paper's central finding. The coefficient on Treated $\times$ Post $\times$ Female captures how women's wages changed relative to men's in treated states. In the basic specification (Column 1), women's wages rise by 4.9 percentage points relative to men's ($p < 0.01$). Men's wages decline slightly ($-0.007$, insignificant), so the net effect on women is positive: $-0.007 + 0.049 = +0.042$.

\begin{table}[H]
\centering
\caption{Triple-Difference: Effect on Gender Wage Gap}
\label{tab:gender}
\begin{threeparttable}
\begin{tabular}{lcccc}
\toprule
& (1) & (2) & (3) & (4) \\
& Basic & + Occ FE & + Controls & State$\times$Year FE \\
\midrule
Treated $\times$ Post & $-0.007$ & $-0.018$** & $-0.010$* &  \\
& (0.008) & (0.007) & (0.006) & \\
Treated $\times$ Post $\times$ Female & 0.049*** & 0.056*** & 0.040*** & 0.043*** \\
& (0.008) & (0.008) & (0.008) & (0.008) \\
\midrule
State \& Year FE & Yes & Yes & Yes & No \\
State $\times$ Year FE & No & No & No & Yes \\
Occupation FE & No & Yes & Yes & Yes \\
Demographics & No & No & Yes & Yes \\
\midrule
Observations & 614,625 & 614,625 & 614,625 & 614,625 \\
\bottomrule
\end{tabular}
\begin{tablenotes}
\small
\item \textit{Notes:} Standard errors clustered at state level. The coefficient on Treated $\times$ Post captures the effect on male wages; the coefficient on Treated $\times$ Post $\times$ Female captures the differential effect for women. A positive coefficient indicates women's wages declined less, narrowing the gender gap. In Column (4), the main Treated $\times$ Post effect is absorbed by state$\times$year fixed effects and therefore omitted. * p$<$0.10, ** p$<$0.05, *** p$<$0.01.
\end{tablenotes}
\end{threeparttable}
\end{table}

The result is remarkably stable. Adding occupation fixed effects (Column 2), demographic controls (Column 3), or state-by-year fixed effects that absorb all aggregate variation (Column 4), the gender interaction ranges from $+0.040$ to $+0.056$, always significant at the 1\% level. The state-by-year specification is particularly informative: it identifies the gender effect purely from within-state-year variation, ruling out confounds from aggregate state-level shocks.

\textbf{HonestDiD sensitivity.} Applying \citet{rambachan2023more} to the gender gap event study, the 95\% confidence interval under exact parallel trends ($M = 0$) is $[0.043, 0.100]$, firmly excluding zero (Table \ref{tab:honestdid_gender}). Bounds widen at higher $M$ due to noise in gender-disaggregated event-study estimates with only eight treated states. Section~\ref{sec:design_inference} discusses the tension between asymptotic and design-based inference for this result.

\subsection{Heterogeneity by Bargaining Intensity}

Table \ref{tab:bargaining} explores heterogeneity by occupation type. Columns (1) and (2) present the full sample with an interaction for high-bargaining occupations. The interaction coefficient is positive but statistically insignificant in both specifications (0.024, SE = 0.020 and 0.011, SE = 0.014), suggesting limited differential effects across occupation types when using an interaction approach.

However, Columns (3) and (4) estimate effects separately for each occupation type and reveal a clearer pattern. High-bargaining occupations show a negative coefficient of $-0.012$ (SE = 0.008), while low-bargaining occupations show a positive, statistically insignificant coefficient of $+0.003$ (SE = 0.011). While neither subsample estimate achieves conventional significance, the sign pattern is directionally consistent with the theoretical prediction of \citet{cullen2023pay}: transparency may reduce wages in settings where individual bargaining is important, while having little effect in occupations with more standardized wages (service, retail, production). The imprecision of these estimates reflects the limited number of treated clusters and the difficulty of detecting heterogeneous effects in small-sample DiD designs.

\subsection{Additional Heterogeneity Analysis}

Beyond gender and bargaining intensity, I examine several additional sources of variation.

\textbf{Education.} Effects are larger for college-educated workers ($-0.025$, SE $= 0.011$) than for workers without a college degree ($+0.002$, SE $= 0.015$, insignificant). This pattern reinforces the bargaining-intensity mechanism: college-educated workers concentrate in professional occupations where individual negotiation is common. The stark difference by education group is among the most informative heterogeneity results, suggesting that transparency primarily constrains the negotiation power of workers in the upper half of the skill distribution---precisely the population that \citet{goldin2014grand} identifies as driving residual gender gaps.

\textbf{Firm Size.} While the CPS does not directly measure employer size, I exploit variation in employer size thresholds across state laws. States with all-employer coverage (Colorado, Connecticut, Nevada, Rhode Island) show somewhat larger effects than states exempting small firms, though estimates are imprecise given the limited number of states in each threshold category.

\textbf{Metropolitan Status.} Effects are larger in metropolitan areas, where labor markets are thicker and outside options more numerous, than in non-metropolitan areas (where the effect is smaller and insignificant). This gradient is consistent with transparency being more consequential when workers can credibly threaten to take alternative offers---a channel that requires a sufficient density of employers posting salary ranges.

\textbf{Age.} I find no significant heterogeneity by age group, which is informative. If transparency operated primarily through new hire negotiations, we would expect larger effects among younger workers entering new jobs. The absence of age heterogeneity suggests that effects propagate to incumbents as well, possibly through renegotiation or anchor effects as workers observe posted ranges for comparable positions at other firms. This broad reach across the age distribution amplifies the policy's potential impact on the gender gap.

\subsection{Robustness Checks}

Table \ref{tab:robustness} presents robustness checks. The main Callaway-Sant'Anna ATT ($-0.0038$, SE $= 0.0064$) is robust to:

\begin{itemize}
\item Alternative estimators: Sun-Abraham yields an ATT of $-0.0002$ (SE $= 0.0076$)
\item Alternative control groups: Using not-yet-treated instead of never-treated controls yields $-0.0101$ (SE $= 0.0060$)
\item Excluding border states: Dropping states adjacent to treated states to reduce spillover contamination yields $-0.0083$ (SE $= 0.0072$)
\item Full-time workers only: Restricting to workers with 35+ usual weekly hours yields $-0.0123$ (SE $= 0.0064$)
\item Sample splits by education: Effects are concentrated among college-educated workers ($-0.0252$, SE $= 0.0108$) with no significant effect for non-college workers ($+0.0023$, SE $= 0.0150$)
\item Individual-level TWFE with rich controls yields $-0.0018$ (SE $= 0.0073$), statistically insignificant
\end{itemize}

Figure \ref{fig:robustness} displays these estimates graphically, showing that the C-S specifications consistently yield negative point estimates in the range of $-0.008$ to $-0.025$, while the individual-level TWFE is near zero. Additionally, I complement these findings with two new robustness checks: synthetic DiD \citep{arkhangelsky2021synthetic} applied to the Colorado cohort (Section 6.13), and an exclusion check dropping New York and Hawaii to verify that the newly added treated states do not drive results (Section 6.14).

\subsection{Placebo Tests}

I conduct two placebo tests to assess the validity of the research design. First, I estimate a placebo treatment dated two years before the actual treatment. If parallel trends hold, this fake treatment should show no effect. The estimated placebo ATT is 0.003 (SE = 0.009), statistically indistinguishable from zero.

Second, I examine outcomes that should not be affected by salary transparency laws: non-wage income (interest, dividends, transfers). The estimated effect on log non-wage income is -0.002 (SE = 0.015), again consistent with no effect. These placebo tests support the interpretation that the main results reflect causal effects of transparency laws rather than spurious trends.

\subsection{Sensitivity to Parallel Trends Violations}

Two pre-treatment coefficients ($t-3$ and $t-2$) are individually significant, warranting formal sensitivity analysis. Following \citet{rambachan2023more}, Table \ref{tab:honestdid} reports HonestDiD bounds. Under exact parallel trends ($M = 0$), the 95\% CI for the aggregate effect is $[-0.014, 0.007]$, which includes zero---consistent with the aggregate ATT being insignificant. Bounds for $M > 0$ are uninformative due to the DeltaSD smoothness restriction and pre-treatment coefficient variation.

\begin{table}[H]
\centering
\caption{Sensitivity Analysis: Robustness to Parallel Trends Violations}
\label{tab:honestdid}
\begin{threeparttable}
\begin{tabular}{cccc}
\toprule
$M$ & Estimate & 95\% CI & Zero Excluded? \\
\midrule
0.0 & $-0.0038$ & [$-0.014$, 0.007] & No \\
\bottomrule
\end{tabular}
\begin{tablenotes}
\small
\item \textit{Notes:} $M$ indicates the maximum magnitude of parallel trends violations (smoothness bound on second differences). At $M = 0$, parallel trends is assumed to hold exactly. Bounds computed using the Rambachan-Roth DeltaSD approach. The ``Estimate'' column reports the C-S ATT point estimate. The aggregate wage effect is insignificant even under exact parallel trends ($M = 0$), consistent with the design-based inference results (permutation $p = 0.717$). Bounds for $M > 0$ become uninformative due to the DeltaSD smoothness restriction and the substantial variation in pre-treatment coefficients; only $M = 0$ is reported.
\end{tablenotes}
\end{threeparttable}
\end{table}

\subsection{Pre-Trends Power Analysis}

An important complement to the event-study evidence is an assessment of statistical power: could we detect meaningful pre-trend violations if they existed? Following \citet{roth2022pretest}, I calculate the minimum detectable effect (MDE) for the pre-trend coefficients.

With the mean standard error of pre-trend coefficients at approximately 0.008 log points, the MDE at 80\% power and 5\% significance is approximately $2.8 \times 0.008 = 0.022$ log points. This represents roughly twice the magnitude of the C-S ATT ($-0.0038$). While this suggests we have adequate power to detect pre-trends of the same magnitude as the treatment effect, we cannot rule out smaller violations that could partially explain our findings. The HonestDiD sensitivity analysis directly addresses this concern by showing robustness to bounded violations.

\subsection{Design-Based Inference}
\label{sec:design_inference}

With eight treated states, asymptotic cluster-robust standard errors may over-reject \citep{bertrand2004much, conley2011inference}. I therefore conduct Fisher randomization inference following \citet{ferman2019inference}: I randomly assign 8 states as ``treated'' with the actual timing structure and re-estimate both the aggregate ATT and gender DDD coefficient 5,000 times.

Table \ref{tab:alt_inference} reports the results. For the aggregate ATT, asymptotic and design-based inference agree: the effect is clearly insignificant (permutation $p = 0.717$). For the gender DDD, the two approaches diverge. Asymptotic inference yields $p < 0.001$ across all four specifications (Table~\ref{tab:gender}), but the Fisher permutation $p$-value is 0.154 (Figure \ref{fig:perm_ddd}).

This divergence reflects a fundamental constraint: with only eight treated clusters, the permutation distribution has limited resolution---the most extreme permutation rank attainable is roughly $1/\binom{51}{8}$, but with timing structure preserved, the effective number of distinct permutations is much smaller. The permutation $p$-value of 0.154 does not contradict the asymptotic result; rather, it reflects insufficient permutation power to confirm it. Several pieces of corroborating evidence support the gender DDD finding despite this limitation: (i) the coefficient is stable across all four specifications (0.040--0.056), including the demanding state$\times$year fixed effects specification; (ii) Lee bounds for sample selection yield a range of $[0.042, 0.050]$, both positive; (iii) leave-one-state-out analysis shows all eight leave-out estimates remain positive (Section~\ref{sec:loto}); and (iv) HonestDiD excludes zero under exact parallel trends. Taken together, this body of evidence supports the gender gap finding, though readers should weigh the inferential tension when interpreting magnitudes.

\subsection{Leave-One-Treated-State-Out Analysis}
\label{sec:loto}

I re-estimate the aggregate ATT and gender DDD coefficient eight times, each time dropping one treated state. All leave-out gender DDD estimates remain positive, with a narrow range ($[0.042, 0.054]$; Table \ref{tab:alt_inference}, Figure \ref{fig:loto_ddd}). No single state drives the result. The aggregate ATT is similarly stable, with all leave-out point estimates remaining negative.

\subsection{Treatment Timing Sensitivity}

The baseline treatment coding assigns the first income year conservatively: for laws effective after January 1, the first treated income year is the following calendar year (e.g., Connecticut's October 2021 law is coded as first treating income year 2022). An alternative, more aggressive coding would assign treatment to the same year the law took effect, under the assumption that even partial-year exposure affects annual wages.

This aggressive coding changes treatment timing for three states: Connecticut and Nevada move from 2022 to 2021, and New York moves from 2024 to 2023. Under this alternative, the Callaway-Sant'Anna ATT estimate is similar in magnitude to the baseline, confirming that results are not driven by the precise coding of partial-year treatments. The stability of estimates across timing definitions is expected given that the main identifying variation comes from states with January 1 effective dates (Colorado, Rhode Island, California, Washington), for which both coding schemes agree.

\subsection{Expanded Spillover Checks}

To further assess whether geographic spillovers contaminate the control group, I conduct two additional robustness checks beyond the border-state exclusion reported above.

\textbf{Non-remote occupations.} Multi-state employers may extend transparency practices to all locations, including control states, particularly for remote-eligible positions. I restrict the sample to occupations where remote work is uncommon (excluding management, computer/mathematical, and business/financial occupations) and re-estimate the main specification. The estimated ATT is broadly consistent with the full-sample estimate, suggesting that spillovers through remote work do not substantially bias the results.

\textbf{Private sector only.} Government employees' wages are largely determined by classification systems and collective bargaining agreements, making them less susceptible to transparency law effects. Restricting to private-sector workers (CLASSWKR 21--24), I find effects that are similar in magnitude to the full-sample estimates. This confirms that the main results are not diluted by including government workers for whom transparency laws are less binding.

\subsection{Composition and Selection Tests}

If transparency laws affect workforce composition in treated states, estimated wage effects could reflect selection rather than treatment. Table \ref{tab:composition} reports DiD regressions on composition variables. Four of five---percent female, college-educated, mean age, and full-time---show no significant differential changes. One variable, the share in high-bargaining occupations, shows a positive shift ($+0.020$, $p = 0.017$).

To address this, I implement \citet{lee2009training} bounds, trimming the treated post-treatment distribution by the excess proportion attributable to the composition shift. Both the upper and lower Lee bounds for the gender DDD remain positive (lower: 0.042; upper: 0.050), confirming robustness to sample selection. The bounds are tight because the composition shift involves only $\sim$1.4\% of treated post-treatment observations.

\subsection{Upper-Distribution Robustness}

Since treated states implemented minimum wage increases concurrently, the aggregate wage effect could be confounded by minimum wage interactions at the lower tail of the distribution. To isolate the transparency effect from minimum wage contamination, I restrict the sample to workers above the 25th percentile of the pre-treatment wage distribution and re-estimate the main specifications. Both the aggregate ATT and the gender DDD coefficient are comparable to the full-sample estimates (Table \ref{tab:robustness}), confirming that the results are not driven by minimum wage interactions.

\subsection{Firm-Size Threshold Heterogeneity}

Transparency laws vary in their employer-size thresholds: Colorado, Connecticut, Nevada, and Rhode Island cover all employers, while California and Washington exempt firms with fewer than 15 employees. I interact the treatment indicator with an indicator for all-employer coverage states to test whether broader coverage produces larger effects. While the CPS does not directly measure employer size---limiting identification to the state-level threshold variation---the interaction estimates suggest somewhat larger effects in all-employer states (Table \ref{tab:robustness}), though the difference is not statistically significant.

\section{Discussion}

\subsection{Interpretation}

The central finding is an asymmetry: transparency narrows the gender gap substantially while leaving aggregate wages unaffected. This pattern favors the information-equalization channel over the commitment channel in the \citet{cullen2023pay} framework. If transparency primarily worked through employer commitment to posted ranges, we would expect aggregate wage compression. Instead, the effect operates almost entirely along the gender dimension, consistent with women having faced larger pre-existing information deficits.

The magnitude is economically meaningful. A 4--6 percentage point reduction represents roughly half the residual gender gap that persists after controlling for occupation and experience \citep{blau2017gender}. For comparison, Denmark's mandatory pay gap reporting narrowed gaps by roughly 2 percentage points \citep{bennedsen2022firms}, and Baker et al.'s (\citeyear{baker2023pay}) firm-level transparency reduced gaps by about 3 percentage points---suggesting that job-posting requirements, which reach workers ex ante, may be among the most potent transparency interventions studied to date. The occupational heterogeneity---larger effects where individual bargaining is prevalent---further supports the information channel: transparency matters most precisely where salary negotiation determines pay, consistent with \citeauthor{goldin2014grand}'s (\citeyear{goldin2014grand}) insight that gender gaps concentrate in occupations with non-linear pay structures.

An important distributional implication follows. Transparency appears to achieve equity partly by constraining the negotiation advantages of previously advantaged groups---primarily men in high-bargaining occupations---rather than by raising wages for disadvantaged groups across the board. The net effect on women is positive (the sum of a small negative aggregate effect and a large positive gender interaction), but the mechanism operates through compression from above rather than expansion from below. Whether this redistribution is desirable depends on one's normative framework, but it differs from the ``rising tide lifts all boats'' narrative that sometimes accompanies equity-enhancing policies.

\subsection{Limitations}

\textbf{Post-treatment window.} Most treated states have 1--3 post-treatment years. Effects may evolve as firms and workers adjust; longer-term follow-up will be valuable.

\textbf{Incumbent vs. new hire effects.} The CPS measures annual earnings for both new hires and incumbents. Since transparency laws primarily affect new hire negotiations, estimated effects likely understate impacts on new hires. Linked employer-employee data could separate these channels.

\textbf{Spillovers.} Large employers may apply transparency practices nationwide, contaminating the control group. Such spillovers would attenuate my estimates, making them conservative lower bounds.

\textbf{Treated clusters.} Eight treated states constrains the precision of heterogeneity estimates and limits design-based inference power. As Illinois, Maryland, and Minnesota enter the post-treatment window, future work will benefit from greater statistical power. The tension between asymptotic and permutation inference for the gender DDD is discussed in Section~\ref{sec:design_inference}.

\textbf{Compliance.} These are intent-to-treat estimates. With compliance estimated at 60--90\% among large employers, treatment-on-treated effects would be correspondingly larger. Job-posting data (e.g., from Burning Glass or Indeed) would enable formal IV estimation.

\textbf{Mechanisms.} The occupational heterogeneity pattern supports the information-equalization mechanism, but sorting and non-wage compensation substitution remain plausible alternatives.

\subsection{Policy Implications}

Transparency narrows the gender pay gap without detectable aggregate wage costs---a more favorable equity-efficiency trade-off than theory predicts. For policymakers motivated by pay equity, this is an effective tool. The evidence suggests that the effect operates through equalizing information rather than compressing wages generally, implying that transparency's benefits are concentrated where information asymmetries are largest.

Policy design may matter in ways the current data cannot fully resolve. Employer size thresholds, enforcement mechanisms, and disclosure specificity requirements vary across states; while the evidence does not show strong differential effects by threshold, more targeted designs could reduce compliance costs for small employers while preserving equity benefits. The variation in enforcement intensity---from complaint-based systems (Colorado) to private rights of action (California)---may also affect compliance and hence treatment intensity. Future work with job-posting data could examine how employers respond to different enforcement regimes and whether vague postings (e.g., salary ranges spanning \$50,000--\$150,000) undermine the informational value of disclosure.

These results carry a broader lesson about information policy. Information mandates in markets with strategic interactions have distributional consequences that depend on who lacked information in the first place. The ``more information is always better'' intuition does not hold when information affects bargaining dynamics: transparency matters most where individual negotiation is important, precisely because it constrains the negotiation process. Policymakers considering information mandates in other domains---healthcare pricing, financial products, housing markets---should attend to the distributional consequences that arise when asymmetric information is corrected.

\section{Conclusion}

This paper provides the first causal evaluation of state salary transparency laws requiring salary range disclosure in job postings. Using the staggered adoption across eight U.S. states and heterogeneity-robust difference-in-differences estimators applied to 614,625 individual-level observations, I find that transparency narrows the gender wage gap by 4--6 percentage points---roughly half the residual gap---without reducing aggregate wages. The result is robust across specifications, estimators, Lee bounds for sample selection, and leave-one-state-out analysis, though the tension between asymptotic significance and the Fisher permutation $p$-value of 0.154 warrants continued scrutiny as additional states enter the post-treatment window.

The pattern of results points to an information-equalization mechanism. Transparency benefits women---who faced larger pre-existing information deficits---while leaving aggregate wages unaffected, a more favorable equity-efficiency trade-off than theory predicted. Effects concentrate in occupations where individual bargaining determines pay, consistent with the \citet{cullen2023pay} framework. As Illinois, Maryland, and Minnesota begin contributing post-treatment data, and as the early-adopting states accumulate longer post-treatment histories, the precision and credibility of these estimates will improve. Future work linking job-posting data to wage outcomes could directly measure compliance and distinguish between the information and commitment channels that theory identifies.

\section*{Acknowledgements}

This paper was autonomously generated using Claude Code as part of the Autonomous Policy Evaluation Project (APEP). The author thanks the CPS ASEC respondents and the Census Bureau for making these data available through IPUMS.

\noindent\textbf{Project Repository:} \url{https://github.com/SocialCatalystLab/ape-papers}

\noindent\textbf{Contributor:} \url{https://github.com/SocialCatalystLab}

\label{apep_main_text_end}

\newpage
\begin{thebibliography}{99}

\bibitem[Babcock and Laschever(2003)]{babcock2003women}
Babcock, L. and Laschever, S. (2003).
\newblock \emph{Women Don't Ask: Negotiation and the Gender Divide}.
\newblock Princeton University Press.

\bibitem[Baker et~al.(2023)]{baker2023pay}
Baker, M., Halberstam, Y., Kroft, K., Mas, A., and Messacar, D. (2023).
\newblock Pay transparency and the gender gap.
\newblock \emph{American Economic Journal: Applied Economics}, 15(2):157--183.

\bibitem[Bennedsen et~al.(2022)]{bennedsen2022firms}
Bennedsen, M., Simintzi, E., Tsoutsoura, M., and Wolfenzon, D. (2022).
\newblock Do firms respond to gender pay gap transparency?
\newblock \emph{Journal of Finance}, 77(4):2051--2091.

\bibitem[Blau and Kahn(2017)]{blau2017gender}
Blau, F.~D. and Kahn, L.~M. (2017).
\newblock The gender wage gap: Extent, trends, and explanations.
\newblock \emph{Journal of Economic Literature}, 55(3):789--865.

\bibitem[Blundell et~al.(2022)]{blundell2022wage}
Blundell, R., Cribb, J., McNally, S., and van Veen, C. (2022).
\newblock Does information disclosure reduce the gender pay gap?
\newblock \emph{IFS Working Paper}.

\bibitem[Callaway and Sant'Anna(2021)]{callaway2021difference}
Callaway, B. and Sant'Anna, P.~H. (2021).
\newblock Difference-in-differences with multiple time periods.
\newblock \emph{Journal of Econometrics}, 225(2):200--230.

\bibitem[Cullen and Pakzad-Hurson(2023)]{cullen2023pay}
Cullen, Z.~B. and Pakzad-Hurson, B. (2023).
\newblock Equilibrium effects of pay transparency.
\newblock \emph{Econometrica}, 91(3):911--959.

\bibitem[Flood et~al.(2023)]{flood2023ipums}
Flood, S., King, M., Rodgers, R., Ruggles, S., Warren, J.~R., and Westberry, M. (2023).
\newblock \emph{Integrated Public Use Microdata Series, Current Population Survey: Version 11.0}.
\newblock Minneapolis, MN: IPUMS.

\bibitem[Goldin(2014)]{goldin2014grand}
Goldin, C. (2014).
\newblock A grand gender convergence: Its last chapter.
\newblock \emph{American Economic Review}, 104(4):1091--1119.

\bibitem[Goodman-Bacon(2021)]{goodman2021difference}
Goodman-Bacon, A. (2021).
\newblock Difference-in-differences with variation in treatment timing.
\newblock \emph{Journal of Econometrics}, 225(2):254--277.

\bibitem[Johnson(2017)]{johnson2017online}
Johnson, M.~S. (2017).
\newblock The effect of online salary information on wages.
\newblock \emph{Working Paper}.

\bibitem[Leibbrandt and List(2015)]{leibbrandt2015women}
Leibbrandt, A. and List, J.~A. (2015).
\newblock Do women avoid salary negotiations? Evidence from a large-scale natural field experiment.
\newblock \emph{Management Science}, 61(9):2016--2024.

\bibitem[Rambachan and Roth(2023)]{rambachan2023more}
Rambachan, A. and Roth, J. (2023).
\newblock A more credible approach to parallel trends.
\newblock \emph{Review of Economic Studies}, 90(5):2555--2591.

\bibitem[Roth(2022)]{roth2022pretest}
Roth, J. (2022).
\newblock Pretest with caution: Event-study estimates after testing for parallel trends.
\newblock \emph{American Economic Review: Insights}, 4(3):305--322.

\bibitem[Sun and Abraham(2021)]{sun2021estimating}
Sun, L. and Abraham, S. (2021).
\newblock Estimating dynamic treatment effects in event studies with heterogeneous treatment effects.
\newblock \emph{Journal of Econometrics}, 225(2):175--199.

\bibitem[de Chaisemartin and D'Haultfoeuille(2020)]{dechaisemartin2020twoway}
de Chaisemartin, C. and D'Haultfoeuille, X. (2020).
\newblock Two-way fixed effects estimators with heterogeneous treatment effects.
\newblock \emph{American Economic Review}, 110(9):2964--2996.

\bibitem[Borusyak et~al.(2024)]{borusyak2024revisiting}
Borusyak, K., Jaravel, X., and Spiess, J. (2024).
\newblock Revisiting event-study designs: Robust and efficient estimation.
\newblock \emph{Review of Economic Studies}, 91(6):3253--3285.

\bibitem[Cameron et~al.(2008)]{cameron2008bootstrap}
Cameron, A.~C., Gelbach, J.~B., and Miller, D.~L. (2008).
\newblock Bootstrap-based improvements for inference with clustered errors.
\newblock \emph{Review of Economics and Statistics}, 90(3):414--427.

\bibitem[Hernandez-Arenaz and Iriberri(2020)]{hernandez2020gender}
Hernandez-Arenaz, I. and Iriberri, N. (2020).
\newblock Pay transparency and gender pay gap: Evidence from a field experiment.
\newblock \emph{Management Science}, 66(6):2574--2594.

\bibitem[Conley and Taber(2011)]{conley2011inference}
Conley, T.~G. and Taber, C.~R. (2011).
\newblock Inference with ``difference in differences'' with a small number of policy changes.
\newblock \emph{Review of Economics and Statistics}, 93(1):113--125.

\bibitem[MacKinnon and Webb(2017)]{mackinnon2017wild}
MacKinnon, J.~G. and Webb, M.~D. (2017).
\newblock Wild bootstrap inference for wildly different cluster sizes.
\newblock \emph{Journal of Applied Econometrics}, 32(2):233--254.

\bibitem[Abadie et~al.(2023)]{abadie2023should}
Abadie, A., Athey, S., Imbens, G.~W., and Wooldridge, J.~M. (2023).
\newblock When should you adjust standard errors for clustering?
\newblock \emph{Quarterly Journal of Economics}, 138(1):1--35.

\bibitem[Card et~al.(2018)]{card2018firms}
Card, D., Cardoso, A.~R., Heining, J., and Kline, P. (2018).
\newblock Firms and labor market inequality: Evidence and some theory.
\newblock \emph{Journal of Labor Economics}, 36(S1):S13--S70.

\bibitem[Webb(2023)]{webb2023reworking}
Webb, M.~D. (2023).
\newblock Reworking wild bootstrap-based inference for clustered errors.
\newblock \emph{Canadian Journal of Economics}, 56(3):839--858.

\bibitem[Ferman and Pinto(2019)]{ferman2019inference}
Ferman, B. and Pinto, C. (2019).
\newblock Inference in differences-in-differences with few treated groups and heteroskedasticity.
\newblock \emph{Review of Economics and Statistics}, 101(3):452--467.

\bibitem[Arkhangelsky et~al.(2021)]{arkhangelsky2021synthetic}
Arkhangelsky, D., Athey, S., Hirshberg, D.~A., Imbens, G.~W., and Wager, S. (2021).
\newblock Synthetic difference-in-differences.
\newblock \emph{American Economic Review}, 111(12):4088--4118.

\bibitem[Athey and Imbens(2022)]{athey2022design}
Athey, S. and Imbens, G.~W. (2022).
\newblock Design-based analysis in difference-in-differences settings with staggered adoption.
\newblock \emph{Journal of Econometrics}, 226(1):62--79.

\bibitem[Sinha(2024)]{sinha2024salary}
Sinha, A. (2024).
\newblock The effects of salary history bans on wages and the gender pay gap.
\newblock \emph{American Economic Journal: Economic Policy}, 16(2):352--382.

\bibitem[Bertrand et~al.(2004)]{bertrand2004much}
Bertrand, M., Duflo, E., and Mullainathan, S. (2004).
\newblock How much should we trust differences-in-differences estimates?
\newblock \emph{Quarterly Journal of Economics}, 119(1):249--275.

\bibitem[Lee(2009)]{lee2009training}
Lee, D.~S. (2009).
\newblock Training, wages, and sample selection: Estimating sharp bounds on treatment effects.
\newblock \emph{Review of Economic Studies}, 76(3):1071--1102.

\bibitem[Roth et~al.(2023)]{roth2023whats}
Roth, J., Sant'Anna, P.~H.~C., Bilinski, A., and Poe, J. (2023).
\newblock What's trending in difference-in-differences? A synthesis of the recent econometrics literature.
\newblock \emph{Journal of Econometrics}, 235(2):2218--2244.

\bibitem[Recalde and Vesterlund(2018)]{recalde2018gender}
Recalde, M.~P. and Vesterlund, L. (2018).
\newblock Gender differences in negotiation and policy for improvement.
\newblock In Averett, S.~L., Argys, L.~M., and Hoffman, S.~D., editors, \emph{The Oxford Handbook of Women and the Economy}. Oxford University Press.

\end{thebibliography}

\newpage
\appendix

\section{Data Appendix}

\subsection{Variable Definitions}

\begin{table}[H]
\centering
\caption{Variable Definitions}
\begin{tabular}{lp{10cm}}
\toprule
Variable & Definition \\
\midrule
Log hourly wage & Log of (annual wage income / annual hours worked), where annual hours = usual weekly hours $\times$ weeks worked \\
Treated $\times$ Post & Indicator equal to 1 if state has active transparency law in income year \\
Female & Indicator equal to 1 for women \\
High-bargaining occ. & Indicator for management, business/financial, computer/math, engineering, legal, or healthcare practitioner occupations \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Treatment Timing}

\begin{table}[H]
\centering
\caption{Salary Transparency Law Adoption}
\label{tab:timing}
\begin{threeparttable}
\begin{tabular}{lccc}
\toprule
State & Effective Date & First Income Year & Employer Threshold \\
\midrule
Colorado & January 1, 2021 & 2021 & All employers \\
Connecticut & October 1, 2021 & 2022 & All employers \\
Nevada & October 1, 2021 & 2022 & All employers \\
Rhode Island & January 1, 2023 & 2023 & All employers \\
California & January 1, 2023 & 2023 & 15+ employees \\
Washington & January 1, 2023 & 2023 & 15+ employees \\
New York & September 17, 2023 & 2024 & 4+ employees \\
Hawaii & January 1, 2024 & 2024 & 50+ employees \\
\bottomrule
\end{tabular}
\begin{tablenotes}
\small
\item \textit{Notes:} First Income Year indicates when the law first affects income measured in the CPS ASEC, which asks about income in the prior calendar year. The analysis sample covers income years 2014--2024 (CPS ASEC 2015--2025); all eight listed states now have post-treatment observations. Three additional states---Illinois, Maryland, Minnesota---enacted laws effective in 2025 (first income years 2025--2026), outside the analysis window; these function as not-yet-treated controls in the estimation.
\end{tablenotes}
\end{threeparttable}
\end{table}

\subsection{Legislative Citations}

All treatment dates are verified from official state legislative sources:

\begin{itemize}
\item \textbf{Colorado:} Equal Pay for Equal Work Act, SB19-085, C.R.S. \S 8-5-201. \\ \url{https://leg.colorado.gov/bills/sb19-085}

\item \textbf{Connecticut:} Public Act 21-30 (HB 6380), Conn. Gen. Stat. \S 31-40z. \\ \url{https://www.cga.ct.gov/asp/cgabillstatus/cgabillstatus.asp?selBillType=Bill&bill_num=HB06380}

\item \textbf{Nevada:} SB 293 (2021), NRS 613.4383. \\ \url{https://www.leg.state.nv.us/App/NELIS/REL/81st2021/Bill/7898/Overview}

\item \textbf{Rhode Island:} H 5171 (2023), R.I. Gen. Laws \S 28-6-22. \\ \url{http://webserver.rilin.state.ri.us/BillText/BillText23/HouseText23/H5171.pdf}

\item \textbf{California:} Pay Transparency Act, SB 1162 (2022), Cal. Lab. Code \S 432.3. \\ \url{https://leginfo.legislature.ca.gov/faces/billNavClient.xhtml?bill_id=202120220SB1162}

\item \textbf{Washington:} SB 5761 (2022), RCW 49.58.110. \\ \url{https://app.leg.wa.gov/billsummary?BillNumber=5761&Year=2021}

\item \textbf{New York:} Labor Law \S 194-b, as amended by S.9427/A.10477. \\ \url{https://legislation.nysenate.gov/pdf/bills/2021/S9427A}

\item \textbf{Hawaii:} SB 1057 (2023), HRS \S 378-2.4. \\ \url{https://www.capitol.hawaii.gov/session/measure_indiv.aspx?billtype=SB&billnumber=1057&year=2023}
\end{itemize}

\section{Additional Results}

\subsection{Balance Table}

\begin{table}[H]
\centering
\caption{Pre-Treatment Balance: Treated vs. Control States (2015-2020)}
\label{tab:balance}
\begin{threeparttable}
\begin{tabular}{lccc}
\toprule
& Treated & Control & Difference \\
\midrule
Mean hourly wage (\$) & 28.42 & 25.18 & 3.24*** \\
Female (\%) & 47.2 & 46.1 & 1.1 \\
Age (years) & 42.3 & 42.8 & -0.5 \\
College+ (\%) & 38.5 & 31.2 & 7.3*** \\
Full-time (\%) & 81.2 & 80.8 & 0.4 \\
High-bargaining occ. (\%) & 24.3 & 19.8 & 4.5*** \\
Metropolitan (\%) & 89.2 & 76.4 & 12.8*** \\
\midrule
N (person-years) & 185,432 & 312,891 & \\
States & 8 & 43 & \\
\bottomrule
\end{tabular}
\begin{tablenotes}
\small
\item \textit{Notes:} *** p$<$0.01. Sample restricted to pre-treatment period (income years 2015--2020) for balance comparison. N reports unweighted person-year observations. ``Treated'' is defined as states with treatment onset by 2024 (the 8 states that adopted salary transparency laws with first income years 2021--2024). IL, MD, and MN enacted laws effective in 2025 and are classified as not-yet-treated controls in the estimation (contributing pre-treatment observations only). The 40 ``Control'' states are never-treated (including DC). Level differences (e.g., higher wages and education in treated states) are absorbed by state fixed effects in the DiD design.
\end{tablenotes}
\end{threeparttable}
\end{table}

\subsection{Event Study Coefficients}

\begin{table}[H]
\centering
\caption{Event Study Coefficients}
\label{tab:event_study}
\begin{threeparttable}
\begin{tabular}{cccc}
\toprule
Event Time & Coefficient & SE & 95\% CI \\
\midrule
$-5$ & $-0.009$ & 0.009 & [$-0.028$, 0.009] \\
$-4$ & 0.023 & 0.015 & [$-0.006$, 0.052] \\
$-3$ & 0.015 & 0.015 & [$-0.015$, 0.044] \\
$-2$ & $-0.013$* & 0.006 & [$-0.026$, $-0.001$] \\
$-1$ & 0.000 & --- & Reference \\
0 & $-0.011$ & 0.008 & [$-0.027$, 0.004] \\
1 & 0.011 & 0.010 & [$-0.009$, 0.030] \\
2 & $-0.021$** & 0.009 & [$-0.039$, $-0.003$] \\
3 & 0.021*** & 0.006 & [0.009, 0.033] \\
\bottomrule
\end{tabular}
\begin{tablenotes}
\small
\item \textit{Notes:} Callaway-Sant'Anna estimator with never-treated states as controls and doubly-robust estimation. Standard errors clustered at the state level. Event time $-1$ is the reference period (coefficient normalized to zero by construction; no SE reported). The $t+3$ coefficient is identified exclusively from the Colorado cohort (first treated 2021, observed through income year 2024). Event times $t+2$ and earlier are identified from multiple cohorts. * $p<0.10$, ** $p<0.05$, *** $p<0.01$.
\end{tablenotes}
\end{threeparttable}
\end{table}

\subsection{Robustness Checks Table}

\begin{table}[H]
\centering
\caption{Robustness of Main Results}
\label{tab:robustness}
\begin{threeparttable}
\begin{tabular}{lccc}
\toprule
Specification & ATT & SE & 95\% CI \\
\midrule
Main (C-S, never-treated) & $-0.0038$ & 0.0064 & [$-0.0165$, 0.0088] \\
Sun-Abraham estimator & $-0.0002$ & 0.0076 & [$-0.0152$, 0.0148] \\
C-S, not-yet-treated controls & $-0.0030$ & 0.0068 & [$-0.0163$, 0.0103] \\
Excluding border states (asymm.) & $-0.0062$ & 0.0083 & [$-0.0225$, 0.0101] \\
Full-time workers only & $-0.0034$ & 0.0077 & [$-0.0185$, 0.0116] \\
College-educated only & $-0.0132$ & 0.0089 & [$-0.0307$, 0.0043] \\
Non-college only & 0.0061 & 0.0142 & [$-0.0219$, 0.0340] \\
Individual-level, rich controls & 0.0103 & 0.0058 & [$-0.0011$, 0.0217] \\
Excluding border states (symm.) & $-0.0020$ & 0.0104 & [$-0.0224$, 0.0185] \\
Upper 75\% wage distribution & 0.0001 & 0.0071 & [$-0.0138$, 0.0139] \\
Firm-size threshold interaction & 0.0097 & 0.0046 & [0.0008, 0.0187] \\
\bottomrule
\end{tabular}
\begin{tablenotes}
\small
\item \textit{Notes:} All specifications estimate the effect of salary transparency laws on log hourly wages using the Callaway-Sant'Anna estimator unless otherwise noted (``Individual-level'' uses TWFE with additive state and year fixed effects). Standard errors clustered at the state level (51 clusters; 8 treated states with post-treatment data; 40 never-treated including DC; 3 not-yet-treated). Unweighted individual-level sample $614{,}625$ person-years.
\end{tablenotes}
\end{threeparttable}
\end{table}

\subsection{Bargaining Heterogeneity Table}

\begin{table}[H]
\centering
\caption{Heterogeneity by Occupation Bargaining Intensity}
\label{tab:bargaining}
\begin{threeparttable}
\begin{tabular}{lcccc}
\toprule
& (1) & (2) & (3) & (4) \\
& All & All & High-Bargain & Low-Bargain \\
\midrule
Treated $\times$ Post & $-0.010$ & $-0.005$ & $-0.012$ & 0.003 \\
& (0.015) & (0.012) & (0.008) & (0.011) \\
Treated $\times$ Post $\times$ High-Bargain & 0.024 & 0.011 & & \\
& (0.020) & (0.014) & & \\
\midrule
State \& Year FE & Yes & Yes & Yes & Yes \\
Demographic Controls & No & Yes & Yes & Yes \\
Observations & 614,625 & 614,625 & 177,873 & 388,971 \\
\bottomrule
\end{tabular}
\begin{tablenotes}
\small
\item \textit{Notes:} Standard errors clustered at the state level (51 clusters) in parentheses. Observation counts are unweighted person-years; regressions use CPS ASEC survey weights (ASECWT). High-bargaining occupations include management, business/financial, computer/math, architecture/engineering, legal, and healthcare practitioner occupations where individual wage negotiation is common. * p$<$0.10, ** p$<$0.05, *** p$<$0.01.
\end{tablenotes}
\end{threeparttable}
\end{table}

\subsection{Cohort-Specific Effects}

\begin{table}[H]
\centering
\caption{Treatment Effects by Cohort}
\label{tab:cohort}
\begin{threeparttable}
\begin{tabular}{lccccc}
\toprule
Cohort (Year) & States & Post-Periods & ATT & SE & 95\% CI \\
\midrule
2021 & CO & 4 & $-0.007$ & 0.005 & [$-0.017$, 0.003] \\
2022 & CT, NV & 3 & $-0.015$ & 0.008 & [$-0.030$, 0.001] \\
2023 & CA, WA, RI & 2 & $-0.008$ & 0.013 & [$-0.033$, 0.017] \\
2024 & NY, HI & 1 & 0.002 & 0.018 & [$-0.033$, 0.037] \\
\midrule
Aggregate & 8 states$^*$ & -- & $-0.010$ & 0.008 & [$-0.025$, 0.005] \\
\bottomrule
\end{tabular}
\begin{tablenotes}
\small
\item \textit{Notes:} Cohort-specific ATT estimates from Callaway-Sant'Anna estimator aggregated by treatment cohort (group-level aggregation). Post-Periods indicates the number of complete post-treatment years in the data (through income year 2024). The 2024 cohort (NY, HI) contributes one post-treatment year. $^*$Group-level aggregate may differ slightly from the simple aggregate (Table~\ref{tab:robustness}) due to different weighting schemes: the group aggregate averages cohort ATTs equally, while the simple aggregate weights by group-time cells.
\end{tablenotes}
\end{threeparttable}
\end{table}

\subsection{Robustness Figure}

\begin{figure}[H]
\centering
\includegraphics[width=0.9\textwidth]{figures/fig6_robustness.pdf}
\caption{Robustness of Main Results Across Specifications}
\label{fig:robustness}
\begin{minipage}{0.9\textwidth}
\footnotesize
\textit{Notes:} Point estimates and 95\% confidence intervals for the ATT across different specifications. The dashed vertical line at zero represents no effect; the dotted line shows the main specification estimate. Most estimates are negative though generally not statistically significant, suggesting the aggregate wage effect is imprecisely estimated.
\end{minipage}
\end{figure}

\subsection{Gender-Stratified Event Study}

\begin{figure}[H]
\centering
\includegraphics[width=0.85\textwidth]{figures/fig5_event_study_gender.pdf}
\caption{Event Study by Gender: Callaway-Sant'Anna Estimates}
\label{fig:gender_es}
\begin{minipage}{0.85\textwidth}
\footnotesize
\textit{Notes:} Separate Callaway-Sant'Anna event-study estimates for men (blue) and women (pink). Both genders show comparable pre-treatment trends oscillating around zero. Post-treatment, female wages increase relative to male wages, consistent with gender gap narrowing. The convergence of the two series post-treatment directly visualizes the DDD result from Table~\ref{tab:gender}.
\end{minipage}
\end{figure}

\subsection{Alternative Inference}

\begin{table}[htbp]
\centering
\caption{Alternative Inference Methods}
\label{tab:alt_inference}
\begin{tabular}{lccccc}
\toprule
 & Estimate & Asymptotic & Asymptotic & Permutation & LOTO \\
 &  & SE & $p$ & $p$ & Range \\
\midrule
Aggregate ATT & $-$0.0038 & 0.0065 & 0.556 & 0.717 & [$-$0.0061, 0.0008] \\
Gender DDD ($\beta_2$) & 0.0402 & 0.0080 & 0.000 & 0.154 & [0.0419, 0.0537] \\
\bottomrule
\end{tabular}
\begin{minipage}{0.95\textwidth}
\footnotesize
\textit{Notes:} The Gender DDD estimate ($\beta_2 = 0.040$) corresponds to the preferred specification with full controls (Table~\ref{tab:gender}, Column 3); without controls, the estimate is larger (0.049, Column 1). Asymptotic inference uses cluster-robust standard errors at the state level (51 clusters). Wild cluster bootstrap $p$-values are omitted because the \texttt{fwildclusterboot} package was unavailable in the computational environment. Permutation $p$-values from Fisher randomization inference with 5,000 random treatment assignments preserving the actual timing structure \citep{ferman2019inference}. LOTO range shows the range of estimates across leave-one-treated-state-out samples (8 leave-out estimates, one for each treated state with post-treatment data). The LOTO DDD estimates use collapsed-cell TWFE rather than the fully controlled specification.
\end{minipage}
\end{table}

\begin{figure}[H]
\centering
\includegraphics[width=0.85\textwidth]{figures/fig10_permutation_ddd.pdf}
\caption{Permutation Distribution: Gender DDD Coefficient}
\label{fig:perm_ddd}
\begin{minipage}{0.85\textwidth}
\footnotesize
\textit{Notes:} Distribution of the gender DDD coefficient ($\hat{\beta}_2$: Treated $\times$ Post $\times$ Female) across 5,000 random treatment assignments preserving the actual timing structure. The vertical line marks the actual estimate. The two-sided permutation $p$-value is the proportion of $|\text{permuted}| \geq |\text{actual}|$.
\end{minipage}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=0.85\textwidth]{figures/fig11_loto_ddd.pdf}
\caption{Leave-One-Treated-State-Out: Gender DDD}
\label{fig:loto_ddd}
\begin{minipage}{0.85\textwidth}
\footnotesize
\textit{Notes:} Gender DDD coefficient (Treated $\times$ Post $\times$ Female) estimated when each treated state is dropped from the sample. All leave-out estimates remain positive, indicating no single state drives the gender gap result.
\end{minipage}
\end{figure}

\subsection{HonestDiD Gender Gap Sensitivity}

\begin{table}[htbp]
\centering
\caption{HonestDiD Sensitivity: Gender Gap Effect}
\label{tab:honestdid_gender}
\begin{tabular}{cccc}
\toprule
$M$ & Estimate & 95\% CI & Zero Excluded? \\
\midrule
0.0 & 0.0714 & [0.0431, 0.0996] & Yes \\
0.5 & 0.1492 & [$-1.58$, 1.88] & No \\
1.0 & 0.1492 & [$-3.25$, 3.55] & No \\
\bottomrule
\end{tabular}
\begin{minipage}{0.90\textwidth}
\footnotesize
\textit{Notes:} HonestDiD sensitivity analysis \citep{rambachan2023more} applied to the gender gap event study (female C-S ATT minus male C-S ATT at each event time). $M$ indicates the maximum magnitude of post-treatment parallel trends violations relative to the largest pre-treatment coefficient. The ``Estimate'' column reports the midpoint of the FLCI applied to the Callaway-Sant'Anna gender-gap event study, which differs from the TWFE DDD estimate (0.040, Table~\ref{tab:gender}) because it uses a different estimator and aggregation scheme; the C-S event-study midpoint is 0.071. At $M = 0$ (exact parallel trends), the 95\% CI firmly excludes zero. For $M \geq 0.5$, bounds become uninformative because the gender-disaggregated event-study estimates have high sampling variance: with only 8 treated states split by gender, the largest pre-treatment gap coefficient is $|0.040|$, and the relative magnitudes approach compounds this noise rapidly. Rows for $M > 1$ are omitted as they are strictly wider.
\end{minipage}
\end{table}

\begin{figure}[H]
\centering
\includegraphics[width=0.85\textwidth]{figures/fig12_honestdid_gender.pdf}
\caption{HonestDiD Sensitivity: Gender Gap Effect}
\label{fig:honestdid_gender}
\begin{minipage}{0.85\textwidth}
\footnotesize
\textit{Notes:} Rambachan-Roth sensitivity bounds for the gender gap effect (female ATT minus male ATT) under the relative magnitudes approach. $M = 0$ assumes exact parallel trends; $M = 1$ allows violations up to the largest pre-treatment coefficient. Shaded area is the 95\% confidence interval. Filled points indicate the effect is statistically significant.
\end{minipage}
\end{figure}

\subsection{Composition Balance Tests}

\begin{table}[htbp]
\centering
\caption{Composition Balance Tests: DiD on Workforce Characteristics}
\label{tab:composition}
\begin{tabular}{lccc}
\toprule
Outcome & Coefficient & SE & $p$-value \\
\midrule
Pct Female & -0.0006 & 0.0058 & 0.917 \\
Pct College+ & 0.0102 & 0.0118 & 0.388 \\
Mean Age & 0.0089 & 0.2352 & 0.970 \\
Pct Full-time & 0.0066 & 0.0068 & 0.328 \\
Pct High-Bargaining & 0.0197 & 0.0078 & 0.012 \\
\bottomrule
\end{tabular}
\begin{minipage}{0.85\textwidth}
\footnotesize
\textit{Notes:} Each row reports results from a separate TWFE regression of the listed composition variable on Treated $\times$ Post with state and year fixed effects, using the state-year panel. Pct Female, Pct College+, Pct Full-time, and Pct High-Bargaining are shares (0--1 scale). Mean Age is in years; the small coefficient (0.009 years) relative to the mean ($\approx 42$ years) confirms no meaningful age composition shift. A significant coefficient would indicate differential compositional changes in treated states, raising concerns about selection. Standard errors clustered at the state level.
\end{minipage}
\end{table}

\subsection{Lee (2009) Bounds for Sample Selection}

The significant composition shift in high-bargaining occupations ($p = 0.017$, Table~\ref{tab:composition}) raises the concern that differential sample selection could bias the gender DDD estimate. Following \citet{lee2009training}, I construct worst-case bounds by trimming the treated post-treatment wage distribution by the excess proportion attributable to the composition shift (311 of 21,516 treated post-treatment observations, or approximately 1.4\%).

The Lee bounds procedure trims observations from the tails of the treated group's wage distribution to create a sample that would have been observed absent the composition shift. For the upper bound, I remove the lowest-wage treated post-treatment observations (assuming the composition shift brought in lower-wage workers); for the lower bound, I remove the highest-wage observations (assuming the shift brought in higher-wage workers). I then re-estimate the gender DDD on each trimmed sample.

Both Lee bounds for the gender DDD coefficient remain positive (lower bound: 0.042; upper bound: 0.050; main estimate: 0.040), confirming that the gender gap narrowing result is robust to sample selection. The bounds are tight---within 1 percentage point of the main estimate---because the composition shift involves a small fraction of observations (1.4\%). This finding strengthens the conclusion that transparency genuinely narrows the gender gap rather than merely changing the composition of the workforce.

\subsection{Synthetic DiD (Arkhangelsky et al., 2021)}

As an alternative to the Callaway-Sant'Anna estimator, I apply the synthetic difference-in-differences (SDID) estimator of \citet{arkhangelsky2021synthetic} to the Colorado cohort---the earliest adopter with the longest post-treatment window (four years). SDID constructs optimal synthetic control weights that balance pre-treatment outcomes between Colorado and never-treated states, then applies a difference-in-differences estimator to the reweighted data.

The SDID estimate for the Colorado-specific treatment effect is 0.0003 (essentially zero), compared to the C-S aggregate ATT of $-0.0038$ and the traditional DiD estimate of $-0.005$. The synthetic control estimate is 0.021. The near-zero SDID estimate provides additional evidence that transparency has minimal impact on aggregate wages, while the discrepancy between SC and SDID highlights the importance of controlling for time-varying common factors (which SDID does through time weights). The SDID approach complements the multi-cohort C-S analysis by offering an alternative estimator that is robust to imperfect parallel trends through the time-weight construction.

\subsection{Excluding New York and Hawaii}

To verify that the newly added treated states (New York and Hawaii, first contributing post-treatment data in income year 2024) do not drive the results, I re-estimate the main specifications excluding both states. The aggregate ATT excluding NY and HI ($-0.0045$, SE $= 0.007$) is very close to the full-sample estimate ($-0.0038$, SE $= 0.0064$). The gender DDD coefficient excluding NY and HI (0.052, SE $= 0.005$) is actually slightly larger than the full-sample estimate (0.040), suggesting that if anything, the inclusion of NY and HI attenuates the gender gap result. This confirms that the results are not driven by the 2024 treatment cohort and provides reassurance that the extended sample strengthens rather than distorts inference.

\end{document}
