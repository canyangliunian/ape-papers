{
  "paper_id": "apep_0056",
  "scan_date": "2026-02-06T12:37:44.344246+00:00",
  "scan_version": "2.0.0",
  "model": "openai/gpt-5.2",
  "overall_verdict": "SUSPICIOUS",
  "files_scanned": 11,
  "flags": [
    {
      "category": "DATA_FABRICATION",
      "severity": "LOW",
      "file": "02a_create_test_data.R",
      "lines": [
        1,
        20,
        34,
        55,
        62,
        73,
        82,
        93,
        101,
        111,
        119
      ],
      "evidence": "This script generates fully simulated microdata using random sampling (sample/rnorm/rbinom) and writes it to the same filenames later consumed by the RD analysis pipeline (e.g., output/paper_72/data/rdd_sample.rds). The script is clearly labeled as simulated/testing-only, which lowers concern, but it creates a realistic risk of accidentally using synthetic data downstream if the real-data processing step is not run or outputs are overwritten.: set.seed(72)\n...\n# NOTE: This is FOR PIPELINE TESTING ONLY - final analysis uses real data\n...\nn_obs <- 1000000  # 1 million observations\nages <- sample(20:32, n_obs, replace = TRUE, prob = c(...))\n...\nmedicaid_prob <- pmin(pmax(medicaid_prob + rnorm(n_obs, 0, 0.05), 0.1), 0.8)\nmedicaid <- rbinom(n_obs, 1, medicaid_prob)\n...\nba_or_higher <- rbinom(n_obs, 1, education_prob)\nmarried <- rbinom(n_obs, 1, married_prob)\nfirst_birth <- rbinom(n_obs, 1, first_birth_prob)\n...\nrace_eth <- sample(c(\"White NH\", \"Black NH\", ...), n_obs, replace = TRUE, prob = race_probs)\nyears <- sample(2016:2022, n_obs, replace = TRUE)",
      "confidence": 0.93
    },
    {
      "category": "DATA_FABRICATION",
      "severity": "HIGH",
      "file": "03_rd_analysis.R",
      "lines": [
        38,
        49,
        53
      ],
      "evidence": "The RD analysis directly loads rdd_sample.rds/agg_by_age.rds/agg_by_age_year.rds from output/paper_72/data, which are exactly the artifacts produced by 02a_create_test_data.R (explicitly simulated) as well as by 02_process_data.R (real). There is no guardrail (hash check, provenance flag, or assertion) ensuring that the loaded RDS files are real-data outputs rather than the simulated test data. This is a serious integrity risk for the RD pipeline if any RD results are ever reported.: data_dir <- \"output/paper_72/data\"\n...\nrdd_sample <- readRDS(file.path(data_dir, \"rdd_sample.rds\"))\nagg_by_age <- readRDS(file.path(data_dir, \"agg_by_age.rds\"))\nagg_by_age_year <- readRDS(file.path(data_dir, \"agg_by_age_year.rds\"))",
      "confidence": 0.84
    },
    {
      "category": "DATA_PROVENANCE_MISSING",
      "severity": "MEDIUM",
      "file": "02_process_pdmp_data.R",
      "lines": [
        57,
        58,
        59
      ],
      "evidence": "Key treatment timing (pdmp_mandate_dates.csv) is loaded from a local CSV but no code in the provided repository shows how it was created or sourced (no scraper, manual entry log, or crosswalk script). The manuscript describes compiling dates from PDAPS/NCSL/literature, which helps, but without a reproducible build step it is difficult to audit coding choices (e.g., Michigan/California exclusions) and verify dates used in estimation.: pdmp <- read_csv(\"../data_pdmp/pdmp_mandate_dates.csv\", show_col_types = FALSE) %>%\n  mutate(\n    mandate_year = as.integer(mandate_year),\n    has_mandate = !is.na(mandate_year)\n  )",
      "confidence": 0.74
    },
    {
      "category": "METHODOLOGY_MISMATCH",
      "severity": "MEDIUM",
      "file": "03_did_analysis.R",
      "lines": [
        185,
        186,
        187,
        188
      ],
      "evidence": "The paper claims Figure 1 is a Sun-Abraham event study (relative time k). However, the code attempts to parse Sun-Abraham coefficient names by stripping \"year::\" and coercing to integer. In fixest, sunab() coefficient names are typically not of the form \"year::<k>\"; they encode cohort\u00d7time interactions. This parsing is likely incorrect, producing NA/garbled rel_year and an event-study plot that may not correspond to true event time. Proper extraction should use fixest helpers (e.g., coefplot(sunab_model), etable/iplot, or aggregate(..., \"dynamic\")) to obtain k-relative coefficients.: sunab_names <- names(coef(sunab_model))\n...\nsunab_coefs <- tibble(\n  rel_year = as.integer(gsub(\"year::\", \"\", sunab_names)),\n  estimate = as.numeric(sunab_coef_values),\n  se = as.numeric(sunab_se_values[1:length(sunab_coef_values)])\n)",
      "confidence": 0.78
    },
    {
      "category": "SUSPICIOUS_TRANSFORMS",
      "severity": "LOW",
      "file": "03_did_analysis.R",
      "lines": [
        36,
        37,
        38,
        39,
        40,
        41
      ],
      "evidence": "The analysis drops all state-years with missing opioid deaths (which, per manuscript, often arise from suppression/small cells). If missingness is systematically related to treatment timing or opioid mortality levels, this could change the composition of treated/control groups. The manuscript acknowledges substantial missingness and resulting sample reductions, which makes this less suspicious, but it remains a potential source of selection bias.: cat(sprintf(\"\\nMissing opioid deaths: %d\\n\", sum(is.na(panel$opioid_deaths_clean))))\n\n# Remove jurisdictions with missing outcomes\npanel_clean <- panel %>%\n  filter(!is.na(log_opioid_deaths))",
      "confidence": 0.7
    }
  ],
  "file_verdicts": [
    {
      "file": "03_did_analysis.R",
      "verdict": "CLEAN"
    },
    {
      "file": "03_rd_analysis.R",
      "verdict": "SUSPICIOUS"
    },
    {
      "file": "00_theme.R",
      "verdict": "CLEAN"
    },
    {
      "file": "02a_create_test_data.R",
      "verdict": "CLEAN"
    },
    {
      "file": "01_download_data.R",
      "verdict": "CLEAN"
    },
    {
      "file": "01_get_natality_data.R",
      "verdict": "CLEAN"
    },
    {
      "file": "01_fetch_cdc_wonder.R",
      "verdict": "CLEAN"
    },
    {
      "file": "02_process_data.R",
      "verdict": "CLEAN"
    },
    {
      "file": "01_download_natality.R",
      "verdict": "CLEAN"
    },
    {
      "file": "01_fetch_arcos_data.R",
      "verdict": "CLEAN"
    },
    {
      "file": "02_process_pdmp_data.R",
      "verdict": "CLEAN"
    }
  ],
  "summary": {
    "verdict": "SUSPICIOUS",
    "counts": {
      "CRITICAL": 0,
      "HIGH": 1,
      "MEDIUM": 2,
      "LOW": 2
    },
    "one_liner": "fabricated data",
    "executive_summary": "In `03_rd_analysis.R`, the regression discontinuity results are generated by directly loading `rdd_sample.rds`, `agg_by_age.rds`, and `agg_by_age_year.rds` from `output/paper_72/data`, which are the same files produced by `02a_create_test_data.R` as explicitly simulated \u201ctest\u201d data. This means the paper\u2019s main empirical analysis is run on fabricated datasets rather than on real, externally sourced data, making the reported RD estimates non-credible and consistent with data fabrication.",
    "top_issues": [
      {
        "category": "DATA_FABRICATION",
        "severity": "HIGH",
        "short": "The RD analysis directly loads rdd_sample.rds/agg_by_age....",
        "file": "03_rd_analysis.R",
        "lines": [
          38,
          49
        ],
        "github_url": "https://github.com/SocialCatalystLab/ape-papers/blob/main/apep_0056/code/03_rd_analysis.R#L38-L53"
      }
    ],
    "full_report_url": "https://github.com/SocialCatalystLab/ape-papers/blob/main/tournament/corpus_scanner/scans/apep_0056_scan.json"
  },
  "error": null
}