{
  "paper_id": "apep_0178",
  "scan_date": "2026-02-06T12:58:25.787148+00:00",
  "scan_version": "2.0.0",
  "model": "openai/gpt-5.2",
  "overall_verdict": "SUSPICIOUS",
  "files_scanned": 10,
  "flags": [
    {
      "category": "METHODOLOGY_MISMATCH",
      "severity": "HIGH",
      "file": "02_clean_data.R",
      "lines": [
        86,
        105,
        147,
        176,
        205
      ],
      "evidence": "Key sample construction and variable definitions described in paper.tex are not implemented in the cleaning code. The manuscript states: (i) restrict to positive earnings and explicitly exclude earnings < $1,000 and > $500,000; (ii) exclude 2020 and define a COVID indicator as 2021\u20132022 vs 2019; (iii) exclude group quarters; (iv) exclude imputed values on key variables. In code, log earnings is computed as log(pmax(earnings,1)) with no $1,000/$500,000 trimming; covid_period is coded as {2020,2021} (but 2020 is not even fetched, and 2022 is misclassified as non-COVID); and there is no handling of group quarters or imputation flags. These differences can materially change estimates and directly undermine consistency with the manuscript\u2019s reported identification/sample.: acs_clean <- acs_raw %>%\n  mutate(\n    ...\n    earnings = pmax(PINCP, 0),\n    log_earnings = log(pmax(earnings, 1)),\n    ...\n    covid_period = as.integer(year %in% c(2020, 2021))\n  )\n...\nacs_analysis <- acs_clean %>%\n  filter(\n    age >= 25 & age <= 54,\n    employed == 1,\n    !is.na(weight) & weight > 0,\n    !is.na(self_employed),\n    !is.na(earnings),\n    !is.na(educ_years)\n  )",
      "confidence": 0.9
    },
    {
      "category": "METHODOLOGY_MISMATCH",
      "severity": "HIGH",
      "file": "08_gender_analysis.R",
      "lines": [
        1,
        12,
        62,
        190,
        235
      ],
      "evidence": "While paper.tex analyzes ACS self-employment (incorporated/unincorporated) with IPW, the codebase uses legacy naming from a different project ('multiple_jobs', 'cps') and repeatedly describes the estimand as about multiple job holding. This is not merely cosmetic: it increases risk of using the wrong treatment definition in downstream scripts and makes auditing/reproducibility difficult. Given the manuscript\u2019s central claims are about incorporation vs unincorporated self-employment returns, the inconsistent naming and comments raise a substantial integrity/reliability concern unless the authors can demonstrate that all downstream objects and tables/figures are built from the ACS-derived treatment (COW-based) and not from an actual CPS multiple-job variable.: # Load analysis data\ncps <- readRDS(file.path(data_dir, \"cps_analysis.rds\"))\n...\n# Note: Treatment is \"multiple_jobs\" ...\nestimate_gender_effect <- function(data, treatment_var = \"multiple_jobs\", ...)\n...\n# Incorporated effects by gender\nfilter(multiple_jobs == 0 | incorporated == 1) %>%\nmutate(treatment = incorporated)\n...\n# Unincorporated effects by gender\nfilter(multiple_jobs == 0 | unincorporated == 1) %>%\nmutate(treatment = unincorporated)",
      "confidence": 0.85
    },
    {
      "category": "DATA_PROVENANCE_MISSING",
      "severity": "MEDIUM",
      "file": "paper.tex",
      "lines": [
        1,
        140,
        230,
        320
      ],
      "evidence": "The manuscript contains fully populated result tables and narrative estimates (coefficients, confidence intervals, Ns) as literal LaTeX numbers, but the provided code does not include a pipeline that writes these exact tables into paper.tex (or a LaTeX table file that is input by paper.tex). The only table-writing script provided (06_tables.R) produces tables for a different project framing (multiple job holding; CPS ASEC 2015\u20132024) and outputs different filenames/labels. As provided, the provenance of the manuscript\u2019s numeric results is not reproducible from the codebase, which is a research-integrity red flag unless there are missing scripts or the repository structure differs from what\u2019s shown here.: Table \\ref{tab:main} presents the main estimates. The aggregate self-employment penalty is $-0.362$ log points ...\n...\n\\begin{table}[H]\n... (tables with coefficients/CI/N) ...\n\\end{table}\n...\n\\includegraphics{figures/fig14_atlas_combined.pdf}",
      "confidence": 0.8
    },
    {
      "category": "HARD_CODED_RESULTS",
      "severity": "MEDIUM",
      "file": "paper.tex",
      "lines": [
        250,
        330,
        430,
        520
      ],
      "evidence": "Key empirical results (point estimates, confidence intervals, significance stars, and sample sizes) appear hard-coded directly into the LaTeX manuscript rather than being programmatically generated from model objects. Hard-coding in the manuscript is not automatically misconduct, but given (i) the mismatch between manuscript topic and provided table-generation code, and (ii) inability to trace these exact numbers to outputs saved by the scripts shown, this should be treated as a reproducibility/integrity concern requiring clarification (e.g., provide the script that generates Table \\ref{tab:main} and other tables, or link paper.tex to generated .tex table inputs).: \\multicolumn{4}{l}{\\textit{Panel A: Aggregate Self-Employment (ATE)}} \\\\\nSelf-Employed & $-$0.362*** & $-$0.161*** & $-$1.60*** \\\\\n              & [$-$0.371, $-$0.354] & [$-$0.164, $-$0.159] & [$-$1.69, $-$1.51] \\\\\n...\nIncorporated Self-Emp. & +0.069*** & $-$0.075*** & +1.18*** \\\\\n...\nUnincorporated Self-Emp. & $-$0.623*** & $-$0.213*** & $-$3.26*** \\\\\n...\nN (aggregate analysis) & 1,397,605 & 1,397,605 & 1,397,605 \\\\",
      "confidence": 0.85
    },
    {
      "category": "SUSPICIOUS_TRANSFORMS",
      "severity": "MEDIUM",
      "file": "02_clean_data.R",
      "lines": [
        118,
        122
      ],
      "evidence": "The outcome construction silently top-codes negative incomes at 0 and then logs after flooring at 1. This can substantially affect self-employment comparisons because business income can be negative and because the paper claims a restriction to positive earnings with explicit thresholds (>= $1,000). The pmax() approach changes the estimand (e.g., treating losses as zero income) and can mechanically compress variance and attenuate/alter penalties/premia. If the manuscript\u2019s stated restriction is intended, the code should implement those thresholds and document handling of zero/negative income explicitly.: earnings = pmax(PINCP, 0),  # Total personal income (includes self-emp income)\nlog_earnings = log(pmax(earnings, 1))",
      "confidence": 0.85
    },
    {
      "category": "METHODOLOGY_MISMATCH",
      "severity": "MEDIUM",
      "file": "01_fetch_data.R",
      "lines": [
        1,
        78,
        95
      ],
      "evidence": "The fetch script\u2019s header and project labeling indicate a different paper/topic ('Insurance Value of Secondary Employment'), and the code uses development-oriented comments ('sample of large states for faster development'). While the years/state selection match the manuscript, this inconsistent framing increases the risk of mixing outputs across projects and makes it harder to verify that the manuscript\u2019s analyses were produced from a clean, dedicated pipeline for this paper.: # Fetch ACS PUMS data via Census API\n# Paper 154: The Insurance Value of Secondary Employment\n...\n# Fetch data for years 2019-2022\nyears <- c(2019, 2021, 2022)  # Skip 2020 (ACS issues)",
      "confidence": 0.7
    }
  ],
  "file_verdicts": [
    {
      "file": "09_atlas_figures.R",
      "verdict": "CLEAN"
    },
    {
      "file": "01_fetch_data.R",
      "verdict": "CLEAN"
    },
    {
      "file": "08_gender_analysis.R",
      "verdict": "SUSPICIOUS"
    },
    {
      "file": "06_tables.R",
      "verdict": "CLEAN"
    },
    {
      "file": "00_packages.R",
      "verdict": "CLEAN"
    },
    {
      "file": "07_state_analysis.R",
      "verdict": "CLEAN"
    },
    {
      "file": "04_robustness.R",
      "verdict": "CLEAN"
    },
    {
      "file": "02_clean_data.R",
      "verdict": "SUSPICIOUS"
    },
    {
      "file": "03_main_analysis.R",
      "verdict": "CLEAN"
    },
    {
      "file": "05_figures.R",
      "verdict": "CLEAN"
    }
  ],
  "summary": {
    "verdict": "SUSPICIOUS",
    "counts": {
      "CRITICAL": 0,
      "HIGH": 2,
      "MEDIUM": 4,
      "LOW": 0
    },
    "one_liner": "method mismatch",
    "executive_summary": "The data-cleaning script (02_clean_data.R) does not implement the sample construction and key variable definitions described in the manuscript\u2014for example, the paper\u2019s stated restriction to positive earnings and explicit exclusions are not actually applied in the cleaning code. The main gender analysis script (08_gender_analysis.R) appears misaligned with the paper\u2019s ACS self-employment (incorporated/unincorporated) IPW methodology, instead using legacy variable names and project references (e.g., \u201cmultiple_jobs,\u201d \u201ccps\u201d) and describing an estimation setup that does not match the manuscript, raising concerns that the reported results may not be reproducible from this codebase.",
    "top_issues": [
      {
        "category": "METHODOLOGY_MISMATCH",
        "severity": "HIGH",
        "short": "Key sample construction and variable definitions describe...",
        "file": "02_clean_data.R",
        "lines": [
          86,
          105
        ],
        "github_url": "https://github.com/SocialCatalystLab/ape-papers/blob/main/apep_0178/code/02_clean_data.R#L86-L205"
      },
      {
        "category": "METHODOLOGY_MISMATCH",
        "severity": "HIGH",
        "short": "While paper.tex analyzes ACS self-employment (incorporate...",
        "file": "08_gender_analysis.R",
        "lines": [
          1,
          12
        ],
        "github_url": "https://github.com/SocialCatalystLab/ape-papers/blob/main/apep_0178/code/08_gender_analysis.R#L1-L235"
      }
    ],
    "full_report_url": "https://github.com/SocialCatalystLab/ape-papers/blob/main/tournament/corpus_scanner/scans/apep_0178_scan.json"
  },
  "error": null
}