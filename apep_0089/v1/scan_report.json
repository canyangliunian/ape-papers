{
  "paper_id": "apep_0089",
  "scan_date": "2026-02-06T12:44:12.719627+00:00",
  "scan_version": "2.0.0",
  "model": "openai/gpt-5.2",
  "overall_verdict": "SUSPICIOUS",
  "files_scanned": 7,
  "flags": [
    {
      "category": "METHODOLOGY_MISMATCH",
      "severity": "HIGH",
      "file": "06_tables.R",
      "lines": [
        44,
        53
      ],
      "evidence": "The table note claims the sample is \"50 states plus DC, 2000-2023\", but the manuscript and analysis scripts define the estimation sample as 2014\u20132024 and 31 states (8 treated + 23 never-treated). This is a reporting/replication mismatch: readers could believe results come from a much larger panel than the code actually uses for DiD. If this note is used in the paper, it materially misdescribes the empirical design.: footnote(general = \"Notes: Sample includes 50 states plus DC, 2000-2023. FPA States are those that adopted Full Practice Authority for nurse practitioners. Non-FPA States have reduced or restricted practice laws.\",\n           threeparttable = TRUE)",
      "confidence": 0.9
    },
    {
      "category": "METHODOLOGY_MISMATCH",
      "severity": "MEDIUM",
      "file": "02_clean_data.R",
      "lines": [
        112,
        118
      ],
      "evidence": "Comment says the main analysis uses a complete/balanced panel for 2014\u20132024 (11 years), but the code only requires n() >= 10, which explicitly permits incomplete panels. If missingness is nonrandom (e.g., suppression/coverage issues in QCEW for certain state-years), allowing unbalanced panels can change identifying comparisons and influence ATTs/event-study paths.: analysis_main <- analysis_clean %>%\n  filter(year >= 2014, year <= 2024) %>%\n  # Keep states with complete panels (2014-2024 = 11 years)\n  group_by(state_fips) %>%\n  filter(n() >= 10) %>%  # Need at least 10 years\n  ungroup()",
      "confidence": 0.8
    },
    {
      "category": "DATA_PROVENANCE_MISSING",
      "severity": "MEDIUM",
      "file": "01_fetch_data.R",
      "lines": [
        24,
        94
      ],
      "evidence": "Treatment timing (FPA adoption years) is manually hard-coded in the script rather than fetched from a cited machine-readable source, and several entries appear inconsistent with the manuscript's own appendix table (paper.tex lists many early adopters with different years: e.g., WA 1994, NH 1998, AZ 2001, HI 2006, ID 2004, DC 2014, RI 2013, WY 2014, etc.). Because cohort assignment is central to staggered DiD, discrepancies in adoption dates can materially change estimates. At minimum, the code should reconcile to the paper\u2019s stated dates or document/verify the alternative coding.: fpa_dates <- tribble(\n  ~state_abbr, ~state_name, ~fpa_year, ~source,\n  ...\n  \"WA\", \"Washington\", 1990, \"AANP - early pioneer\",\n  \"NH\", \"New Hampshire\", 1990, \"AANP - early pioneer\",\n  ...\n  \"DC\", \"District of Columbia\", 2000, \"AANP\",\n  ...\n  \"RI\", \"Rhode Island\", 2008, \"DePriest et al. 2020\",\n  ...\n  \"ID\", \"Idaho\", 2000, \"AANP\",\n  \"HI\", \"Hawaii\", 2000, \"AANP\"",
      "confidence": 0.75
    },
    {
      "category": "SUSPICIOUS_TRANSFORMS",
      "severity": "LOW",
      "file": "02_clean_data.R",
      "lines": [
        55,
        63
      ],
      "evidence": "The manuscript describes log employment; adding 1 is typically used to handle zeros. For NAICS 6211 state totals, zeros are unlikely; if they occur due to suppression/missing recoded as 0, +1 could mask data quality problems. Not necessarily problematic, but should be justified and checked (e.g., confirm whether any employment==0 values exist and why).: log_emp = log(employment + 1),\nlog_estab = log(establishments + 1),",
      "confidence": 0.6
    },
    {
      "category": "SELECTIVE_REPORTING",
      "severity": "MEDIUM",
      "file": "04_robustness.R",
      "lines": [
        12,
        26
      ],
      "evidence": "Placebo tests are explicitly omitted and replaced with NULL placeholders. Given QCEW API supports many industries via the same endpoint pattern used elsewhere in the code, the stated limitation is not clearly binding from the code context. Skipping placebo/falsification checks reduces transparency and can facilitate selective presentation of validation exercises.: cat(\"Skipping placebo tests due to API limitations for other industry codes.\\n\")\ncat(\"Placebo validation can be done manually with downloaded QCEW data.\\n\")\n\n# Create placeholder for consistency\nplacebo_results <- list()\nplacebo_results[[\"Manufacturing\"]] <- NULL\nplacebo_results[[\"Retail\"]] <- NULL",
      "confidence": 0.7
    }
  ],
  "file_verdicts": [
    {
      "file": "01_fetch_data.R",
      "verdict": "CLEAN"
    },
    {
      "file": "06_tables.R",
      "verdict": "SUSPICIOUS"
    },
    {
      "file": "00_packages.R",
      "verdict": "CLEAN"
    },
    {
      "file": "04_robustness.R",
      "verdict": "CLEAN"
    },
    {
      "file": "02_clean_data.R",
      "verdict": "CLEAN"
    },
    {
      "file": "03_main_analysis.R",
      "verdict": "CLEAN"
    },
    {
      "file": "05_figures.R",
      "verdict": "CLEAN"
    }
  ],
  "summary": {
    "verdict": "SUSPICIOUS",
    "counts": {
      "CRITICAL": 0,
      "HIGH": 1,
      "MEDIUM": 3,
      "LOW": 1
    },
    "one_liner": "method mismatch",
    "executive_summary": "The table-generation code in `06_tables.R` reports a note stating the estimation sample is \u201c50 states plus DC, 2000\u20132023,\u201d but the rest of the manuscript and analysis scripts define and use a different sample: 2014\u20132024 and only 31 states (8 treated + 23 never-treated). This inconsistency means the tables are labeled with incorrect sample coverage, undermining the validity and interpretability of the reported results.",
    "top_issues": [
      {
        "category": "METHODOLOGY_MISMATCH",
        "severity": "HIGH",
        "short": "The table note claims the sample is \"50 states plus DC, 2...",
        "file": "06_tables.R",
        "lines": [
          44,
          53
        ],
        "github_url": "/apep_0089/code/06_tables.R#L44-L53"
      }
    ],
    "full_report_url": "/tournament/corpus_scanner/scans/apep_0089_scan.json"
  },
  "error": null
}