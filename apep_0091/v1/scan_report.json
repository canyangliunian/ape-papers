{
  "paper_id": "apep_0091",
  "scan_date": "2026-02-06T12:44:53.580326+00:00",
  "scan_version": "2.0.0",
  "model": "openai/gpt-5.2",
  "overall_verdict": "SEVERE",
  "files_scanned": 13,
  "flags": [
    {
      "category": "DATA_FABRICATION",
      "severity": "HIGH",
      "file": "01_fetch_data.R",
      "lines": [
        256,
        275
      ],
      "evidence": "If the OpenStreetMap Overpass query fails, the script silently substitutes a hand-constructed 'minimal dispensary dataset' of four 'known locations'. This is synthetic data creation that can materially change downstream distance measures, first-stage validation, maps, and any distance-to-dispensary regressions. The manuscript claims 1,399 dispensaries from OSM; this fallback would violate that claim unless explicitly flagged and prevented from being used for analysis outputs.: if (httr::status_code(response) == 200) {\n  ...\n} else {\n  cat(\"Warning: OSM query failed. Status:\", httr::status_code(response), \"\\n\")\n\n  # Create minimal dispensary dataset from known locations\n  known_dispensaries <- data.frame(\n    name = c(\"Trinidad Dispensary\", \"Fort Collins Dispensary\", \"Ontario Dispensary\", \"Spokane Dispensary\"),\n    lat = c(37.169, 40.585, 44.025, 47.658),\n    lon = c(-104.500, -105.084, -116.963, -117.426)\n  )\n  dispensaries_sf <- st_as_sf(known_dispensaries, coords = c(\"lon\", \"lat\"), crs = 4326)\n  saveRDS(dispensaries_sf, \"../data/dispensaries_sf.rds\")\n  cat(\"Created minimal dispensary dataset with known locations.\\n\")\n}",
      "confidence": 0.9
    },
    {
      "category": "HARD_CODED_RESULTS",
      "severity": "HIGH",
      "file": "06_tables_v2.R",
      "lines": [
        24,
        46
      ],
      "evidence": "Key summary statistics (single-vehicle and rural shares) are inserted as literals labeled 'approximate' rather than computed from the analysis dataset. If these numbers appear in the manuscript tables, they are not reproducible from the code and may not match the actual sample used.: summary_df <- data.frame(\n  Statistic = c(\"N Crashes\", \"Alcohol Involvement (%)\", \"Nighttime (%)\", \"Weekend (%)\", \"Single Vehicle (%)\", \"Rural (%)\"),\n  All = c(\n    format(nrow(crashes), big.mark = \",\"),\n    sprintf(\"%.1f\", mean(crashes$alcohol_involved) * 100),\n    sprintf(\"%.1f\", mean(crashes$is_nighttime, na.rm = TRUE) * 100),\n    sprintf(\"%.1f\", mean(crashes$is_weekend, na.rm = TRUE) * 100),\n    sprintf(\"%.1f\", 48.3),  # approximate single vehicle rate\n    sprintf(\"%.1f\", 42.1)   # approximate rural rate\n  ),\n  Legal = c(\n    ...\n    sprintf(\"%.1f\", 47.8),  # approximate single vehicle rate\n    sprintf(\"%.1f\", 38.9)   # approximate rural rate\n  ),\n  Prohibition = c(\n    ...\n    sprintf(\"%.1f\", 49.5),  # approximate single vehicle rate\n    sprintf(\"%.1f\", 50.4)   # approximate rural rate\n  ),\n  Border150km = c(\n    ...\n    sprintf(\"%.1f\", 49.1),  # approximate single vehicle rate\n    sprintf(\"%.1f\", 55.2)   # approximate rural rate\n  )\n)",
      "confidence": 0.85
    },
    {
      "category": "HARD_CODED_RESULTS",
      "severity": "CRITICAL",
      "file": "06_tables_v2.R",
      "lines": [
        55,
        94
      ],
      "evidence": "This script fabricates alternative-specification RDD estimates/SEs by multiplying the baseline estimate/SE by arbitrary constants, hard-codes p-values, and hard-codes N. These are not computed from rdrobust outputs. If used to generate manuscript Table 2 (or similar), the reported robustness/specification results are not credible.: rdd_results <- data.frame(\n  Specification = c(\"Baseline\", \"Quadratic\", \"0.5x BW\", \"1.5x BW\", \"2x BW\"),\n  Estimate = c(\n    sprintf(\"%.3f\", main_results$main_estimate),\n    sprintf(\"%.3f\", main_results$main_estimate * 1.2),\n    sprintf(\"%.3f\", main_results$main_estimate * 1.3),\n    sprintf(\"%.3f\", main_results$main_estimate * 0.75),\n    sprintf(\"%.3f\", main_results$main_estimate * 0.43)\n  ),\n  SE = c(\n    sprintf(\"(%.3f)\", main_results$main_se),\n    sprintf(\"(%.3f)\", main_results$main_se * 1.4),\n    sprintf(\"(%.3f)\", main_results$main_se * 1.44),\n    sprintf(\"(%.3f)\", main_results$main_se * 0.83),\n    sprintf(\"(%.3f)\", main_results$main_se * 0.71)\n  ),\n  pvalue = c(\"0.127\", \"0.173\", \"0.158\", \"0.163\", \"0.347\"),\n  Bandwidth = c(\n    sprintf(\"%.1f\", main_results$optimal_bandwidth),\n    sprintf(\"%.1f\", main_results$optimal_bandwidth * 1.37),\n    sprintf(\"%.1f\", main_results$optimal_bandwidth * 0.5),\n    sprintf(\"%.1f\", main_results$optimal_bandwidth * 1.5),\n    sprintf(\"%.1f\", main_results$optimal_bandwidth * 2)\n  ),\n  N = c(1446, 2093, 562, 2275, 2888)\n)",
      "confidence": 0.95
    },
    {
      "category": "HARD_CODED_RESULTS",
      "severity": "HIGH",
      "file": "06_tables_v2.R",
      "lines": [
        104,
        128
      ],
      "evidence": "One column ('Weekend Night') is inserted with hard-coded coefficient, SE, and N rather than being computed from a model object (unlike the other rows). If this feeds the paper\u2019s distance-to-dispensary table, at least one reported result is not reproducible.: dist_results <- data.frame(\n  Specification = c(\"All Crashes\", \"Nighttime\", \"Daytime\", \"Weekend Night\"),\n  Coefficient = c(sprintf(\"%.3f\", coef_all), sprintf(\"%.3f\", coef_night), sprintf(\"%.3f\", coef_day), \"0.003\"),\n  SE = c(sprintf(\"(%.3f)\", se_all), sprintf(\"(%.3f)\", se_night), sprintf(\"(%.3f)\", se_day), \"(0.025)\"),\n  N = c(n_all, n_night, n_day, 1358),\n  MeanAlcohol = c(\"28.0%\", \"45.2%\", \"20.5%\", \"51.3%\")\n)",
      "confidence": 0.9
    },
    {
      "category": "DATA_PROVENANCE_MISSING",
      "severity": "HIGH",
      "file": "01_fetch_data.R",
      "lines": [
        96,
        205
      ],
      "evidence": "The pipeline may produce a crash dataset where the key outcome ingredient (DRUNK_DR) is missing and set to NA. Downstream, 02_clean_data.R defines alcohol_involved = as.integer(drunk_dr >= 1) and then filters out NA outcomes. If the API or the accident-file download does not include DRUNK_DR, the effective analysis sample and outcome construction depend on undocumented API field availability rather than a stable, documented FARS extract/merge (accident-vehicle-person). This creates a provenance/reproducibility risk for the central outcome variable.: # Collect all crashes\nall_crashes <- list()\n...\n# Combine all crashes\nif (length(all_crashes) > 0) {\n  fars_raw <- bind_rows(all_crashes)\n  ...\n} else {\n  # If API fails, try the public FARS download\n  ...\n  # Read accident file\n  acc_file <- list.files(temp_extract, pattern = \"accident\", ignore.case = TRUE, full.names = TRUE)[1]\n  ...\n  acc_data <- read.csv(acc_file, stringsAsFactors = FALSE)\n  ...\n}\n...\n# Handle DRUNK_DR column (may be named differently)\nif (!\"drunk_dr\" %in% names(fars_clean)) {\n  ...\n  } else {\n    # If no alcohol variable, set to NA for now\n    fars_clean$drunk_dr <- NA\n    cat(\"Warning: No DRUNK_DR column found. Will need person-level data.\\n\")\n  }\n}",
      "confidence": 0.75
    },
    {
      "category": "METHODOLOGY_MISMATCH",
      "severity": "CRITICAL",
      "file": "01_fetch_data.R",
      "lines": [
        12,
        46
      ],
      "evidence": "The manuscript explicitly states treatment is time-varying (CA legal only after Jan 2018; NV legal only after Jul 2017; CA/NV pre-period crashes should be coded as control). The code assigns legal_status as a time-invariant state attribute, treating CA and NV as legal for all years (2016\u20132019). This directly conflicts with the paper\u2019s described identification strategy and changes both the treatment indicator and the running variable sign assignment.: legal_fips <- c(\"06\", \"08\", \"32\", \"41\", \"53\")\n...\nstates_sf <- states_sf %>%\n  mutate(\n    legal_status = case_when(\n      STATEFP %in% legal_fips ~ \"Legal\",\n      TRUE ~ \"Prohibition\"\n    )\n  )",
      "confidence": 0.95
    },
    {
      "category": "METHODOLOGY_MISMATCH",
      "severity": "HIGH",
      "file": "02_clean_data.R",
      "lines": [
        18,
        47
      ],
      "evidence": "The manuscript describes constructing legal\u2013prohibition border segments programmatically as a function of crash date (different border regimes over time). The code instead creates a single static border union from borders_sf (which itself is built from time-invariant legal/prohibition assignments) and then signs distance using time-invariant legal_status. There is no crash-date-specific border set, so the implemented running variable does not match the paper\u2019s stated design.: # Combine all borders into single multilinestring\nall_borders <- borders_sf %>%\n  st_union() %>%\n  st_sf()\n...\n# Determine sign based on legal status\nlegal_status <- point_sf$legal_status\n...\nsigned_dist <- ifelse(legal_status == \"Legal\", -dist_km, dist_km)",
      "confidence": 0.9
    },
    {
      "category": "SUSPICIOUS_TRANSFORMS",
      "severity": "MEDIUM",
      "file": "07_distance_analysis.R",
      "lines": [
        112,
        121
      ],
      "evidence": "Crash timing is approximated as July 1 of each year, which can misclassify 'post_treatment' around legalization start dates (e.g., Nevada Jul 2017, California Jan 2018). The manuscript emphasizes correct date-based treatment assignment. This approximation can attenuate effects or create spurious pre/post comparisons.: mutate(\n  treatment_date = sapply(NAME, get_treatment_date) %>% as.Date(origin = \"1970-01-01\"),\n  crash_date = as.Date(paste(year, \"07\", \"01\", sep = \"-\")),  # Mid-year approximation\n  post_treatment = as.integer(crash_date >= treatment_date),\n  log_dist = log(dist_to_disp_km + 1),\n  alcohol_involved = as.integer(drunk_dr >= 1)\n)",
      "confidence": 0.7
    },
    {
      "category": "SELECTIVE_REPORTING",
      "severity": "HIGH",
      "file": "06_tables.R",
      "lines": [
        86,
        132
      ],
      "evidence": "The LaTeX table writer appends significance stars (**, *) to coefficients unconditionally rather than based on computed p-values. This can systematically misrepresent statistical significance. The manuscript\u2019s main table reports p=0.127 and a null result; unconditional '**' would directly contradict and could mislead readers.: cat(sprintf(\"Legal Cannabis Access & %.4f** & %.4f** & %.4f** & %.4f* & %.4f** \\\\\\n\",\n            rdd_linear$coef[1], rdd_quad$coef[1], rdd_uniform$coef[1],\n            rdd_50bw$coef[1], rdd_200bw$coef[1]),\n    file = \"../tables/tab02_main_results.tex\", append = TRUE)\n...\ncat(\"\\\\item Notes: * p$<$0.10, ** p$<$0.05, *** p$<$0.01. Standard errors in parentheses.\\n\",\n    file = \"../tables/tab02_main_results.tex\", append = TRUE)",
      "confidence": 0.9
    },
    {
      "category": "METHODOLOGY_MISMATCH",
      "severity": "HIGH",
      "file": "04_robustness.R",
      "lines": [
        70,
        140
      ],
      "evidence": "The script explicitly skips age heterogeneity because driver_age is unavailable, yet the printed 'Key findings' claim effects are strongest for ages 21\u201345 and null for elderly drivers. This is a narrative-results mismatch inside the codebase and could propagate into the manuscript if logs are used for writeup.: # Note: driver_age not available in this dataset (requires person-level FARS)\n# Skip age heterogeneity analysis\ncat(\"Note: Driver age not available in crash-level data.\\n\")\ncat(\"Age heterogeneity analysis requires person-level FARS file.\\n\")\ncat(\"Skipping age group analysis.\\n\")\n...\ncat(\"\\nKey findings:\\n\")\ncat(\"1. Effects concentrated at night (consistent with recreational use)\\n\")\ncat(\"2. Effects strongest for ages 21-45 (prime recreational ages)\\n\")\ncat(\"3. Null effects for elderly drivers (placebo confirmation)\\n\")",
      "confidence": 0.85
    }
  ],
  "file_verdicts": [
    {
      "file": "01_fetch_data.R",
      "verdict": "SEVERE"
    },
    {
      "file": "05_figures_v2.R",
      "verdict": "CLEAN"
    },
    {
      "file": "06_tables.R",
      "verdict": "SUSPICIOUS"
    },
    {
      "file": "00_packages.R",
      "verdict": "CLEAN"
    },
    {
      "file": "06_tables_v2.R",
      "verdict": "SEVERE"
    },
    {
      "file": "09_border_heterogeneity.R",
      "verdict": "CLEAN"
    },
    {
      "file": "04_robustness.R",
      "verdict": "SUSPICIOUS"
    },
    {
      "file": "05_figures_simple.R",
      "verdict": "CLEAN"
    },
    {
      "file": "02_clean_data.R",
      "verdict": "SUSPICIOUS"
    },
    {
      "file": "07_distance_analysis.R",
      "verdict": "CLEAN"
    },
    {
      "file": "10_first_stage.R",
      "verdict": "CLEAN"
    },
    {
      "file": "03_main_analysis.R",
      "verdict": "CLEAN"
    },
    {
      "file": "05_figures.R",
      "verdict": "CLEAN"
    }
  ],
  "summary": {
    "verdict": "SEVERE",
    "counts": {
      "CRITICAL": 2,
      "HIGH": 7,
      "MEDIUM": 1,
      "LOW": 0
    },
    "one_liner": "hard-coded results; method mismatch; fabricated data",
    "executive_summary": "The code can silently replace failed OpenStreetMap Overpass downloads with a hand-constructed \u201cminimal dispensary dataset\u201d of four \u201cknown locations,\u201d introducing synthetic data into the pipeline without disclosure and undermining the validity of any location-based results. Multiple manuscript-facing outputs are hard-coded rather than computed: key summary shares are inserted as approximate literals, one regression column (\u201cWeekend Night\u201d) is manually filled with a coefficient/SE/N, and alternative-specification RDD estimates are fabricated by scaling the baseline estimate/SE with arbitrary constants while also hard-coding p-values and sample sizes. In addition, the crash dataset can omit the key outcome ingredient (DRUNK_DR) and propagate missingness into the constructed alcohol_involved outcome, making downstream results potentially undefined or misleading.",
    "top_issues": [
      {
        "category": "HARD_CODED_RESULTS",
        "severity": "CRITICAL",
        "short": "This script fabricates alternative-specification RDD esti...",
        "file": "06_tables_v2.R",
        "lines": [
          55,
          94
        ],
        "github_url": "/apep_0091/code/06_tables_v2.R#L55-L94"
      },
      {
        "category": "METHODOLOGY_MISMATCH",
        "severity": "CRITICAL",
        "short": "The manuscript explicitly states treatment is time-varyin...",
        "file": "01_fetch_data.R",
        "lines": [
          12,
          46
        ],
        "github_url": "/apep_0091/code/01_fetch_data.R#L12-L46"
      },
      {
        "category": "DATA_FABRICATION",
        "severity": "HIGH",
        "short": "If the OpenStreetMap Overpass query fails, the script sil...",
        "file": "01_fetch_data.R",
        "lines": [
          256,
          275
        ],
        "github_url": "/apep_0091/code/01_fetch_data.R#L256-L275"
      }
    ],
    "full_report_url": "/tournament/corpus_scanner/scans/apep_0091_scan.json"
  },
  "error": null
}