{
  "paper_id": "apep_0193",
  "scan_date": "2026-02-06T13:01:53.822320+00:00",
  "scan_version": "2.0.0",
  "model": "openai/gpt-5.2",
  "overall_verdict": "SUSPICIOUS",
  "files_scanned": 9,
  "flags": [
    {
      "category": "METHODOLOGY_MISMATCH",
      "severity": "HIGH",
      "file": "02b_add_pop_weights.R",
      "lines": [
        26,
        39
      ],
      "evidence": "The manuscript states population weights (shares) are based on pre-treatment employment averaged over 2012\u20132013 to keep shares predetermined (Borusyak et al. 2022 recommendation). This code instead uses mean(emp) over the entire panel (apparently 2012\u20132022), which incorporates post-treatment outcomes into the weights. That is a substantive methodological deviation that can mechanically induce endogeneity in the constructed exposure and IV (shares depend on post-period employment).: county_pop <- panel %>%\n  group_by(county_fips) %>%\n  summarise(pop_proxy = mean(emp, na.rm = TRUE), .groups = \"drop\")",
      "confidence": 0.85
    },
    {
      "category": "METHODOLOGY_MISMATCH",
      "severity": "HIGH",
      "file": "01_fetch_data.R",
      "lines": [
        240,
        260
      ],
      "evidence": "The manuscript claims the outcome is total county employment across all industries, and explicitly states the \"all workers\" QWI series includes private-sector and government employment. The API query hard-codes ownercode=A05 (private sector only) and requests multiple industries (00 plus selected sectors). Unless later code aggregates/filters exactly as described (not shown here), this is inconsistent with the stated data construction and could materially change the dependent variable and sample.: url <- paste0(\n    qwi_base,\n    \"?get=Emp,EarnS,HirA,Sep,FrmJbC,FrmJbD\",\n    \"&for=county:*\",\n    \"&in=state:\", state_fips,\n    \"&year=\", year,\n    \"&quarter=\", quarter,\n    \"&industry=00,44-45,72,52,54\",  # All, Retail, Accommodation/Food, Finance, Professional\n    \"&ownercode=A05\",                # Private sector\n    \"&agegrp=A00\"                    # All ages\n  )",
      "confidence": 0.8
    },
    {
      "category": "DATA_PROVENANCE_MISSING",
      "severity": "MEDIUM",
      "file": "01_fetch_data.R",
      "lines": [
        283,
        290
      ],
      "evidence": "Comments indicate the QWI pull may be a \"subset for demonstration\" even though years_to_fetch/quarters cover the full 2012\u20132022 and 1\u20134. This creates ambiguity about whether the replication code actually retrieves the full QWI used in the paper or whether the paper used an external/local QWI extract not fully documented here. In addition, if the API calls fail, the script sets qwi_raw <- tibble() and continues, which can lead to downstream panels being constructed from missing/alternative sources without an explicit hard stop.: # Fetch QWI for sample of years (2012-2022) and quarters\n# Note: Full data would take long; fetching subset for demonstration\nyears_to_fetch <- 2012:2022\nquarters <- 1:4",
      "confidence": 0.65
    },
    {
      "category": "HARD_CODED_RESULTS",
      "severity": "LOW",
      "file": "01_fetch_data.R",
      "lines": [
        125,
        235
      ],
      "evidence": "State minimum wage histories are hard-coded as a curated tribble rather than programmatically pulled from DOL/NCSL. This is a reproducibility/provenance risk (manual transcription errors, incomplete states/years) but it is explicitly acknowledged in both the code header and manuscript as manual curation from named sources, so it is not inherently suspicious. It does, however, warrant verification against the cited sources because these values are key \"shocks\" in the shift-share design.: state_mw_changes <- tribble(\n  ~state_fips, ~state_abbr, ~date, ~min_wage,\n  # California\n  \"06\", \"CA\", \"2014-07-01\", 9.00,\n  ...\n)",
      "confidence": 0.9
    },
    {
      "category": "SUSPICIOUS_TRANSFORMS",
      "severity": "MEDIUM",
      "file": "02b_add_pop_weights.R",
      "lines": [
        57,
        62
      ],
      "evidence": "This left_join can introduce NA pop_proxy for destinations missing from the panel (e.g., suppressed QWI counties or dropped observations). Those NAs then propagate to sci_pop and total_sci_pop, affecting normalization (w_pop = sci_pop / total_sci_pop). Depending on how many destination counties are missing, weights may be implicitly renormalized over a non-random subset of destinations, potentially changing exposure measures in a way correlated with data availability/suppression. The manuscript claims near-universal coverage (99.5%+), but the code does not enforce or report missing join rates here.: sci_pop_full <- sci %>%\n  filter(county_fips_1 != county_fips_2) %>%\n  left_join(county_pop, by = c(\"county_fips_2\" = \"county_fips\")) %>%\n  mutate(sci_pop = sci * pop_proxy)",
      "confidence": 0.7
    },
    {
      "category": "SELECTIVE_REPORTING",
      "severity": "LOW",
      "file": "06_tables.R",
      "lines": [
        215,
        222
      ],
      "evidence": "The distance-robustness table explicitly filters to specifications with first-stage F >= 10, omitting weaker-instrument rows. This can be defensible (avoiding weak-IV bias), but it is a selective display choice: readers may not see how estimates behave when the first stage weakens. The manuscript discusses weakening first stages at larger distances; including all rows with clearly flagged weak-IV cases would be more transparent.: tab4_data <- dist_df %>%\n    filter(fs_f >= 10) %>%\n    mutate(\n      `Distance Threshold` = paste0(\"$\\\\geq$ \", dist, \" km\"),\n      ...\n    )",
      "confidence": 0.75
    },
    {
      "category": "DATA_FABRICATION",
      "severity": "LOW",
      "file": "00_packages.R",
      "lines": [
        52,
        53
      ],
      "evidence": "A global random seed is set at package-load time. No simulated data generation is present in the provided scripts, and the manuscript describes permutation inference (which should be seeded). This is likely benign, but placing set.seed() in a shared import file can inadvertently make other stochastic steps (e.g., sample() in permutation inference) deterministic across runs in ways not always intended. Not evidence of fabrication; just note for reproducibility hygiene.: # Set seed for reproducibility\nset.seed(42)",
      "confidence": 0.6
    }
  ],
  "file_verdicts": [
    {
      "file": "02b_add_pop_weights.R",
      "verdict": "SUSPICIOUS"
    },
    {
      "file": "01_fetch_data.R",
      "verdict": "SUSPICIOUS"
    },
    {
      "file": "06_tables.R",
      "verdict": "CLEAN"
    },
    {
      "file": "00_packages.R",
      "verdict": "CLEAN"
    },
    {
      "file": "04b_mechanisms.R",
      "verdict": "CLEAN"
    },
    {
      "file": "04_robustness.R",
      "verdict": "CLEAN"
    },
    {
      "file": "02_clean_data.R",
      "verdict": "CLEAN"
    },
    {
      "file": "03_main_analysis.R",
      "verdict": "CLEAN"
    },
    {
      "file": "05_figures.R",
      "verdict": "CLEAN"
    }
  ],
  "summary": {
    "verdict": "SUSPICIOUS",
    "counts": {
      "CRITICAL": 0,
      "HIGH": 2,
      "MEDIUM": 2,
      "LOW": 3
    },
    "one_liner": "method mismatch",
    "executive_summary": "The code does not implement the paper\u2019s stated weighting strategy: instead of constructing population weights from pre-treatment employment averaged over 2012\u20132013 to keep shares predetermined (as recommended by Borusyak et al. 2022), `02b_add_pop_weights.R` uses a different basis/time window for the shares. In addition, `01_fetch_data.R` does not pull the manuscript\u2019s claimed outcome\u2014total county employment across all industries including both private-sector and government\u2014because the API query targets a QWI series/filters that do not correspond to \u201call workers\u201d with government employment included.",
    "top_issues": [
      {
        "category": "METHODOLOGY_MISMATCH",
        "severity": "HIGH",
        "short": "The manuscript states population weights (shares) are bas...",
        "file": "02b_add_pop_weights.R",
        "lines": [
          26,
          39
        ],
        "github_url": "https://github.com/SocialCatalystLab/ape-papers/blob/main/apep_0193/code/02b_add_pop_weights.R#L26-L39"
      },
      {
        "category": "METHODOLOGY_MISMATCH",
        "severity": "HIGH",
        "short": "The manuscript claims the outcome is total county employm...",
        "file": "01_fetch_data.R",
        "lines": [
          240,
          260
        ],
        "github_url": "https://github.com/SocialCatalystLab/ape-papers/blob/main/apep_0193/code/01_fetch_data.R#L240-L260"
      }
    ],
    "full_report_url": "https://github.com/SocialCatalystLab/ape-papers/blob/main/tournament/corpus_scanner/scans/apep_0193_scan.json"
  },
  "error": null
}