{
  "paper_id": "apep_0127",
  "scan_date": "2026-02-06T12:48:12.577509+00:00",
  "scan_version": "2.0.0",
  "model": "openai/gpt-5.2",
  "overall_verdict": "SUSPICIOUS",
  "files_scanned": 11,
  "flags": [
    {
      "category": "METHODOLOGY_MISMATCH",
      "severity": "HIGH",
      "file": "03b_main_analysis_car_housing.R",
      "lines": [
        86,
        113
      ],
      "evidence": "The manuscript states: \"Standard errors are clustered at the municipality level\" for the pooled 2015\u20132016 regressions. The code uses base R lm() and never computes clustered/robust standard errors (e.g., via sandwich::vcovCL, fixest::feols with cluster=, or estimatr::lm_robust). As written, any SEs/p-values produced by summary(lm) are conventional iid OLS SEs, not municipality-clustered, so inference would not match the paper.: model5 <- lm(merit_excl_new ~ cars_per_1000 + rental_housing_pct + teachers_qualified +\n             factor(county_code) + factor(year),\n             data = analysis_data)\n\n# ...\n# (no clustered SEs computed anywhere)",
      "confidence": 0.9
    },
    {
      "category": "METHODOLOGY_MISMATCH",
      "severity": "HIGH",
      "file": "paper.tex",
      "lines": [
        250,
        360
      ],
      "evidence": "The LaTeX regression table reports clustered-SE-style significance stars and specific coefficient/SE values, but the provided regression code (03b_main_analysis_car_housing.R) does not compute clustered SEs and does not export a table with SEs matching Table \\ref{tab:regression}. This creates a reproducibility gap: the manuscript\u2019s reported inference cannot be reproduced from the shown code path.: We estimate this equation using OLS... Standard errors are clustered at the municipality level...\n\nTable~\\ref{tab:regression} presents our main regression results...",
      "confidence": 0.75
    },
    {
      "category": "METHODOLOGY_MISMATCH",
      "severity": "MEDIUM",
      "file": "03_main_analysis.R",
      "lines": [
        55,
        140
      ],
      "evidence": "A substantial portion of the repository implements an RDD design around a 50% \"school accessibility\" cutoff using 2023 data (and produces rdd_* tables/figures). This methodology is not described in the provided manuscript, which instead presents a 2015\u20132016 municipality panel OLS relating merit points to 2013 car ownership/housing tenure. This looks like a different project/paper living in the same repo, risking accidental cross-contamination of outputs (tables/figures) if not carefully separated.: # Approach A: Use N07531 (% children within 2km of school) as proxy for treatment\n# ...\ncutoff_accessibility <- 50  # 50% of children within 2km\n# ...\nrdd_merit <- rdrobust(\n  y = analysis_2023$merit_all,\n  x = analysis_2023$running_var,\n  c = 0,\n  kernel = \"triangular\",\n  bwselect = \"mserd\"\n)",
      "confidence": 0.85
    },
    {
      "category": "DATA_PROVENANCE_MISSING",
      "severity": "HIGH",
      "file": "02_clean_data.R",
      "lines": [
        214,
        260
      ],
      "evidence": "The \"skolskjuts_thresholds\" dataset is manually created inside the script with no machine-verifiable provenance (no URLs per municipality, no scrape logs, no archived pages, no citation file). For an academic workflow, this is a key provenance gap: values could be inadvertently wrong or selectively entered, and cannot be independently audited from the codebase.: # Based on web research, create threshold database\n# Source: Municipal websites (manual collection)\n# ...\nskolskjuts_thresholds <- tribble(\n  ~municipality_id, ~municipality_name, ~threshold_F3_km, ~threshold_46_km, ~threshold_79_km, ~source,\n  \"0114\", \"Upplands V\u00e4sby\", 2.0, 3.0, 4.0, \"Municipal website\",\n  \"0180\", \"Stockholm\", 2.0, 3.0, 4.0, \"Municipal website\",\n  ...\n)",
      "confidence": 0.95
    },
    {
      "category": "SUSPICIOUS_TRANSFORMS",
      "severity": "MEDIUM",
      "file": "02_clean_data.R",
      "lines": [
        285,
        304
      ],
      "evidence": "For municipalities without manually documented thresholds, the code imputes default thresholds (2/3/4 km). This may be reasonable (it matches the statutory guideline mentioned in the manuscript), but it is a strong assumption that can attenuate or bias any analysis using threshold variation. Because the thresholds are not used in the car/housing OLS section, the risk is mainly for the RDD/transport-subsidy parts of the repository.: analysis_data <- analysis_data |>\n  mutate(\n    threshold_F3_km = coalesce(threshold_F3_km, 2.0),\n    threshold_46_km = coalesce(threshold_46_km, 3.0),\n    threshold_79_km = coalesce(threshold_79_km, 4.0)\n  )",
      "confidence": 0.8
    },
    {
      "category": "HARD_CODED_RESULTS",
      "severity": "LOW",
      "file": "03_main_analysis.R",
      "lines": [
        86,
        103
      ],
      "evidence": "The RDD cutoff is hard-coded at 50% (children within 2km). This is a design choice rather than a \"result\"; however, it is nonstandard to define an RDD cutoff at a sample-independent constant unless justified by institutional rules. If the cutoff is intended to be the median, earlier code computes a median but does not use it as the cutoff. This should be justified/documented to avoid perceptions of post-hoc cutoff selection.: cutoff_accessibility <- 50  # 50% of children within 2km\n# Create centered running variable\nanalysis_2023 <- analysis_2023 |>\n  mutate(\n    running_var = school_access_2km - cutoff_accessibility,\n    treated = school_access_2km < cutoff_accessibility\n  )",
      "confidence": 0.7
    },
    {
      "category": "DATA_PROVENANCE_MISSING",
      "severity": "MEDIUM",
      "file": "01_fetch_data.R",
      "lines": [
        162,
        233
      ],
      "evidence": "If the Skolverket school registry API call fails, the script writes an empty schools file and later relies on OpenStreetMap (OSM) data. OSM is crowd-sourced and may be incomplete/non-uniform across municipalities; this provenance/coverage issue is not discussed in the manuscript (which also does not appear to use school-level spatial measures). If any conclusions depend on school coordinates/accessibility, the data source substitution should be disclosed and validated.: cat(\"  ERROR fetching from Skolverket API:\", e$message, \"\\n\")\ncat(\"  Will use alternative data source (OpenStreetMap) instead...\\n\")\n\n# Create empty structure for fallback to OSM data\nschools_df <- tibble(\n  school_id = character(),\n  school_name = character(),\n  municipality_id = character(),\n  municipality_name = character(),\n  principal_type = character(),\n  address_street = character(),\n  address_postal = character(),\n  address_city = character(),\n  latitude = numeric(),\n  longitude = numeric()\n)\n\nwrite_csv(schools_df, \"../data/raw/schools_grundskola.csv\")",
      "confidence": 0.8
    }
  ],
  "file_verdicts": [
    {
      "file": "01_fetch_data.R",
      "verdict": "CLEAN"
    },
    {
      "file": "06_tables.R",
      "verdict": "CLEAN"
    },
    {
      "file": "00_packages.R",
      "verdict": "CLEAN"
    },
    {
      "file": "01b_fetch_transport_housing.R",
      "verdict": "CLEAN"
    },
    {
      "file": "04_robustness.R",
      "verdict": "CLEAN"
    },
    {
      "file": "02b_merge_all_data.R",
      "verdict": "CLEAN"
    },
    {
      "file": "02_clean_data.R",
      "verdict": "SUSPICIOUS"
    },
    {
      "file": "03b_main_analysis_car_housing.R",
      "verdict": "SUSPICIOUS"
    },
    {
      "file": "03_main_analysis.R",
      "verdict": "CLEAN"
    },
    {
      "file": "05_figures.R",
      "verdict": "CLEAN"
    },
    {
      "file": "05b_figures_car_housing.R",
      "verdict": "CLEAN"
    },
    {
      "file": "paper.tex",
      "verdict": "SUSPICIOUS"
    }
  ],
  "summary": {
    "verdict": "SUSPICIOUS",
    "counts": {
      "CRITICAL": 0,
      "HIGH": 3,
      "MEDIUM": 3,
      "LOW": 1
    },
    "one_liner": "method mismatch; unclear provenance",
    "executive_summary": "The analysis scripts claim to use municipality-clustered standard errors for pooled 2015\u20132016 regressions, but the provided R code runs only plain `lm()` models and never computes clustered or otherwise robust SEs, making the reported inference inconsistent with the implemented methodology. The LaTeX regression table nevertheless reports clustered-SE-style significance stars and coefficient/SE values that cannot be reproduced from the available code as written. In addition, a key input (`skolskjuts_thresholds`) is manually assembled inside the cleaning script without machine-verifiable provenance (no source links, scrape logs, or archived references), preventing independent verification of the underlying data.",
    "top_issues": [
      {
        "category": "METHODOLOGY_MISMATCH",
        "severity": "HIGH",
        "short": "The manuscript states",
        "file": "03b_main_analysis_car_housing.R",
        "lines": [
          86,
          113
        ],
        "github_url": "https://github.com/SocialCatalystLab/ape-papers/blob/main/apep_0127/code/03b_main_analysis_car_housing.R#L86-L113"
      },
      {
        "category": "METHODOLOGY_MISMATCH",
        "severity": "HIGH",
        "short": "The LaTeX regression table reports clustered-SE-style sig...",
        "file": "paper.tex",
        "lines": [
          250,
          360
        ],
        "github_url": "https://github.com/SocialCatalystLab/ape-papers/blob/main/apep_0127/code/paper.tex#L250-L360"
      },
      {
        "category": "DATA_PROVENANCE_MISSING",
        "severity": "HIGH",
        "short": "The \"skolskjuts_thresholds\" dataset is manually created i...",
        "file": "02_clean_data.R",
        "lines": [
          214,
          260
        ],
        "github_url": "https://github.com/SocialCatalystLab/ape-papers/blob/main/apep_0127/code/02_clean_data.R#L214-L260"
      }
    ],
    "full_report_url": "https://github.com/SocialCatalystLab/ape-papers/blob/main/tournament/corpus_scanner/scans/apep_0127_scan.json"
  },
  "error": null
}