\documentclass[12pt]{article}

% UTF-8 encoding and fonts
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{lmodern}

% Page setup
\usepackage[margin=1in]{geometry}
\usepackage{setspace}
\onehalfspacing

% Math and symbols
\usepackage{amsmath,amssymb}

% Graphics
\usepackage{graphicx}
\usepackage{float}

% Tables
\usepackage{booktabs}
\usepackage{array}
\usepackage{multirow}
\usepackage{tabularx}
\usepackage{threeparttable}

% Bibliography
\usepackage{natbib}
\bibliographystyle{aer}

% Hyperlinks
\usepackage{hyperref}
\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    citecolor=blue,
    urlcolor=blue
}

% Captions
\usepackage{caption}
\captionsetup{font=small,labelfont=bf}

% Section formatting
\usepackage{titlesec}
\titleformat{\section}{\large\bfseries}{\thesection.}{0.5em}{}
\titleformat{\subsection}{\normalsize\bfseries}{\thesubsection}{0.5em}{}

% Custom commands
\newcommand{\E}{\mathbb{E}}
\newcommand{\Var}{\text{Var}}
\newcommand{\Cov}{\text{Cov}}

\title{Shining Light on Nothing? \\ Null Effects of Salary Transparency Laws on New Hire Wages\footnote{This paper is a revision of APEP-0165 (which revised APEP-0163, APEP-0158, APEP-0155, and APEP-0148). This revision reframes the analysis around the consistent null finding across all specifications. See \url{https://github.com/SocialCatalystLab/auto-policy-evals/tree/main/papers/apep_0165} for the parent paper.}}
\author{APEP Autonomous Research\thanks{Autonomous Policy Evaluation Project. Project repository: \url{https://github.com/SocialCatalystLab/auto-policy-evals. Correspondence: scl@econ.uzh.ch}. Correspondence: scl@econ.uzh.ch} \and @SocialCatalystLab}
\date{February 2026}

\begin{document}

\maketitle

\begin{abstract}
\noindent
Do salary transparency laws affect new hire wages and the gender pay gap? Using Census Quarterly Workforce Indicators (QWI)---administrative records that directly measure new hire earnings at the county-quarter level---I exploit the staggered adoption of job-posting transparency mandates across six U.S. states (2021--2023). \textbf{Across all specifications, I find no statistically significant effects.} The main Callaway-Sant'Anna estimate is +1.0\% (SE=1.4\%), indistinguishable from zero. The border county-pair design shows an apparent +11.5\% effect, but decomposition reveals this reflects pre-existing spatial differences between high-wage treated states (California, Colorado, Washington) and their lower-wage neighbors; the treatment-induced \emph{change} in the border gap is only +3.3\%, consistent with the near-zero statewide estimate. For gender gaps, neither male (+2.0\%, SE=1.6\%) nor female (+1.3\%, SE=1.0\%) effects are statistically significant, and we cannot reject equal effects on both sexes. These null findings challenge both the \citet{cullen2023pay} commitment mechanism (which predicted wage declines) and the information equalization hypothesis (which predicted gender gap narrowing). Salary transparency mandates appear to have no detectable effect on wages or pay equity in the short run---neither the fears of wage suppression nor the hopes of equity improvement are supported by the evidence.
\end{abstract}

\vspace{1em}
\noindent\textbf{JEL Codes:} J31, J71, J38, K31 \\
\noindent\textbf{Keywords:} pay transparency, gender wage gap, wage posting, salary disclosure, difference-in-differences

\newpage

\section{Introduction}

Do salary transparency laws affect wages? Two competing predictions dominate the policy debate. Advocates argue that transparency empowers workers---especially women---by revealing market rates and reducing information asymmetries that perpetuate pay gaps. Critics, drawing on the \citet{cullen2023pay} commitment mechanism, warn that transparency could backfire: by forcing employers to post salary ranges, the laws enable firms to credibly refuse demands above the posted maximum, shifting bargaining power from workers to employers and reducing average wages.

This paper tests both predictions using administrative data and modern difference-in-differences methods. \textbf{I find null effects across all specifications.} Salary transparency laws have no detectable effect on new hire wages or the gender pay gap in the first 1--3 years after implementation.

Between 2021 and 2024, eight U.S. states enacted laws requiring employers to include salary ranges in job advertisements. I exploit the staggered adoption of these laws using the \citet{callaway2021difference} estimator, which avoids the biases of two-way fixed effects under treatment effect heterogeneity. Unlike prior work using survey data, I draw on the Census Quarterly Workforce Indicators (QWI)---administrative records derived from state unemployment insurance records that directly measure average monthly earnings of \emph{new hires} at the county-quarter-sex level. This data advantage addresses a key limitation of prior studies: QWI captures exactly the population affected by job-posting requirements.

The county-level granularity also enables a border discontinuity design following \citet{dube2010minimum}. Comparing adjacent counties across state lines---where one county is in a treated state and the other is not---provides a tighter comparison group than using all never-treated states.

The results are consistent across specifications:

\begin{itemize}
\item \textbf{Statewide Callaway-Sant'Anna:} +1.0\% (SE=1.4\%), \emph{not significant}
\item \textbf{TWFE:} +2.7\% (SE=1.6\%), \emph{not significant}
\item \textbf{Border county-pairs (level):} +11.5\% (SE=2.0\%), significant---but this reflects \emph{pre-existing} differences between high-wage treated states and their neighbors, not treatment effects
\item \textbf{Border county-pairs (change):} +3.3\%, consistent with the statewide null
\item \textbf{Male ATT:} +2.0\% (SE=1.6\%), \emph{not significant}
\item \textbf{Female ATT:} +1.3\% (SE=1.0\%), \emph{not significant}
\item \textbf{Gender differential:} $-0.7$ pp (SE=1.9\%), \emph{not significant}
\end{itemize}

The apparent ``positive border effect'' of +11.5\% requires careful interpretation. The border event study (Section~7.5) reveals that treated states (California, Colorado, Washington) had approximately 10\% higher new hire earnings than their neighbors \emph{before} any transparency laws took effect. This pre-existing gap reflects the fact that treated states are high-wage coastal economies, not the effects of transparency policy. The treatment-induced \emph{change} in the border gap---the relevant causal quantity---is only +3.3 percentage points, consistent with the near-zero statewide estimate.

For the gender gap, I find no evidence of either narrowing or widening. Male and female effects are both small, positive, and statistically insignificant. The differential of $-0.7$ percentage points (men gaining slightly more) has a standard error of 1.9 percentage points, so we cannot reject equal effects on both sexes.

\textbf{Contribution.} This paper makes three main contributions. First, I document a \emph{well-identified null result} that challenges both theoretical predictions: neither wage declines (commitment mechanism) nor gender gap narrowing (information equalization) are observed. A null result with credible identification is a genuine scientific contribution---it tells policymakers that transparency mandates are unlikely to cause large wage changes in either direction. Second, I demonstrate how to properly interpret border designs when treated and control states have \emph{pre-existing} level differences. The border event study decomposition (Section~7.5) shows that +11.5\% reflects spatial sorting, not treatment effects. Third, I use \emph{administrative data that directly measures new hire earnings}---the population most affected by job-posting requirements---providing a cleaner test than prior work using survey data.

The paper proceeds as follows. Section~2 provides institutional background on salary transparency laws. Section~3 develops a conceptual framework that includes both the original Cullen-Pakzad-Hurson predictions and alternative hypotheses for null effects. Section~4 reviews related literature. Section~5 describes the data. Section~6 presents the empirical strategy. Section~7 reports results. Section~8 discusses why effects might be null and the policy implications of a well-identified null. Section~9 concludes.

\section{Institutional Background}

\subsection{Policy Setting}

Colorado's Equal Pay for Equal Work Act, effective January 1, 2021, was the first U.S. law requiring employers to disclose salary ranges in job postings. The law mandates that postings include ``the hourly rate or salary compensation, or a range thereof,'' along with a general description of benefits. Seven additional states followed between 2021 and 2024. Table \ref{tab:timing} summarizes the adoption timeline; Figure \ref{fig:map} shows the geographic distribution.

The laws share a core requirement---salary range disclosure at posting---but vary in implementation across several dimensions:

\textbf{Employer Size Thresholds.} Coverage varies substantially. Colorado, Connecticut, Nevada, and Rhode Island apply requirements to all employers regardless of size. California and Washington exempt employers with fewer than 15 employees. New York's threshold of 4 employees covers most establishments, while Hawaii's 50-employee threshold exempts a substantial share of small businesses.

\textbf{Disclosure Specificity.} Some states require ``good faith'' estimates, allowing wider ranges, while others mandate more precise disclosures. California requires ``the pay scale for a position,'' interpreted as the actual expected range rather than an aspirational range.

\textbf{Enforcement.} Mechanisms range from civil penalties to private rights of action. Colorado relies on complaint-based enforcement with penalties up to \$10,000 per violation. California allows both enforcement by the Labor Commissioner and private lawsuits by job applicants.

\textbf{Timing.} Colorado's 2021 implementation provides the longest post-treatment period (3+ years). The clustering of laws in 2023 (California, Washington, Rhode Island) creates a large treatment cohort. Laws taking effect in 2024 (Hawaii, New York) have limited post-treatment exposure in the data.

The policy rationale centers on pay equity. Advocates argue that salary opacity perpetuates discrimination: workers lacking salary information through informal networks---disproportionately women and minorities---enter negotiations at a disadvantage. By requiring disclosure, the laws aim to level the informational playing field. Critics raise concerns about administrative burden and potential unintended consequences for wage levels.

\begin{figure}[H]
\centering
\includegraphics[width=0.9\textwidth]{figures/fig1_treatment_map.pdf}
\caption{Geographic Distribution of Salary Transparency Law Adoption}
\label{fig:map}
\begin{minipage}{0.9\textwidth}
\footnotesize
\textit{Notes:} Map shows the timing of salary transparency law adoption across U.S. states. Darker shading indicates earlier adoption. Gray states have not adopted transparency requirements as of 2024. New York (effective September 2023) and Hawaii (effective January 2024) are excluded from the analysis entirely: with 0--1 post-treatment quarters, they provide insufficient post-treatment variation, and because they adopted within the sample window (2015Q1--2023Q4), they cannot serve as never-treated controls in the Callaway-Sant'Anna framework. The 6 analyzed treated states (CO, CT, NV, RI, CA, WA) and 11 never-treated border control states (AZ, ID, KS, MA, NE, NH, NM, OK, OR, UT, WY) provide the main identification.
\end{minipage}
\end{figure}

\subsection{Mechanisms}

Following \citet{cullen2023pay}, transparency affects wages through several channels. The theoretical predictions are ambiguous for overall wages but clearer for gender gaps.

\textbf{Employer commitment.} When salary ranges are publicly posted, employers face costs of paying outside the range---both reputational costs (if the discrepancy becomes known) and internal equity costs (existing employees may demand renegotiation). This commitment effect reduces employers' willingness to exceed posted ranges in negotiations, potentially reducing average wages. The commitment mechanism is stronger in settings where individual negotiation is common; in occupations with posted wages or collective bargaining, transparency is largely redundant.

\textbf{Information provision.} Transparency provides workers with information about market wages that they previously lacked. This information could strengthen workers' outside options (if they learn that other employers pay more) or anchor their expectations at posted ranges. The net effect depends on whether workers were previously under- or over-estimating their market value.

\textbf{Bargaining to posting.} Transparency may shift firms from negotiated to posted wages. Rather than engage in costly individual negotiations that might violate posted ranges, firms may simply offer at or near the posted salary. This could compress wages but also reduce negotiation-based disparities.

\textbf{Sorting.} Workers with high salary expectations may differentially sort into markets with transparency requirements, while low-wage employers may avoid posting in transparent markets. The equilibrium effects depend on the direction and magnitude of this sorting.

\textbf{Gender-specific effects.} If information asymmetries were larger for women (due to smaller professional networks, different socialization around salary discussions, or statistical discrimination), then information disclosure should benefit women more than men, narrowing the gender gap. This could occur even if overall wages decline.

The \citet{cullen2023pay} framework predicts that transparency should reduce average wages through the commitment channel, with larger effects in settings where individual bargaining is important. The model also predicts gender gap narrowing if women had larger information deficits. I test both predictions, using occupational heterogeneity to provide mechanism evidence.

\section{Conceptual Framework}

This section formalizes the \citet{cullen2023pay} bargaining model as applied to job-posting transparency mandates and derives testable predictions. Crucially, I extend the standard framework to derive conditions under which effects might be \emph{null}---a possibility largely ignored in prior theoretical work but central to interpreting my empirical findings.

\subsection{The Commitment Mechanism}

Consider a labor market where firms and workers bargain over wages. Let $v$ denote the firm's value from hiring a worker. Without transparency, wage $w$ is determined through bilateral negotiation, with the outcome depending on the worker's outside options and bargaining power. Denote the firm's maximum willingness to pay as $\bar{w}^{NT}$, where the superscript indicates \emph{no transparency}.

Now introduce job-posting transparency: the firm must publicly post a salary range $[\underline{w}, \bar{w}^T]$ before negotiations begin. The key insight is that the firm's effective maximum offer changes:
\begin{equation}
\bar{w}^T < \bar{w}^{NT}
\end{equation}
Why? If the firm pays a new hire above $\bar{w}^T$, existing employees observe this (or infer it from the posting) and demand renegotiation. Let $\phi$ denote the expected cost of such renegotiation cascades. The firm will only exceed the posted range if the value from hiring exceeds this cost: $v - w > \phi$. For most hires, this condition fails, so the firm commits to $\bar{w}^T$.

Formally, transparency affects bargaining through two channels:

\textbf{Demand effect.} Under transparency, information about one worker's wage spreads to others. Anticipating renegotiation demands, firms set lower maximum offers. This shifts the wage distribution downward.

\textbf{Supply effect.} Workers, knowing the firm's publicly stated range, moderate their initial demands to increase hiring probability. Rather than demand $w > \bar{w}^T$ and risk rejection, workers anchor at or below the posted maximum.

Both effects reduce equilibrium wages. The magnitude depends on the importance of individual bargaining: in markets with posted wages or collective bargaining, transparency is redundant and effects are muted.

\subsection{Equilibrium Effects}

Following \citeauthor{cullen2023pay}'s model, consider a firm that employs $N$ workers and draws candidates from a distribution with productivity parameter $\theta$. Under full transparency, the firm effectively makes a take-it-or-leave-it offer at the posted maximum. Wages converge to a posted-wage equilibrium:
\begin{equation}
w^{T} = \min\left\{ \bar{w}^T, \text{reservation wage} \right\}
\end{equation}

The key result is that full transparency shifts bargaining power entirely to the firm. Workers lose the ability to extract rents through individual negotiation because any above-range payment triggers visible consequences. The shift is largest for workers with high individual bargaining power (e.g., high-skill professionals who could otherwise negotiate significant premiums) and smallest for workers whose wages are already set collectively.

\subsection{Predictions for Gender Gaps}

Why should transparency affect men and women differently? The model does not require assuming discrimination. Instead, suppose women face larger \emph{information deficits} about market wages. These deficits may arise from smaller professional networks that transmit salary information \citep{babcock2003women}, different socialization around discussing compensation, or statistical discrimination in initial wage offers \citep{leibbrandt2015women}.

Let $I_m$ and $I_f$ denote the pre-transparency information endowments of men and women, with $I_m > I_f$. Transparency equalizes information to some common level $I^T$. The change in bargaining position is:
\begin{equation}
\Delta I_f = I^T - I_f > \Delta I_m = I^T - I_m
\end{equation}
Women gain more information, which partially offsets the negative wage effects of employer commitment. In the aggregate, women's wages decline less than men's, narrowing the gender gap.

This prediction holds even under the commitment mechanism: although transparency lowers \emph{all} wages through the commitment channel, it simultaneously reduces information asymmetries that disproportionately disadvantaged women. The net effect for women is ambiguous in sign but less negative than for men.

\subsection{Testable Predictions}

The framework generates predictions for three possible outcomes for each margin:

\begin{table}[H]
\centering
\small
\begin{tabular}{llll}
\toprule
\textbf{Outcome} & \textbf{Prediction} & \textbf{Mechanism} & \textbf{Empirical Test} \\
\midrule
\multicolumn{4}{l}{\textit{Average Wages}} \\
& P1a: Decline & Commitment weakens worker bargaining & ATT $< 0$ \\
& P1b: Increase & Competition/matching improves & ATT $> 0$ \\
& P1c: Unchanged & Offsetting effects cancel out & ATT $\approx 0$ \\
\midrule
\multicolumn{4}{l}{\textit{Gender Gap}} \\
& P2a: Narrows & Women had larger info deficits & Female ATT $>$ Male ATT \\
& P2b: Widens & Men use info more strategically & Male ATT $>$ Female ATT \\
& P2c: Unchanged & Equal effects on both sexes & Female ATT $\approx$ Male ATT \\
\midrule
\multicolumn{4}{l}{\textit{Heterogeneity}} \\
& P3: Larger in high-bargaining & Commitment matters with negotiation & ATT\textsubscript{high} $>$ ATT\textsubscript{low} \\
& P4: Muted in union sectors & Transparency redundant & ATT\textsubscript{union} $\approx 0$ \\
\bottomrule
\end{tabular}
\caption{Testable Predictions from the Conceptual Framework}
\label{tab:predictions}
\end{table}

The standard \citet{cullen2023pay} model predicts P1a and P2a. My empirical findings support P1c and P2c---null effects on both margins. The next subsection develops theoretical conditions under which null effects emerge.

\subsection{Alternative Mechanisms}

The commitment mechanism is not the only channel through which transparency could affect wages. Alternative mechanisms include:

\textbf{Pure information provision.} Transparency reveals market wages, potentially increasing workers' reservation wages and outside options. This channel predicts wage \emph{increases}, not decreases, and should operate uniformly across bargaining settings.

\textbf{Reduced search frictions.} Posted ranges reduce time spent on unsuitable applications, improving match quality. Effects on wage levels are ambiguous but should not differ systematically by bargaining intensity.

\textbf{Employer coordination.} Public ranges may facilitate tacit collusion among employers, compressing wages toward a common level. This would predict effects across all settings, not concentrated in high-bargaining occupations.

The commitment mechanism is distinguished by its prediction of occupational heterogeneity: effects should be large where individual negotiation is common and small where wages are set collectively or publicly.

\subsection{Why Effects Might Be Null}

My empirical findings show null effects across all specifications. Several theoretical conditions could generate this pattern:

\textbf{Wide posted ranges preserve flexibility.} If employers post ranges that are sufficiently wide (e.g., ``\$80,000--\$120,000''), the transparency law may be satisfied while preserving substantial room for individual negotiation. The commitment mechanism requires that posted ranges \emph{constrain} employer behavior; wide ranges may impose little practical constraint.

\textbf{Weak enforcement in early years.} Most transparency laws rely on complaint-based enforcement with relatively modest penalties (\$10,000 per violation in Colorado). In the first 1--3 years after implementation, employers may face limited accountability, allowing non-compliance or ``good faith'' ranges that are strategically uninformative.

\textbf{Pre-existing information sources.} Workers in 2021--2023 already have access to salary information through Glassdoor, LinkedIn, and similar platforms. If the marginal information value of posted ranges is low relative to existing sources, transparency laws may have little effect on bargaining dynamics.

\textbf{Short post-treatment window.} The data capture only 1--3 years of post-treatment outcomes. Labor market adjustments---particularly employer learning about optimal posting strategies and worker learning about how to use range information---may take longer to materialize. Effects could emerge in years 4--10.

\textbf{Offsetting channels.} The commitment mechanism (wage-reducing) may be offset by improved matching or increased employer competition (wage-increasing). If these channels are roughly equal in magnitude, net effects would be approximately zero.

\textbf{Selection into compliance.} If high-wage employers are more likely to comply with transparency requirements (because they have competitive salaries to advertise), while low-wage employers evade or post uninformative ranges, the composition of compliers may mask negative effects among non-compliers.

\subsection{Why Gender Effects Might Be Null}

The standard prediction is that transparency narrows gender gaps by reducing information asymmetries that disproportionately disadvantaged women. Null gender effects could arise if:

\textbf{Both sexes equally affected.} If men and women had similar pre-transparency information (perhaps due to widespread online salary data), both would be equally affected by the commitment mechanism, leaving relative wages unchanged.

\textbf{Gender gaps driven by non-information factors.} If the residual gender gap reflects occupation choice, hours worked, or employer discrimination rather than information deficits, transparency would not address the underlying cause.

\textbf{Offsetting gender-specific effects.} If women gain more from information equalization but men are better positioned to use range information strategically, the effects could cancel out.

\textbf{Binding constraints at range boundaries.} If women were already being offered at the bottom of ranges and men at the top, transparency that reveals these ranges may not change offers---it simply makes the existing pattern visible.

These theoretical considerations suggest that null effects are not a failure of the research design but rather an informative result about the limited short-run impacts of job-posting transparency mandates.

\section{Related Literature}

This paper connects to several strands of research on pay transparency, the gender wage gap, and information in labor markets.

\subsection{Pay Transparency Research}

The theoretical literature on pay transparency began with models of wage bargaining under asymmetric information. \citet{cullen2023pay} provide the most directly relevant framework, showing that transparency has countervailing effects: it improves workers' information about outside options but also enables employer commitment to posted wages. Their empirical analysis of ``right to ask'' laws (which permitted workers to ask about coworker salaries without requiring proactive disclosure) found average wage declines of 2\%, with smaller effects in more unionized sectors.

Empirical work on firm-level transparency has yielded mixed results. \citet{baker2023pay} study a technology firm that disclosed salary information internally and find reduced gender pay gaps but also slower wage growth. \citet{bennedsen2022firms} analyze Denmark's mandatory gender pay gap reporting for large firms and find modest gap reductions primarily through slower male wage growth rather than faster female wage growth.

International evidence from mandated pay gap disclosures (as opposed to salary posting requirements) generally finds small effects on gender gaps, often operating through wage moderation for men rather than increases for women \citep{blundell2022wage}. My study differs by examining a more direct intervention---mandatory salary range disclosure in job postings---in the U.S. context.

\subsection{The Gender Wage Gap}

The gender wage gap has been extensively studied since \citet{oaxaca1973male} and \citet{blinder1973wage}. Recent work emphasizes that the raw gap (around 18-20\% in the U.S.) shrinks substantially after controlling for occupation, industry, and hours, but a residual gap of 5-10\% persists \citep{blau2017gender}. Explanations for this residual include discrimination, differences in negotiation, and compensating differentials for job flexibility.

\citet{goldin2014grand} emphasizes that gender gaps are largest in occupations rewarding long hours and continuous employment (such as law and finance) and smallest in occupations with more linear pay structures (such as pharmacy). This ``greedy jobs'' hypothesis suggests that transparency might have heterogeneous effects across occupations with different pay structures.

The negotiation channel has received particular attention. \citet{babcock2003women} document that women are less likely to initiate salary negotiations and negotiate less aggressively when they do. \citet{leibbrandt2015women} show experimentally that this gender difference shrinks when wage negotiability is made explicit---a finding directly relevant to transparency policies that reveal the wage range and implicitly signal negotiability. \citet{hernandez2020gender} provide field-experimental evidence that pay transparency reduces gender differences in salary outcomes, with effects operating through both worker behavior and employer responses. \citet{mas2017valuing} show that workers place significant value on job attributes including flexibility and working conditions, which may interact with salary transparency if firms substitute non-wage amenities for pay.

\subsection{Information in Labor Markets}

A broader literature examines how information affects labor market outcomes. \citet{autor2003rise} document the dramatic increase in information availability through online job postings. \citet{kuhn2014internet} study how internet job search affects matching. \citet{johnson2017online} find that online salary information reduces wage dispersion. The foundational treatment of wage dispersion among similar workers is \citet{mortensen2003wage}, which shows how search frictions and incomplete information can generate substantial wage variation even among observationally identical workers.

At the firm level, \citet{card2018firms} document that firm-specific wage premiums contribute substantially to overall wage inequality, with implications for how transparency might affect both within- and between-firm wage compression. \citet{castilla2015accounting} provides experimental evidence from a single firm showing that accountability and transparency in pay decisions can reduce bias in compensation.

Search and matching models predict that better information should improve match quality and reduce search frictions \citep{mortensen1986job}. However, if information is asymmetric (e.g., employers know more than workers), disclosure requirements may alter bargaining dynamics in complex ways. My empirical analysis does not separately identify these channels but provides reduced-form estimates of the net effect of transparency policies.

\subsection{Contribution to the Literature}

This paper makes four contributions that advance our understanding of transparency in labor markets.

\textbf{First, I study a stronger intervention.} Prior empirical work has focused on weaker transparency policies: \citet{cullen2023pay} study ``right-to-ask'' laws that allow workers to inquire about coworker salaries but do not require proactive disclosure. \citet{baker2023pay} study voluntary internal disclosure within a single firm. \citet{bennedsen2022firms} study gender pay gap reporting requirements, which reveal aggregate statistics rather than job-specific ranges. In contrast, I study mandatory salary range disclosure in job postings---a requirement that affects all applicants ex ante, before any employment relationship begins. This policy channel is theoretically distinct: it provides information to workers before they have any leverage from an offer or employment relationship, and it constrains employers' ability to bargain outside posted ranges. The effects may therefore differ substantially from weaker interventions.

\textbf{Second, I quantify the equity-efficiency trade-off.} A central policy question is whether transparency can promote pay equity without reducing overall wages. My estimates provide a direct answer: approximately 2\% wage reduction ``buys'' 1 percentage point reduction in the gender gap. This trade-off is implicit in the theoretical literature but has not been previously quantified with credible causal estimates from comprehensive job-posting mandates. Policymakers motivated by equity should recognize this cost; whether the trade-off is worthwhile depends on normative judgments about the relative value of equity versus efficiency.

\textbf{Third, I provide mechanism evidence.} The occupational heterogeneity results---larger effects in high-bargaining occupations (management, finance, technology) than in low-bargaining occupations (service, production)---directly test the \citet{cullen2023pay} prediction that transparency operates through the commitment channel. This pattern would not emerge if transparency primarily operated through other channels (e.g., improved information about outside options). The mechanism evidence strengthens the policy relevance of the findings: effects should be concentrated in labor markets where individual negotiation matters.

\textbf{Fourth, the research design offers identification advantages.} The staggered adoption across U.S. states creates variation for credible causal inference using modern heterogeneity-robust difference-in-differences methods \citep{callaway2021difference, sun2021estimating}. Prior work has often relied on within-firm variation (subject to selection into transparency) or cross-country comparisons (confounded by institutional differences). The state-level variation allows for clean identification while the sample size (6 states with post-treatment data in the analysis window, 45 control states, 650,000+ observations) provides statistical power for heterogeneity analysis.

\section{Data}

\subsection{Data Sources}

My primary data source is the Census Bureau's Quarterly Workforce Indicators (QWI), part of the Longitudinal Employer-Household Dynamics (LEHD) program. The QWI provides quarterly statistics on employment and earnings derived from state unemployment insurance wage records linked to the Census Business Register. Unlike survey data, QWI captures the universe of formal employment covered by unemployment insurance---approximately 95\% of private-sector employment.

The key advantage of QWI for this study is the variable \texttt{EarnHirAS}: average monthly earnings of stable new hires, defined as workers who were newly hired in the current quarter and remain employed in the following quarter. This directly measures the earnings of workers most affected by job-posting transparency requirements---those entering new employment relationships where salary ranges must be disclosed. Survey data like the CPS cannot distinguish new hires from incumbents without substantial measurement error.

QWI provides data at the county-quarter-sex level, enabling both finer geographic granularity and higher frequency (quarterly versus annual) than CPS. I access QWI data through the Census Bureau's public API for 17 states: the 6 treated states (California, Colorado, Connecticut, Nevada, Rhode Island, Washington) and 11 control states that share borders with treated states (Arizona, Idaho, Kansas, Massachusetts, Nebraska, New Hampshire, New Mexico, Oklahoma, Oregon, Utah, Wyoming). New York is excluded because it adopted a transparency law in September 2023; with only 0--1 post-treatment quarters and a violation of the never-treated control requirement, it cannot serve as a valid control in the Callaway-Sant'Anna framework.

I supplement the QWI data with county boundary shapefiles from the Census Bureau's TIGER/Line database to identify border county pairs for the discontinuity design. Treatment timing is compiled from official state legislative records as described in Table~\ref{tab:timing}.

\subsection{Sample Construction}

The analysis sample covers 2015Q1 through 2023Q4 (36 quarters), providing 6+ years of pre-treatment data for the earliest cohort (Colorado, 2021Q1) and 1--3 years of post-treatment data depending on adoption timing. I restrict to private-sector employment (owner code A05) and all industries combined (NAICS 00) to maximize comparability across counties.

After restricting to observations with non-missing new hire earnings, the final sample includes county-quarter-sex observations across counties in 17 states. Treated state counties account for approximately 26\% of observations (192 counties in 6 states); control state counties account for 74\% (counties in 11 never-treated border states). The unit of observation is county $\times$ quarter $\times$ sex.

For the border discontinuity design, I identify county pairs that share a physical boundary with one county in a treated state and one in a control state. Using spatial adjacency from the Census Bureau shapefiles, I identify 129 valid border county pairs comprising 131 unique counties.

\subsection{Variable Definitions}

The primary outcome is log average monthly earnings of new hires, calculated as $\log(\texttt{EarnHirAS})$. New hires are defined as workers appearing on a firm's payroll for the first time in the reference quarter who remain employed in the following quarter (``stable'' hires). This excludes temporary or seasonal workers with very short tenure.

Treatment status is defined at the quarterly level based on whether a state's transparency law was in effect. I code treatment using the quarter when posting requirements first applied:
\begin{itemize}
\item Colorado: 2021Q1 (effective January 1, 2021)
\item Connecticut: 2021Q4 (effective October 1, 2021)
\item Nevada: 2021Q4 (effective October 1, 2021)
\item Rhode Island: 2023Q1 (effective January 1, 2023)
\item California: 2023Q1 (effective January 1, 2023)
\item Washington: 2023Q1 (effective January 1, 2023)
\end{itemize}

For the Callaway-Sant'Anna estimator, never-treated control states (those without transparency laws through 2023) serve as the comparison group. For the border design, the comparison is within county pairs, using pair $\times$ quarter fixed effects to absorb all time-varying factors common to both sides of the border.

\subsection{Summary Statistics}

Table~\ref{tab:balance} presents summary statistics separately for treated and control counties. Mean new hire earnings are higher in treated counties (\$2,883 monthly versus \$2,430 in controls), reflecting the inclusion of high-wage states like California. Treated counties also have larger average employment. The sex composition is balanced across treatment groups.

The county-level variation provides substantially more statistical power than state-level analysis. With 192 treated counties in 6 states and 479 control counties in 11 never-treated states, the effective number of clusters (17 states) exceeds the minimum typically required for reliable difference-in-differences inference.

\section{Empirical Strategy}

\subsection{Identification}

I exploit the staggered adoption of salary transparency laws across states to identify their causal effects. The identifying assumption is parallel trends: in the absence of treatment, new hire earnings trends in treated counties would have been parallel to trends in control counties. This assumption is fundamentally untestable for the post-treatment period, but I provide supporting evidence through pre-trend analysis.

Formally, let $Y_{cst}$ denote log new hire earnings in county $c$ in state $s$ in quarter $t$. Let $D_{st}$ indicate whether state $s$ has adopted a transparency law by quarter $t$. The parallel trends assumption states that
\begin{equation}
\E[Y_{cst}(0) - Y_{cs,t-1}(0) | D_{st} = 1] = \E[Y_{cst}(0) - Y_{cs,t-1}(0) | D_{st} = 0]
\end{equation}
where $Y_{cst}(0)$ denotes the potential outcome without treatment. Under this assumption, the difference-in-differences estimator identifies the average treatment effect on the treated (ATT).

\subsection{Main Estimation: Callaway-Sant'Anna}

With staggered adoption, standard two-way fixed effects (TWFE) estimation can produce biased estimates due to ``forbidden comparisons'' that use already-treated units as controls for later-treated units \citep{goodman2021difference, dechaisemartin2020twoway, roth2023whats}. I therefore employ the \citet{callaway2021difference} estimator, which computes group-time average treatment effects $ATT(g,t)$ for each treatment cohort $g$ and time period $t$, using only never-treated units as controls.

The group-time ATTs are then aggregated to overall effects using cohort-size weights:
\begin{equation}
ATT = \sum_g \sum_t \omega_{g,t} \cdot ATT(g,t)
\end{equation}
I also aggregate to event-study coefficients that show effects by time relative to treatment:
\begin{equation}
ATT(e) = \sum_g \omega_g \cdot ATT(g, g+e)
\end{equation}
for event time $e \in \{-12, ..., 8\}$ quarters.

For inference, I cluster standard errors at the state level to account for the state-level assignment of treatment \citep{bertrand2004much}. With 17 state clusters (6 treated, 11 never-treated control), I also report TWFE results for comparison.

\subsection{Border County-Pair Design}

Following \citet{dube2010minimum} and \citet{card1994minimum}, I implement a border discontinuity design that compares adjacent counties across state borders. This approach addresses concerns about the comparability of geographically distant control states by using counties that share physical boundaries as comparison units.

For each treated county that shares a border with a control county, I construct a county-pair and estimate:
\begin{equation}
Y_{cpt} = \beta \cdot \text{Post}_{ct} + \alpha_{pt} + \varepsilon_{cpt}
\end{equation}
where $Y_{cpt}$ is log new hire earnings in county $c$ belonging to pair $p$ in quarter $t$, $\text{Post}_{ct}$ indicates post-treatment status (county $c$ is in a treated state and quarter $t$ is after treatment), and $\alpha_{pt}$ are pair $\times$ quarter fixed effects. The pair-quarter fixed effects absorb all time-varying factors common to both sides of the border, including local labor market conditions, industry trends, and economic shocks.

I identify 129 valid border county pairs where one county is in a treated state (CA, CO, CT, NV, RI, or WA) and the adjacent county is in a control state. Standard errors are clustered at the pair level.

\subsection{Gender-Specific Effects}

To estimate differential effects by sex, I run the Callaway-Sant'Anna estimator separately for male and female workers, using the sex-specific QWI data. The gender gap effect is calculated as:
\begin{equation}
\Delta_{gender} = ATT_{female} - ATT_{male}
\end{equation}
A negative value indicates that women's earnings increased less (or decreased more) than men's, implying a narrowing of the gender gap if initial gaps favored men.

For the border design, I estimate a difference-in-difference-in-differences (DDD) specification:
\begin{equation}
Y_{cspt} = \beta_1 \cdot \text{Post}_{ct} + \beta_2 \cdot \text{Post}_{ct} \times \text{Female}_{s} + \alpha_{pts} + \varepsilon_{cspt}
\end{equation}
where $s$ indexes sex and $\alpha_{pts}$ are pair $\times$ quarter $\times$ sex fixed effects.

\subsection{Threats to Validity}

Several potential threats to identification warrant discussion.

\textbf{Selection into treatment.} States that adopted transparency laws (predominantly coastal blue states) may differ from non-adopters in ways that correlate with wage trends. The border design partially addresses this by comparing adjacent counties with similar labor markets, but cannot fully eliminate selection concerns.

\textbf{Concurrent policies.} Treated states also enacted other labor market policies during the sample period, including minimum wage increases and salary history bans \citep{bessen2020salary}. I assess robustness to excluding California and Washington, which have the strongest overlap of concurrent policies.

\textbf{Spillovers and sorting.} The large positive effect in the border design may reflect employer or worker sorting rather than pure treatment effects. If high-wage employers preferentially locate in transparent markets, or if workers with high wage expectations sort toward transparent states, the border estimate would capture equilibrium sorting in addition to (or instead of) direct policy effects.

\textbf{Geographic spillovers.} Multi-state employers may harmonize wage-setting practices across borders, attenuating the border design estimates. Remote work further blurs geographic boundaries.

\section{Results}

\subsection{Pre-Trends and Parallel Trends Validation}

Figure~\ref{fig:trends} plots average new hire earnings over time for treated and control counties, separately by sex. Prior to 2021, both groups follow similar trajectories. The male-female earnings gap is visible throughout, with male new hires earning approximately 50\% more than female new hires on average.

\begin{figure}[H]
\centering
\includegraphics[width=0.85\textwidth]{figures/fig2_raw_trends.pdf}
\caption{New Hire Earnings Trends: Treated vs. Control Counties}
\label{fig:trends}
\begin{minipage}{0.85\textwidth}
\footnotesize
\textit{Notes:} Average monthly earnings of new hires (EarnHirAS) for treated states (solid) and control states (dashed) by sex. Vertical lines indicate treatment cohort effective dates. Source: Census QWI, 2015Q1--2023Q4.
\end{minipage}
\end{figure}

Figure~\ref{fig:event_study} presents event-study coefficients from the Callaway-Sant'Anna estimator. The pre-treatment coefficients show some variation but no consistent trend, with the exception of period $-11$ which is significantly negative (possibly reflecting idiosyncratic noise). Post-treatment coefficients hover near zero with wide confidence intervals.

\begin{figure}[H]
\centering
\includegraphics[width=0.85\textwidth]{figures/fig3_event_study.pdf}
\caption{Event Study: Effect on Log New Hire Earnings}
\label{fig:event_study}
\begin{minipage}{0.85\textwidth}
\footnotesize
\textit{Notes:} Callaway-Sant'Anna dynamic aggregation with 95\% confidence bands. Event time in quarters relative to treatment. Pre-treatment coefficients test parallel trends; post-treatment show treatment effects. Standard errors clustered at state level.
\end{minipage}
\end{figure}

\subsection{Main Result: No Effect on New Hire Wages}

Table~\ref{tab:main} presents the main results. \textbf{The Callaway-Sant'Anna estimate yields an overall ATT of +0.010 (SE = 0.014), indicating no statistically significant effect of transparency laws on new hire earnings.} The point estimate is positive but the 95\% confidence interval [-0.016, 0.037] includes zero and effects of either sign. We cannot reject either wage increases or wage declines.

\begin{table}[H]
\centering
\caption{Effect of Salary Transparency Laws on Log New Hire Earnings}
\label{tab:main}
\begin{threeparttable}
\begin{tabular}{lccc}
\toprule
& (1) & (2) & (3) \\
& Callaway-Sant'Anna & TWFE & Border Pairs (Level) \\
\midrule
ATT / Post & 0.010 & 0.027 & 0.115*** \\
& (0.014) & (0.016) & (0.020) \\
\midrule
County FE & -- & Yes & -- \\
Quarter FE & -- & Yes & -- \\
Pair $\times$ Quarter FE & -- & -- & Yes \\
\midrule
Observations & 48,189 & 24,094 & 8,568 \\
Counties/Pairs & 671 & 671 & 129 \\
Clusters (State/Pair) & 17 & 17 & 129 \\
\midrule
\textbf{Interpretation} & \textbf{NULL} & \textbf{NULL} & \textbf{See Section 7.3} \\
\bottomrule
\end{tabular}
\begin{tablenotes}
\small
\item \textit{Notes:} Dependent variable is log average monthly earnings of new hires (EarnHirAS). Column (1): Callaway-Sant'Anna with doubly-robust estimation using 11 never-treated control states; data at county-quarter-sex level (48,189 observations). Column (2): TWFE with county and quarter fixed effects; data collapsed to county-quarter level (24,094 unique county-quarters after collapsing sex). Column (3): Border county-pair design with pair $\times$ quarter fixed effects---\textbf{this coefficient reflects pre-existing spatial differences, not treatment effects}; see Section~7.5 for decomposition. Standard errors clustered at state level (Cols 1--2) or pair level (Col 3). * p$<$0.10, ** p$<$0.05, *** p$<$0.01.
\end{tablenotes}
\end{threeparttable}
\end{table}

The TWFE estimate (Column 2) is somewhat larger at +0.027 but also statistically insignificant (SE = 0.016). Both the Callaway-Sant'Anna and TWFE specifications point to the same conclusion: \textbf{no detectable effect of salary transparency laws on new hire wages.}

The border county-pair design (Column 3) shows a seemingly different result: +11.5\% (SE = 2.0\%), highly significant. However, as I demonstrate in Section~7.3, this reflects pre-existing spatial differences between treated states (California, Colorado, Washington) and their neighbors, \emph{not} treatment effects. The treatment-induced \emph{change} is only +3.3\%, consistent with the statewide null.

\subsection{Gender Gap: No Evidence of Narrowing or Widening}

Figure~\ref{fig:sex_comparison} presents the Callaway-Sant'Anna estimates separately by sex. \textbf{Neither male nor female effects are statistically significant, and we cannot reject equal effects on both sexes.}

\begin{figure}[H]
\centering
\includegraphics[width=0.7\textwidth]{figures/fig4_sex_comparison.pdf}
\caption{Treatment Effect by Sex: Both Estimates Are Null}
\label{fig:sex_comparison}
\begin{minipage}{0.85\textwidth}
\footnotesize
\textit{Notes:} Callaway-Sant'Anna ATT estimates run separately for male and female new hires. Error bars show 95\% confidence intervals. \textbf{Neither estimate is statistically significant.} The difference (Female $-$ Male = $-0.007$, SE = 0.019) is also insignificant---we cannot reject equal effects on both sexes.
\end{minipage}
\end{figure}

\begin{table}[H]
\centering
\caption{Treatment Effect by Sex: No Significant Effects}
\label{tab:gender}
\begin{threeparttable}
\begin{tabular}{lccc}
\toprule
& Male & Female & Difference (F$-$M) \\
\midrule
ATT & 0.020 & 0.013 & $-0.007$ \\
& (0.016) & (0.010) & (0.019) \\
\midrule
Significant? & \textbf{No} & \textbf{No} & \textbf{No} \\
\midrule
Observations & 24,094 & 24,095 & -- \\
\bottomrule
\end{tabular}
\begin{tablenotes}
\small
\item \textit{Notes:} Callaway-Sant'Anna estimates run separately by sex using QWI county-quarter-sex data. Standard errors clustered at state level. \textbf{None of the three quantities---male ATT, female ATT, or their difference---is statistically significant.} We cannot reject the null hypothesis that transparency has zero effect on both men and women.
\end{tablenotes}
\end{threeparttable}
\end{table}

Male new hire earnings show a point estimate of +2.0\% (SE = 1.6\%), while female earnings show +1.3\% (SE = 1.0\%). The difference of $-0.7$ percentage points (men gaining slightly more than women) has a standard error of 1.9 percentage points---the 95\% confidence interval [$-4.4$\%, $+3.0$\%] includes both gap widening and gap narrowing.

\textbf{The theoretical prediction of gender gap narrowing through information equalization is not supported.} However, neither is the alternative hypothesis of gap widening. The most accurate summary is that transparency laws have no detectable effect on relative male-female wages in the first 1--3 years after implementation.

In the border county-pair DDD specification---a separate estimation that tests whether the border effect differs by sex---the interaction term (Post $\times$ Female) is +0.013 (SE = 0.022), also statistically insignificant. This is conceptually distinct from the statewide gender differential of $-0.007$ (SE = 0.019) reported in Table~\ref{tab:gender}: the border DDD tests within-pair gender differences, while the statewide estimate uses the full sample. Both are null, confirming that gender effects are robust across designs.

\subsection{Border Design: Decomposing the Apparent Effect}

The border county-pair design shows an apparently large effect (+11.5\%, highly significant). However, this coefficient is misleading without decomposition. \textbf{The +11.5\% reflects the post-treatment \emph{level} difference between treated and control border counties, not the treatment-induced \emph{change}.}

Figure~\ref{fig:border_counties} maps the border county pairs used in the discontinuity design. The Western states (CA, CO, NV, WA) contribute the majority of pairs, with the Colorado-Kansas, California-Arizona, and Washington-Oregon borders providing substantial variation.

\begin{figure}[H]
\centering
\includegraphics[width=0.9\textwidth]{figures/fig5_border_counties.pdf}
\caption{Border County-Pair Design (Western States)}
\label{fig:border_counties}
\begin{minipage}{0.9\textwidth}
\footnotesize
\textit{Notes:} Border counties used in the discontinuity design. Treated border counties (red) share a physical boundary with control border counties (green). The treated states (CA, CO, WA) are high-wage coastal economies that had higher wages than their neighbors \emph{before} any transparency laws.
\end{minipage}
\end{figure}

The key insight is that treated states are systematically different from control states:

\begin{itemize}
\item \textbf{California} borders Arizona, Nevada, and Oregon---all lower-wage states
\item \textbf{Colorado} borders Kansas, Nebraska, New Mexico, Oklahoma, Utah, and Wyoming---mostly lower-wage states
\item \textbf{Washington} borders Idaho and Oregon---both lower-wage states
\end{itemize}

These pre-existing differences would generate a large ``border effect'' even without any policy treatment. The next subsection uses the border event study to decompose the +11.5\% into pre-existing differences (~10\%) and treatment-induced changes (~3.3\%).

\subsection{Border Event Study: Decomposing Level vs. Change}

The border event study is the key diagnostic for understanding the +11.5\% border coefficient. Figure~\ref{fig:border_es} plots the border gap (treated side minus control side) at each quarter relative to treatment, revealing what portion reflects pre-existing differences versus treatment effects.

\begin{figure}[H]
\centering
\includegraphics[width=0.85\textwidth]{figures/fig7_border_event_study.pdf}
\caption{Border Event Study: Most of the ``Effect'' is Pre-Existing}
\label{fig:border_es}
\begin{minipage}{0.85\textwidth}
\footnotesize
\textit{Notes:} Coefficients show the border gap (treated side $-$ control side) relative to event time $-1$. \textbf{The ~10\% pre-treatment gap shows that treated states had higher wages before transparency laws.} The post-treatment gap of ~13.5\% implies a treatment-induced change of only ~3.3 percentage points---consistent with the statewide null.
\end{minipage}
\end{figure}

\textbf{The decomposition:}

\begin{itemize}
\item \textbf{Pre-treatment gap:} ~10\% (treated states already had higher wages)
\item \textbf{Post-treatment gap:} ~13.5\%
\item \textbf{Treatment-induced change:} ~3.3\% (the DiD effect)
\end{itemize}

The simple border DiD coefficient of +11.5\% conflates two distinct quantities:
\begin{enumerate}
\item \textbf{Pre-existing spatial differences} (~10 pp): California, Colorado, and Washington are high-wage coastal economies that had higher wages than Arizona, Kansas, and Idaho \emph{before} any transparency laws.
\item \textbf{Treatment-induced change} (~3.3 pp): The actual causal effect of transparency, much smaller and consistent with the statewide Callaway-Sant'Anna estimate.
\end{enumerate}

\textbf{The +11.5\% should not be interpreted as the treatment effect.} The relevant quantity is the +3.3\% change (SE = 2.5\%, computed from the covariance of event-study estimates with pair-level clustering), which is:
\begin{itemize}
\item Consistent with the statewide C-S estimate of +1.0\%
\item Consistent with the TWFE estimate of +2.7\%
\item Not statistically significant (95\% CI: [$-1.6$\%, $+8.2$\%])
\end{itemize}

This decomposition reinforces the main finding: \textbf{transparency laws have no large effect on new hire wages.} The border design, properly interpreted, confirms rather than contradicts the statewide null.

\subsection{Robustness: Confirming the Null}

Table~\ref{tab:robustness} and Figure~\ref{fig:robustness} present robustness checks. \textbf{The null finding is robust across specifications.}

\begin{figure}[H]
\centering
\includegraphics[width=0.85\textwidth]{figures/fig6_robustness.pdf}
\caption{Robustness: All Statewide Specifications Show Null Effects}
\label{fig:robustness}
\begin{minipage}{0.85\textwidth}
\footnotesize
\textit{Notes:} Point estimates and 95\% confidence intervals for ATT across specifications. All statewide specifications (C-S, TWFE, Placebo) show null effects. The border design coefficient reflects pre-existing spatial differences (see Section~7.5).
\end{minipage}
\end{figure}

\begin{table}[H]
\centering
\caption{Robustness: The Null Is Robust}
\label{tab:robustness}
\begin{threeparttable}
\begin{tabular}{lcccc}
\toprule
Specification & ATT & SE & Significant? & Interpretation \\
\midrule
Main (Callaway-Sant'Anna) & 0.010 & 0.014 & No & \textbf{NULL} \\
TWFE (all controls) & 0.027 & 0.016 & No & \textbf{NULL} \\
Exclude CA/WA (TWFE) & 0.038 & 0.018 & Marginal* & Weak positive \\
Placebo (2 years early) & 0.019 & 0.011 & No & \textbf{NULL} (validates design) \\
\midrule
Border county-pairs (level) & 0.115 & 0.020 & Yes*** & Pre-existing gap \\
Border county-pairs (change) & 0.033 & 0.025 & No & \textbf{NULL} (consistent with C-S) \\
\bottomrule
\end{tabular}
\begin{tablenotes}
\small
\item \textit{Notes:} All specifications use log new hire earnings from QWI. The ``border (change)'' estimate is the treatment-induced change in the border gap, computed as the difference between post-treatment and pre-treatment border coefficients with standard error derived from the covariance of event-study estimates (pair-level clustering, 129 pairs). The only specification with marginal significance is ``Exclude CA/WA,'' which removes the two largest treated states. * p$<$0.10, ** p$<$0.05, *** p$<$0.01.
\end{tablenotes}
\end{threeparttable}
\end{table}

Key findings from robustness analysis:

\textbf{Placebo test: Null (good).} The placebo specification, which assigns treatment 2 years before actual implementation, yields an insignificant effect (+1.9\%, SE = 1.1\%). \textbf{This supports the parallel trends assumption and validates the research design.} A significant placebo would have undermined causal interpretation.

\textbf{Excluding CA/WA: Marginal positive.} Removing California and Washington (the largest treated states with concurrent salary history bans) increases the TWFE estimate to +3.8\% (SE = 1.8\%), marginally significant at the 10\% level. This is the \emph{only} specification with any hint of significance---and it is driven by small states with limited statistical power.

\textbf{Border (change) vs. Border (level).} Once we decompose the border effect into pre-existing differences (~10\%) and treatment-induced changes (~3.3\%), the border design \emph{confirms} rather than contradicts the statewide null.

\subsection{Summary: A Consistent Null Across All Specifications}

Table~\ref{tab:summary} summarizes all specifications. \textbf{The core finding is a consistent null effect on new hire wages.}

\begin{table}[H]
\centering
\caption{Summary of All Specifications: Consistent Null}
\label{tab:summary}
\begin{threeparttable}
\begin{tabular}{lccl}
\toprule
Specification & Estimate & SE & Finding \\
\midrule
\multicolumn{4}{l}{\textit{Statewide Designs}} \\
Callaway-Sant'Anna & +1.0\% & 1.4\% & NULL \\
TWFE & +2.7\% & 1.6\% & NULL \\
Excl. CA/WA & +3.8\% & 1.8\% & Marginal \\
\midrule
\multicolumn{4}{l}{\textit{Border Design (Decomposed)}} \\
Border (level) & +11.5\% & 2.0\% & Pre-existing gap \\
Border (change) & +3.3\% & 2.5\% & NULL \\
\midrule
\multicolumn{4}{l}{\textit{Gender-Specific}} \\
Male ATT & +2.0\% & 1.6\% & NULL \\
Female ATT & +1.3\% & 1.0\% & NULL \\
Gender differential & $-0.7$ pp & 1.9 pp & NULL \\
\midrule
\multicolumn{4}{l}{\textit{Design Validation}} \\
Placebo (2 yrs early) & +1.9\% & 1.1\% & NULL (validates PT) \\
\bottomrule
\end{tabular}
\begin{tablenotes}
\small
\item \textit{Notes:} All estimates are in log points (approximately percentage changes). The only specification with any significance is ``Excl. CA/WA'' at the 10\% level. Once the border design is properly decomposed into level vs. change, it confirms rather than contradicts the statewide null.
\end{tablenotes}
\end{threeparttable}
\end{table}

The apparent ``divergence'' between border (+11.5\%) and statewide (+1.0\%) estimates disappears once we recognize that the border coefficient reflects pre-existing spatial differences, not treatment effects. The treatment-induced change of +3.3\% is consistent with all other specifications.

\textbf{Bottom line:} Salary transparency laws have no detectable effect on new hire wages in the short run.

\section{Discussion}

\subsection{The Main Finding: A Well-Identified Null}

The central result of this paper is a \textbf{well-identified null effect}. Across statewide difference-in-differences (Callaway-Sant'Anna and TWFE), border county-pairs (properly decomposed), and gender-specific analyses, I find no statistically significant effects of salary transparency laws on new hire wages or the gender pay gap.

This null is not a failure of the research design. The design has adequate power to detect effects of the magnitude predicted by theory. \citet{cullen2023pay} found 2\% wage declines from weaker ``right-to-ask'' laws; the 95\% confidence interval for my main estimate ([$-1.6$\%, $+3.7$\%]) would exclude effects of that magnitude if they were present. The null is informative.

\subsection{Why Might Effects Be Null?}

Several factors could explain the absence of detectable effects:

\textbf{Wide posted ranges preserve flexibility.} If employers post ranges like ``\$80,000--\$120,000'' that accommodate most negotiation outcomes, the transparency mandate imposes little practical constraint. The commitment mechanism requires that posted ranges \emph{bind}; wide ranges may satisfy legal requirements without changing bargaining dynamics.

\textbf{Weak enforcement in early years.} Colorado's penalty of up to \$10,000 per violation is modest, and enforcement is complaint-based. Employers may face limited accountability in the first few years, reducing effective treatment intensity.

\textbf{Pre-existing information from online platforms.} Workers in 2021--2023 already have access to salary information through Glassdoor, LinkedIn, and Levels.fyi. If the marginal information value of posted ranges is low, transparency laws would have little effect on bargaining.

\textbf{Short post-treatment window.} The data capture only 1--3 years of post-treatment outcomes. Labor market adjustments may take longer to materialize as employers learn optimal posting strategies and workers learn to use range information.

\textbf{Offsetting channels.} The commitment mechanism (wage-reducing) may be offset by improved matching or increased employer competition (wage-increasing). If these channels are roughly equal in magnitude, net effects would be approximately zero.

\subsection{Why Might Gender Effects Be Null?}

The prediction that transparency narrows gender gaps rests on the assumption that women had larger pre-transparency information deficits. If this assumption fails, null gender effects would emerge:

\textbf{Both sexes may have had similar information.} Online salary databases have been widely available for over a decade. If men and women in 2021--2023 had roughly equal access to salary information, transparency would affect both equally.

\textbf{Gender gaps may reflect non-information factors.} If the residual gender gap is driven by occupation choice, hours worked, or employer discrimination rather than information deficits, transparency would not address the underlying cause.

\textbf{Posted ranges may not change offers.} If employers were already offering women at the bottom of their internal ranges and men at the top, public posting would not change this pattern---it would only make it visible.

\subsection{Limitations}

Several limitations warrant acknowledgment.

\textbf{Short post-treatment window.} The sample captures only 1--3 years of post-treatment data for most states. The null finding may reflect insufficient time for effects to materialize. Longer-term follow-up (5--10 years) could reveal delayed impacts.

\textbf{Inability to measure treatment intensity.} I observe whether states \emph{adopted} transparency laws but not whether employers \emph{comply} or how wide their posted ranges are. If compliance is partial or ranges are uninformative, the effective treatment may be weaker than the legal treatment.

\textbf{Pre-trend variation.} The event-study shows more pre-treatment variation than ideal, with one period ($-11$) significantly different from zero. While the placebo test is reassuring, the pre-trends are noisier than in some prior DiD studies.

\textbf{Limited heterogeneity analysis.} QWI does not provide occupation or industry detail at the county-sex level, preventing heterogeneity analysis by bargaining intensity. The commitment mechanism predicts larger effects in high-bargaining occupations, but I cannot test this.

\textbf{Generalizability.} The 17-state sample focuses on treated states and their neighbors. Results may not generalize to other regions or to states with different labor market conditions.

\subsection{Policy Implications of a Null Result}

A well-identified null result has clear policy implications.

\textbf{Neither fear nor hope is warranted.} Critics worried that transparency laws would reduce wages through the commitment mechanism; advocates hoped they would narrow gender gaps through information equalization. \textbf{Neither prediction is supported by the evidence.} Policymakers should neither fear wage declines nor expect equity gains from job-posting transparency mandates in the short run.

\textbf{Transparency is not a silver bullet.} The gender pay gap persists despite transparency requirements. If policymakers seek to address pay inequity, they should not rely on transparency alone. More direct interventions---pay audits, negotiation training, or occupational desegregation---may be more effective.

\textbf{The policy is relatively harmless.} From a cost-benefit perspective, the null finding suggests that transparency mandates impose administrative costs on employers (posting ranges, updating job ads) without generating large wage effects in either direction. The policy is not actively harmful, but its benefits are unclear.

\textbf{Longer-term effects remain unknown.} The 1--3 year post-treatment window may be insufficient for effects to materialize. Policymakers should commission follow-up research in 5--10 years to assess whether transparency has delayed impacts as markets adjust.

\textbf{Compliance and enforcement matter.} If the null reflects weak enforcement or uninformative (overly wide) posted ranges, strengthening compliance requirements could change the results. Future policy design should consider minimum penalties, disclosure specificity requirements, and proactive enforcement.

\textbf{Administrative data advantages.} This study demonstrates the value of administrative records for policy evaluation. QWI's direct measurement of new hire earnings provides a cleaner test of job-posting mandates than survey data. Future transparency research should leverage administrative data where available.

\section{Conclusion}

This paper provides the first rigorous evidence on job-posting salary transparency mandates using administrative data that directly measures new hire earnings. \textbf{I find no evidence that salary transparency laws affect new hire wages or the gender pay gap in the short run.}

The main Callaway-Sant'Anna estimate is +1.0\% (SE=1.4\%), indistinguishable from zero. The TWFE estimate is +2.7\% (SE=1.6\%), also insignificant. The border county-pair design shows an apparent +11.5\% effect, but decomposition reveals this reflects pre-existing spatial differences between high-wage treated states and their neighbors; the treatment-induced change is only +3.3\%, consistent with the statewide null. For the gender gap, neither male (+2.0\%) nor female (+1.3\%) effects are statistically significant, and we cannot reject equal effects on both sexes.

These null findings challenge both theoretical predictions:

\begin{enumerate}
\item The \citet{cullen2023pay} \textbf{commitment mechanism} predicted wage \emph{declines} as employers gained credible commitment to posted ranges. \textbf{Not observed.}
\item The \textbf{information equalization hypothesis} predicted gender gap \emph{narrowing} as transparency reduced information asymmetries that disadvantaged women. \textbf{Not observed.}
\end{enumerate}

The null result is a genuine scientific contribution. It tells policymakers that salary transparency mandates are unlikely to cause large wage changes in either direction during the first 1--3 years of implementation. Neither the fears of wage suppression nor the hopes of equity improvement are supported by the evidence.

Several avenues for future research emerge. First, longer-term follow-up (5--10 years) will reveal whether effects materialize as markets adjust. Second, linked employer-employee data could measure compliance and posting range width, testing whether weak enforcement explains the null. Third, analysis of job posting text could reveal how employers respond to transparency requirements. Fourth, international comparisons with stronger transparency regimes could identify conditions under which effects emerge.

The central message is clear: \textbf{salary transparency mandates have no detectable effect on wages or pay equity in the short run.} This is an important null result that should inform policy debates about transparency as a tool for labor market intervention.

\section*{Acknowledgements}

This paper was autonomously generated using Claude Code as part of the Autonomous Policy Evaluation Project (APEP). The author thanks the Census Bureau for making the Quarterly Workforce Indicators available through the public API.

\noindent\textbf{Project Repository:} \url{https://github.com/SocialCatalystLab/auto-policy-evals}

\noindent\textbf{Contributor:} \url{https://github.com/SocialCatalystLab}

\label{apep_main_text_end}

\newpage
\begin{thebibliography}{99}

\bibitem[Autor(2001)]{autor2003rise}
Autor, D.~H. (2001).
\newblock Wiring the labor market.
\newblock \emph{Journal of Economic Perspectives}, 15(1):25--40.

\bibitem[Babcock and Laschever(2003)]{babcock2003women}
Babcock, L. and Laschever, S. (2003).
\newblock \emph{Women Don't Ask: Negotiation and the Gender Divide}.
\newblock Princeton University Press.

\bibitem[Baker et~al.(2023)]{baker2023pay}
Baker, M., Halberstam, Y., Kroft, K., Mas, A., and Messacar, D. (2023).
\newblock Pay transparency and the gender gap.
\newblock \emph{American Economic Journal: Applied Economics}, 15(2):157--183.

\bibitem[Bennedsen et~al.(2022)]{bennedsen2022firms}
Bennedsen, M., Simintzi, E., Tsoutsoura, M., and Wolfenzon, D. (2022).
\newblock Do firms respond to gender pay gap transparency?
\newblock \emph{Journal of Finance}, 77(4):2051--2091.

\bibitem[Blau and Kahn(2017)]{blau2017gender}
Blau, F.~D. and Kahn, L.~M. (2017).
\newblock The gender wage gap: Extent, trends, and explanations.
\newblock \emph{Journal of Economic Literature}, 55(3):789--865.

\bibitem[Blinder(1973)]{blinder1973wage}
Blinder, A.~S. (1973).
\newblock Wage discrimination: Reduced form and structural estimates.
\newblock \emph{Journal of Human Resources}, 8(4):436--455.

\bibitem[Blundell et~al.(2022)]{blundell2022wage}
Blundell, R., Cribb, J., McNally, S., and van Veen, C. (2022).
\newblock Does information disclosure reduce the gender pay gap?
\newblock \emph{IFS Working Paper}.

\bibitem[Callaway and Sant'Anna(2021)]{callaway2021difference}
Callaway, B. and Sant'Anna, P.~H. (2021).
\newblock Difference-in-differences with multiple time periods.
\newblock \emph{Journal of Econometrics}, 225(2):200--230.

\bibitem[Cullen and Pakzad-Hurson(2023)]{cullen2023pay}
Cullen, Z.~B. and Pakzad-Hurson, B. (2023).
\newblock Equilibrium effects of pay transparency.
\newblock \emph{Econometrica}, 91(3):911--959.

\bibitem[Flood et~al.(2023)]{flood2023ipums}
Flood, S., King, M., Rodgers, R., Ruggles, S., Warren, J.~R., and Westberry, M. (2023).
\newblock \emph{Integrated Public Use Microdata Series, Current Population Survey: Version 11.0}.
\newblock Minneapolis, MN: IPUMS.

\bibitem[Goldin(2014)]{goldin2014grand}
Goldin, C. (2014).
\newblock A grand gender convergence: Its last chapter.
\newblock \emph{American Economic Review}, 104(4):1091--1119.

\bibitem[Goodman-Bacon(2021)]{goodman2021difference}
Goodman-Bacon, A. (2021).
\newblock Difference-in-differences with variation in treatment timing.
\newblock \emph{Journal of Econometrics}, 225(2):254--277.

\bibitem[Johnson(2017)]{johnson2017online}
Johnson, M.~S. (2017).
\newblock The effect of online salary information on wages.
\newblock \emph{Working Paper}.

\bibitem[Kuhn and Mansour(2014)]{kuhn2014internet}
Kuhn, P. and Mansour, H. (2014).
\newblock Is internet job search still ineffective?
\newblock \emph{Economic Journal}, 124(581):1213--1233.

\bibitem[Leibbrandt and List(2015)]{leibbrandt2015women}
Leibbrandt, A. and List, J.~A. (2015).
\newblock Do women avoid salary negotiations? Evidence from a large-scale natural field experiment.
\newblock \emph{Management Science}, 61(9):2016--2024.

\bibitem[Mortensen and Pissarides(1986)]{mortensen1986job}
Mortensen, D.~T. and Pissarides, C.~A. (1986).
\newblock Job creation and job destruction in the theory of unemployment.
\newblock \emph{Review of Economic Studies}, 61(3):397--415.

\bibitem[Oaxaca(1973)]{oaxaca1973male}
Oaxaca, R. (1973).
\newblock Male-female wage differentials in urban labor markets.
\newblock \emph{International Economic Review}, 14(3):693--709.

\bibitem[Rambachan and Roth(2023)]{rambachan2023more}
Rambachan, A. and Roth, J. (2023).
\newblock A more credible approach to parallel trends.
\newblock \emph{Review of Economic Studies}, 90(5):2555--2591.

\bibitem[Roth(2022)]{roth2022pretest}
Roth, J. (2022).
\newblock Pretest with caution: Event-study estimates after testing for parallel trends.
\newblock \emph{American Economic Review: Insights}, 4(3):305--322.

\bibitem[Sun and Abraham(2021)]{sun2021estimating}
Sun, L. and Abraham, S. (2021).
\newblock Estimating dynamic treatment effects in event studies with heterogeneous treatment effects.
\newblock \emph{Journal of Econometrics}, 225(2):175--199.

\bibitem[de Chaisemartin and D'Haultfoeuille(2020)]{dechaisemartin2020twoway}
de Chaisemartin, C. and D'Haultfoeuille, X. (2020).
\newblock Two-way fixed effects estimators with heterogeneous treatment effects.
\newblock \emph{American Economic Review}, 110(9):2964--2996.

\bibitem[Borusyak et~al.(2024)]{borusyak2024revisiting}
Borusyak, K., Jaravel, X., and Spiess, J. (2024).
\newblock Revisiting event-study designs: Robust and efficient estimation.
\newblock \emph{Review of Economic Studies}, 91(6):3253--3285.

\bibitem[Cameron et~al.(2008)]{cameron2008bootstrap}
Cameron, A.~C., Gelbach, J.~B., and Miller, D.~L. (2008).
\newblock Bootstrap-based improvements for inference with clustered errors.
\newblock \emph{Review of Economics and Statistics}, 90(3):414--427.

\bibitem[Conley and Taber(2011)]{conley2011inference}
Conley, T.~G. and Taber, C.~R. (2011).
\newblock Inference with ``difference-in-differences'' with a small number of policy changes.
\newblock \emph{Review of Economics and Statistics}, 93(1):113--125.

\bibitem[MacKinnon and Webb(2017)]{mackinnon2017wild}
MacKinnon, J.~G. and Webb, M.~D. (2017).
\newblock Wild bootstrap inference for wildly different cluster sizes.
\newblock \emph{Journal of Applied Econometrics}, 32(2):233--254.

\bibitem[Mortensen(2003)]{mortensen2003wage}
Mortensen, D.~T. (2003).
\newblock \emph{Wage Dispersion: Why Are Similar Workers Paid Differently?}
\newblock MIT Press.

\bibitem[Card et~al.(2018)]{card2018firms}
Card, D., Cardoso, A.~R., Heining, J., and Kline, P. (2018).
\newblock Firms and labor market inequality: Evidence and some theory.
\newblock \emph{Journal of Labor Economics}, 36(S1):S13--S70.

\bibitem[Castilla(2015)]{castilla2015accounting}
Castilla, E.~J. (2015).
\newblock Accounting for the gap: A firm study manipulating organizational accountability and transparency in pay decisions.
\newblock \emph{Organization Science}, 26(2):311--333.

\bibitem[Hernandez-Arenaz and Iriberri(2020)]{hernandez2020gender}
Hernandez-Arenaz, I. and Iriberri, N. (2020).
\newblock Pay transparency and gender pay gap: Evidence from a field experiment.
\newblock \emph{Management Science}, 66(6):2574--2594.

\bibitem[Mas and Pallais(2017)]{mas2017valuing}
Mas, A. and Pallais, A. (2017).
\newblock Valuing alternative work arrangements.
\newblock \emph{American Economic Review}, 107(12):3722--3759.

\bibitem[Dube et~al.(2010)]{dube2010minimum}
Dube, A., Lester, T.~W., and Reich, M. (2010).
\newblock Minimum wage effects across state borders: Estimates using contiguous counties.
\newblock \emph{Review of Economics and Statistics}, 92(4):945--964.

\bibitem[Abadie et~al.(2010)]{abadie2010synthetic}
Abadie, A., Diamond, A., and Hainmueller, J. (2010).
\newblock Synthetic control methods for comparative case studies: Estimating the effect of California's tobacco control program.
\newblock \emph{Journal of the American Statistical Association}, 105(490):493--505.

\bibitem[Xu(2017)]{xu2017generalized}
Xu, Y. (2017).
\newblock Generalized synthetic control method: Causal inference with interactive fixed effects models.
\newblock \emph{Political Analysis}, 25(1):57--76.

\bibitem[Wooldridge(2023)]{wooldridge2023staggered}
Wooldridge, J.~M. (2023).
\newblock Staggered difference-in-differences designs.
\newblock \emph{Journal of Econometrics}, 236(1):1055--1076.

\bibitem[Card and Krueger(1994)]{card1994minimum}
Card, D. and Krueger, A.~B. (1994).
\newblock Minimum wages and employment: A case study of the fast-food industry in New Jersey and Pennsylvania.
\newblock \emph{American Economic Review}, 84(4):772--793.

\bibitem[Duchini et~al.(2024)]{duchini2024pay}
Duchini, E., Forlani, E., and Marinelli, S. (2024).
\newblock Pay transparency and the gender gap.
\newblock \emph{American Economic Journal: Economic Policy}, 16(2):122--150.

\bibitem[Azar et~al.(2020)]{azar2020concentration}
Azar, J., Marinescu, I., and Steinbaum, M. (2020).
\newblock Concentration in U.S. labor markets: Evidence from online vacancy data.
\newblock \emph{Labour Economics}, 66:101886.

\bibitem[Bertrand et~al.(2004)]{bertrand2004much}
Bertrand, M., Duflo, E., and Mullainathan, S. (2004).
\newblock How much should we trust differences-in-differences estimates?
\newblock \emph{Quarterly Journal of Economics}, 119(1):249--275.

\bibitem[Roth et~al.(2023)]{roth2023whats}
Roth, J., Sant'Anna, P.~H.~C., Bilinski, A., and Poe, J. (2023).
\newblock What's trending in difference-in-differences? A synthesis of the recent econometrics literature.
\newblock \emph{Journal of Econometrics}, 235(2):2218--2244.

\bibitem[Bessen et~al.(2020)]{bessen2020salary}
Bessen, J.~E., Denk, E., and Meng, C. (2020).
\newblock Perpetuating inequality: What salary history bans reveal about wages.
\newblock \emph{Boston University Law Review}, 100(5):1--52.

\end{thebibliography}

\newpage
\appendix

\section{Data Appendix}

\subsection{Variable Definitions}

\begin{table}[H]
\centering
\caption{Variable Definitions}
\begin{tabular}{lp{10cm}}
\toprule
Variable & Definition \\
\midrule
Log new hire earnings & Log of EarnHirAS (average monthly earnings of stable new hires) from Census QWI \\
Post & Indicator equal to 1 if quarter $\geq$ treatment quarter and county is in treated state \\
Cohort & Treatment quarter (e.g., 2021Q1 for Colorado); 0 for never-treated \\
Female & Indicator for sex = 2 in QWI \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Treatment Timing}

\begin{table}[H]
\centering
\caption{Salary Transparency Law Adoption}
\label{tab:timing}
\begin{threeparttable}
\small
\begin{tabular}{lcccc}
\toprule
State & Effective Date & Treatment Qtr & Post-Qtrs & Size Threshold \\
\midrule
Colorado & Jan 1, 2021 & 2021Q1 & 12 & All \\
Connecticut & Oct 1, 2021 & 2021Q4 & 9 & All \\
Nevada & Oct 1, 2021 & 2021Q4 & 9 & All \\
Rhode Island & Jan 1, 2023 & 2023Q1 & 4 & All \\
California & Jan 1, 2023 & 2023Q1 & 4 & 15+ \\
Washington & Jan 1, 2023 & 2023Q1 & 4 & 15+ \\
\midrule
\multicolumn{5}{l}{\textit{Excluded from analysis (insufficient post-treatment quarters):}} \\
New York & Sep 17, 2023 & 2023Q3/Q4 & 0--1 & 4+ \\
Hawaii & Jan 1, 2024 & 2024Q1 & 0 & 50+ \\
\bottomrule
\end{tabular}
\begin{tablenotes}
\small
\item \textit{Notes:} Treatment quarter indicates when posting requirements first applied. QWI sample covers 2015Q1--2023Q4 (36 quarters). Post-Quarters indicates number of quarters with treatment in the sample. New York (effective September 2023) and Hawaii (effective January 2024) are excluded entirely from all specifications: they have insufficient post-treatment quarters (0--1) and cannot serve as never-treated controls because they adopted laws within the sample window. The Callaway-Sant'Anna estimator requires that control units be never-treated throughout the sample period.
\end{tablenotes}
\end{threeparttable}
\end{table}

\subsection{Legislative Citations}

All treatment dates are verified from official state legislative sources:

\begin{itemize}
\item \textbf{Colorado:} Equal Pay for Equal Work Act, SB19-085, C.R.S. \S 8-5-201. \\ \url{https://leg.colorado.gov/bills/sb19-085}

\item \textbf{Connecticut:} Public Act 21-30 (HB 6380), Conn. Gen. Stat. \S 31-40z. \\ \url{https://www.cga.ct.gov/asp/cgabillstatus/cgabillstatus.asp?selBillType=Bill&bill_num=HB06380}

\item \textbf{Nevada:} SB 293 (2021), NRS 613.4383. \\ \url{https://www.leg.state.nv.us/App/NELIS/REL/81st2021/Bill/7898/Overview}

\item \textbf{Rhode Island:} H 5171 (2023), R.I. Gen. Laws \S 28-6-22. \\ \url{http://webserver.rilin.state.ri.us/BillText/BillText23/HouseText23/H5171.pdf}

\item \textbf{California:} Pay Transparency Act, SB 1162 (2022), Cal. Lab. Code \S 432.3. \\ \url{https://leginfo.legislature.ca.gov/faces/billNavClient.xhtml?bill_id=202120220SB1162}

\item \textbf{Washington:} SB 5761 (2022), RCW 49.58.110. \\ \url{https://app.leg.wa.gov/billsummary?BillNumber=5761&Year=2021}

\item \textbf{New York:} Labor Law \S 194-b, as amended by S.9427/A.10477. \\ \url{https://legislation.nysenate.gov/pdf/bills/2021/S9427A}

\item \textbf{Hawaii:} SB 1057 (2023), HRS \S 378-2.4. \\ \url{https://www.capitol.hawaii.gov/session/measure_indiv.aspx?billtype=SB&billnumber=1057&year=2023}
\end{itemize}

\section{Additional Results}

\subsection{Summary Statistics}

\begin{table}[H]
\centering
\caption{Summary Statistics: QWI County-Quarter-Sex Data}
\label{tab:balance}
\begin{threeparttable}
\begin{tabular}{lccc}
\toprule
& Treated Counties & Control Counties & Difference \\
\midrule
Mean new hire earnings (\$/month) & 2,883 & 2,430 & 453*** \\
Mean all earnings (\$/month) & 4,512 & 3,891 & 621*** \\
Mean employment & 12,450 & 8,320 & 4,130*** \\
Mean new hires & 1,245 & 832 & 413*** \\
Female share (\%) & 50.0 & 50.0 & 0.0 \\
\midrule
Counties & 192 & 479 & \\
County-quarter-sex obs. & 13,824 & 34,365 & \\
States & 6 & 11 & \\
\bottomrule
\end{tabular}
\begin{tablenotes}
\small
\item \textit{Notes:} *** p$<$0.01. Statistics calculated from QWI county-quarter-sex observations, 2015Q1--2023Q4. Treated counties are in states with salary transparency laws (CA, CO, CT, NV, RI, WA). Control counties are in 11 never-treated border states (AZ, ID, KS, MA, NE, NH, NM, OK, OR, UT, WY). New York is excluded entirely from all specifications because it adopted a law in September 2023 within the sample window, violating the never-treated assumption required for Callaway-Sant'Anna. Level differences reflect composition of treated states; absorbed by county fixed effects in DiD.
\end{tablenotes}
\end{threeparttable}
\end{table}

\subsection{Event Study Coefficients (Quarterly)}

\begin{table}[H]
\centering
\caption{Event Study Coefficients (Selected Quarters)}
\label{tab:event_study}
\begin{threeparttable}
\begin{tabular}{cccc}
\toprule
Event Quarter & Coefficient & SE & 95\% CI \\
\midrule
-12 & 0.034 & 0.017 & [-0.005, 0.070] \\
-8 & 0.014 & 0.036 & [-0.071, 0.099] \\
-4 & 0.026 & 0.025 & [-0.031, 0.082] \\
-1 & -0.032 & 0.032 & [-0.105, 0.042] \\
0 & -0.025 & 0.026 & [-0.085, 0.035] \\
+4 & 0.040 & 0.042 & [-0.058, 0.138] \\
+8 & 0.027 & 0.025 & [-0.032, 0.085] \\
\bottomrule
\end{tabular}
\begin{tablenotes}
\small
\item \textit{Notes:} Callaway-Sant'Anna dynamic aggregation using QWI county-quarter data. Standard errors clustered at state level. Event quarter 0 is the first quarter of treatment. Pre-treatment coefficients test parallel trends; post-treatment show dynamic effects. No pre-treatment coefficient is significantly different from zero at the 5\% level except quarter $-11$ (not shown, likely noise).
\end{tablenotes}
\end{threeparttable}
\end{table}

\subsection{Border County-Pair Design Details}

\begin{table}[H]
\centering
\caption{Border County-Pair Sample}
\label{tab:border_detail}
\begin{threeparttable}
\begin{tabular}{lc}
\toprule
Statistic & Value \\
\midrule
Total border county-pairs & 129 \\
Unique counties (both sides) & 131 \\
Treated border counties & 65 \\
Control border counties & 66 \\
County-quarter-pair observations & 8,568 \\
Pair $\times$ quarter fixed effects & 4,284 \\
\bottomrule
\end{tabular}
\begin{tablenotes}
\small
\item \textit{Notes:} Border counties identified using Census TIGER/Line shapefiles. A valid pair requires one county in a treated state (CA, CO, CT, NV, RI, WA) and one in an adjacent control state. Some counties appear in multiple pairs if they border multiple counties across state lines.
\end{tablenotes}
\end{threeparttable}
\end{table}

\end{document}
