{
  "paper_id": "apep_0086",
  "scan_date": "2026-02-06T12:43:37.548772+00:00",
  "scan_version": "2.0.0",
  "model": "openai/gpt-5.2",
  "overall_verdict": "CLEAN",
  "files_scanned": 12,
  "flags": [
    {
      "category": "DATA_PROVENANCE_MISSING",
      "severity": "MEDIUM",
      "file": "01_fetch_data.R",
      "lines": [
        94,
        147,
        171,
        190
      ],
      "evidence": "The script constructs only two measures via pivot_wider(): 'unemp_rate' and 'employment'. It then refers to a 'labor_force' column that is never created in this pipeline. This implies either (a) the script as shown would error, or (b) earlier versions/data objects differed. Either way, the provenance/derivation of the labor-force-related variables is not reproducible from the code shown, and the comments/variable names suggest confusion about which LAUS series codes correspond to which concepts (labor force vs unemployment rate). This matters because subsequent scripts (02_clean_data.R) explicitly acknowledge mislabeling and rename columns accordingly, indicating that the raw fetched data semantics were incorrect at some point.: lf_series <- sprintf(\"LASST%02d0000000000003\", state_fips_map$statefip)  # Unemp rate\nemp_series <- sprintf(\"LASST%02d0000000000005\", state_fips_map$statefip)  # Employment level\n...\n# Parse state FIPS from series ID and classify measure\nbls_parsed <- bls_raw %>%\n  mutate(\n    statefip = as.integer(substr(series_id, 6, 7)),\n    measure = ifelse(grepl(\"03$\", series_id), \"unemp_rate\", \"employment\"),\n    month = as.integer(sub(\"M\", \"\", period))\n  )\n...\nbls_march <- bls_parsed %>%\n  filter(month == 3) %>%\n  select(statefip, year, measure, value) %>%\n  pivot_wider(names_from = measure, values_from = value) %>%\n  mutate(\n    lfp_thousands = labor_force,\n    emp_thousands = employment,\n    unemp_thousands = labor_force - employment\n  )",
      "confidence": 0.8
    },
    {
      "category": "SUSPICIOUS_TRANSFORMS",
      "severity": "MEDIUM",
      "file": "02_clean_data.R",
      "lines": [
        12,
        26
      ],
      "evidence": "This script indicates that a core variable in the fetched data (named 'labor_force' in bls_state_panel.rds) actually contains the unemployment rate series, and then corrects it by renaming. That correction may be appropriate, but it also signals that earlier outputs could have been generated using misinterpreted variables if any downstream analysis used the pre-fix naming. Given the manuscript\u2019s emphasis on LAUS employment/unemployment outcomes, this is a material integrity risk unless the authors can show that all published results were generated after the fix and from the corrected panel.: # From 01_fetch_data.R, series 03 was labeled \"labor_force\" but is actually\n# unemployment rate (%). series 05 labeled \"employment\" is employment level.\n# Fix column names:\n\nbls <- bls_raw %>%\n  rename(\n    unemp_rate_march = labor_force,  # Series 03 = unemployment rate\n    employment_march = employment     # Series 05 = employment level\n  )",
      "confidence": 0.75
    },
    {
      "category": "HARD_CODED_RESULTS",
      "severity": "LOW",
      "file": "06_tables.R",
      "lines": [
        55,
        73
      ],
      "evidence": "A specific policy effective date for Wyoming is hard-coded at table-generation time if missing in the PDMP date file. This does not hard-code econometric results, but it is a hard-coded substantive input that can change treatment timing in reported tables. It is also internally inconsistent with 01_fetch_data.R, where WY is included with mandate_effective_date = \"2020-01-01\" and full-exposure year 2021. The discrepancy should be reconciled and documented (source citation for the correct effective date and how 'full-exposure year' is defined).: mutate(\n  # For WY: use known date if not in pdmp file\n  mandate_effective_date = ifelse(is.na(mandate_effective_date) & state_abbr == \"WY\",\n                                 \"2020-07-01\", mandate_effective_date),\n  mandate_year_full_exposure = ifelse(is.na(mandate_year_full_exposure),\n                                     first_treat, mandate_year_full_exposure)\n)",
      "confidence": 0.7
    },
    {
      "category": "METHODOLOGY_MISMATCH",
      "severity": "MEDIUM",
      "file": "01_fetch_data.R",
      "lines": [
        320,
        363
      ],
      "evidence": "The manuscript states that TWFE robustness controls include naloxone access laws, Good Samaritan laws, Medicaid expansion, and medical marijuana legalization. In the provided codebase, only Medicaid expansion and recreational marijuana dates are compiled. No naloxone/Good Samaritan series are defined here, and the marijuana series is recreational (rec_marijuana), not medical marijuana. This is a mismatch between claimed controls and implemented data construction, unless those other policy controls are built in other (missing) scripts or data files not provided.: cat(\"\\n=== PART 3: Concurrent Policy Dates ===\\n\")\n\nmedicaid_expansion <- tribble(\n  ~statefip, ~medicaid_expansion_year,\n  ...\n)\n\nrec_marijuana <- tribble(\n  ~statefip, ~rec_marijuana_year,\n  ...\n)",
      "confidence": 0.65
    }
  ],
  "file_verdicts": [
    {
      "file": "07_advisor_fixes.R",
      "verdict": "CLEAN"
    },
    {
      "file": "01_fetch_data.R",
      "verdict": "CLEAN"
    },
    {
      "file": "06_tables.R",
      "verdict": "CLEAN"
    },
    {
      "file": "00_packages.R",
      "verdict": "CLEAN"
    },
    {
      "file": "04_robustness.R",
      "verdict": "CLEAN"
    },
    {
      "file": "02_clean_data.R",
      "verdict": "CLEAN"
    },
    {
      "file": "08_sensitivity.R",
      "verdict": "CLEAN"
    },
    {
      "file": "08_revision.R",
      "verdict": "CLEAN"
    },
    {
      "file": "07_first_stage.R",
      "verdict": "CLEAN"
    },
    {
      "file": "03_main_analysis.R",
      "verdict": "CLEAN"
    },
    {
      "file": "05_figures.R",
      "verdict": "CLEAN"
    },
    {
      "file": "01b_fix_treatment.R",
      "verdict": "CLEAN"
    }
  ],
  "summary": {
    "verdict": "CLEAN",
    "counts": {
      "CRITICAL": 0,
      "HIGH": 0,
      "MEDIUM": 3,
      "LOW": 1
    },
    "one_liner": "Minor issues only",
    "executive_summary": "Minor code quality issues detected, but no evidence of data fabrication or manipulation.",
    "top_issues": [],
    "full_report_url": "/tournament/corpus_scanner/scans/apep_0086_scan.json"
  },
  "error": null
}