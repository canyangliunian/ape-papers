{
  "paper_id": "apep_0183",
  "scan_date": "2026-02-06T12:59:29.082035+00:00",
  "scan_version": "2.0.0",
  "model": "openai/gpt-5.2",
  "overall_verdict": "SUSPICIOUS",
  "files_scanned": 14,
  "flags": [
    {
      "category": "METHODOLOGY_MISMATCH",
      "severity": "HIGH",
      "file": "01_fetch_data.R",
      "lines": [
        132,
        189
      ],
      "evidence": "This script defines signed distance as + for treated and \u2212 for control. Other scripts assume the opposite sign convention (treated negative, control positive). If different data-generation scripts were used at different times to produce data/qwi_border.rds, the running variable sign can flip across versions, which can flip the interpretation/sign of the estimated discontinuity terms and interactions.: pair_counties <- bind_rows(treated_counties, control_counties) %>%\n    mutate(\n      # Signed distance: positive for treated, negative for control\n      signed_dist = ifelse(treated, dist_to_border, -dist_to_border),\n      treated_state = pair$treated_fips,\n      control_state = pair$control_fips\n    )",
      "confidence": 0.85
    },
    {
      "category": "METHODOLOGY_MISMATCH",
      "severity": "HIGH",
      "file": "01e_fetch_robust.R",
      "lines": [
        126,
        176
      ],
      "evidence": "This script encodes distance with the opposite sign convention from 01_fetch_data.R (+ for control, \u2212 for treated). Downstream analysis (03_main_analysis.R) states/assumes this convention. If qwi_border.rds was generated by 01_fetch_data.R (using signed_dist) rather than 01e_fetch_robust.R (using dist_km), the analysis can silently run with a different distance sign or even without the intended variable, changing the implemented DiDisc/RDD functional form relative to what the manuscript describes (signed distance running variable).: treated_df <- treated_counties %>%\n  st_drop_geometry() %>%\n  mutate(\n    border_pair = border_pair_name,\n    treated = 1,\n    treated_state = treated_fips,\n    dist_to_border = treated_dists,\n    dist_km = -dist_to_border  # Negative = treated side\n  )\n\ncontrol_df <- neighbor_counties %>%\n  st_drop_geometry() %>%\n  mutate(\n    border_pair = border_pair_name,\n    treated = 0,\n    treated_state = treated_fips,\n    dist_to_border = neighbor_dists,\n    dist_km = dist_to_border  # Positive = control side\n  )",
      "confidence": 0.9
    },
    {
      "category": "METHODOLOGY_MISMATCH",
      "severity": "HIGH",
      "file": "03_main_analysis.R",
      "lines": [
        21,
        45
      ],
      "evidence": "The main analysis hard-assumes a column dist_km exists with treated negative and control positive. However, 01_fetch_data.R constructs signed_dist (not dist_km) and uses the opposite sign convention. 06_tables.R later sets dist_km = signed_dist, implying a third convention/workaround. This creates a serious reproducibility/integrity risk: results may depend on which fetch script last overwrote data/qwi_border.rds and how dist_km was constructed.: analysis_sample <- qwi_border %>%\n  filter(in_bandwidth, industry == \"00\") %>%\n  mutate(\n    # dist_km is already computed (negative = treated side, positive = control)\n    dist_km2 = dist_km^2,\n    # Interactions for DiDisc\n    treat_post = treated * post,\n    treat_dist = treated * dist_km,\n    treat_post_dist = treated * post * dist_km\n  )",
      "confidence": 0.9
    },
    {
      "category": "METHODOLOGY_MISMATCH",
      "severity": "MEDIUM",
      "file": "03_main_analysis.R",
      "lines": [
        118,
        160
      ],
      "evidence": "The placebo regressions cluster at border_pair (as the manuscript describes), but the p-value is computed using a t distribution with df = nrow(window_data) - 6, which is inconsistent with clustered inference and especially problematic with ~8 clusters. This can materially misstate placebo significance and the manuscript\u2019s placebo-validation narrative.: placebo_reg <- tryCatch({\n    feols(\n      log_earn_hire ~ treated + pseudo_post + pseudo_treat_post +\n        dist_km + treated:dist_km |\n        border_pair,\n      data = window_data,\n      cluster = ~border_pair\n    )\n  }, error = function(e) NULL)\n...\n      p_value = 2 * pt(-abs(tau_placebo / se_placebo), df = nrow(window_data) - 6)",
      "confidence": 0.8
    },
    {
      "category": "DATA_PROVENANCE_MISSING",
      "severity": "MEDIUM",
      "file": "00_packages.R",
      "lines": [
        33,
        37
      ],
      "evidence": "Reproducibility depends on running inside RStudio (rstudioapi) with an open source file. In non-interactive runs (e.g., CI, command line, replication packages), getSourceEditorContext() can fail, causing wrong working directory and potentially reading/writing different data/qwi_border.rds versions. This can exacerbate the multiple-fetch-script ambiguity and make data provenance hard to verify.: if (!grepl(\"code$\", getwd())) {\n  setwd(dirname(rstudioapi::getSourceEditorContext()$path))\n}",
      "confidence": 0.75
    },
    {
      "category": "SUSPICIOUS_TRANSFORMS",
      "severity": "LOW",
      "file": "01_fetch_data.R",
      "lines": [
        257,
        270
      ],
      "evidence": "Outcome-based filtering drops observations with EarnHirAS missing or nonpositive. QWI suppresses small cells; suppression/missingness may be nonrandom across rural border counties/industries. This is common in administrative data cleaning, but it can change the effective sample in ways correlated with treatment status and distance, potentially biasing estimates if not explicitly assessed (the manuscript discusses suppression; severity reduced).: qwi_clean <- qwi_raw %>%\n  mutate(\n    EarnHirAS = as.numeric(EarnHirAS),\n    ...\n  ) %>%\n  filter(!is.na(EarnHirAS), EarnHirAS > 0) %>%\n  mutate(\n    log_earn_hire = log(EarnHirAS),\n    log_earn = log(EarnS),\n    log_emp = log(Emp + 1),\n    log_hires = log(HirA + 1)\n  )",
      "confidence": 0.7
    },
    {
      "category": "HARD_CODED_RESULTS",
      "severity": "MEDIUM",
      "file": "paper.tex",
      "lines": [
        420,
        520
      ],
      "evidence": "Key regression results are manually embedded as literals in the LaTeX tables rather than being \\input{} from code-generated table files. The repository does include code to generate LaTeX tables (06_tables.R), but the manuscript excerpt shows hard-coded numbers. This creates a provenance gap: readers cannot verify that the published table values correspond to the code output used for the paper.: \\begin{table}[H]\n\\centering\n\\caption{Main DiDisc Estimates: Effect of Marijuana Legalization on New Hire Earnings}\n...\n$\\hat{\\tau}^{DiDisc}$ & $-0.028$ & $-0.031$ & $-0.035$ & $-0.031$ \\\\\n& (0.058) & (0.062) & (0.068) & (0.062) \\\\\n& [0.63] & [0.62] & [0.60] & [0.62] \\\\\n...",
      "confidence": 0.8
    },
    {
      "category": "SELECTIVE_REPORTING",
      "severity": "LOW",
      "file": "01b_fetch_data_fast.R",
      "lines": [
        1,
        20
      ],
      "evidence": "There are many alternative data-fetch pipelines (01b/01c/01d/01e/01f/01h) described as 'proof of concept', 'targeted', 'working', etc., all writing to the same output file (data/qwi_border.rds) in various scripts. This structure can enable untracked specification/data-scope selection (e.g., choosing the fetch version that 'works' or yields cleaner estimates). Not direct evidence of selective reporting, but it increases the risk unless the paper explicitly pins down which pipeline produced the analysis dataset and preserves the exact generated artifact.: # Fast QWI Fetch - Focus on Colorado Border Only (Proof of Concept)\n# Then expand to other borders",
      "confidence": 0.65
    }
  ],
  "file_verdicts": [
    {
      "file": "01b_fetch_data_fast.R",
      "verdict": "CLEAN"
    },
    {
      "file": "04_industry_analysis.R",
      "verdict": "CLEAN"
    },
    {
      "file": "01_fetch_data.R",
      "verdict": "SUSPICIOUS"
    },
    {
      "file": "06_tables.R",
      "verdict": "CLEAN"
    },
    {
      "file": "00_packages.R",
      "verdict": "CLEAN"
    },
    {
      "file": "01c_fetch_minimal.R",
      "verdict": "CLEAN"
    },
    {
      "file": "01f_fetch_targeted.R",
      "verdict": "CLEAN"
    },
    {
      "file": "01h_fetch_with_key.R",
      "verdict": "CLEAN"
    },
    {
      "file": "02_clean_data.R",
      "verdict": "CLEAN"
    },
    {
      "file": "01e_fetch_robust.R",
      "verdict": "SUSPICIOUS"
    },
    {
      "file": "03_main_analysis.R",
      "verdict": "SUSPICIOUS"
    },
    {
      "file": "01d_fetch_bulk.R",
      "verdict": "CLEAN"
    },
    {
      "file": "01g_fetch_bulk_working.R",
      "verdict": "CLEAN"
    },
    {
      "file": "05_figures.R",
      "verdict": "CLEAN"
    }
  ],
  "summary": {
    "verdict": "SUSPICIOUS",
    "counts": {
      "CRITICAL": 0,
      "HIGH": 3,
      "MEDIUM": 3,
      "LOW": 2
    },
    "one_liner": "method mismatch",
    "executive_summary": "The codebase uses inconsistent sign conventions for the signed distance-to-border variable: `01_fetch_data.R` defines treated as positive and control as negative, while `01e_fetch_robust.R` (and the narrative assumptions in `03_main_analysis.R`) use the opposite (treated negative, control positive). In addition, `03_main_analysis.R` hard-assumes a `dist_km` column with the treated-negative/control-positive convention, but `01_fetch_data.R` produces `signed_dist` (not `dist_km`) under the opposite convention, so downstream estimates can be flipped or mis-specified depending on which data-generation path is used.",
    "top_issues": [
      {
        "category": "METHODOLOGY_MISMATCH",
        "severity": "HIGH",
        "short": "This script defines signed distance as + for treated and ...",
        "file": "01_fetch_data.R",
        "lines": [
          132,
          189
        ],
        "github_url": "/apep_0183/code/01_fetch_data.R#L132-L189"
      },
      {
        "category": "METHODOLOGY_MISMATCH",
        "severity": "HIGH",
        "short": "This script encodes distance with the opposite sign conve...",
        "file": "01e_fetch_robust.R",
        "lines": [
          126,
          176
        ],
        "github_url": "/apep_0183/code/01e_fetch_robust.R#L126-L176"
      },
      {
        "category": "METHODOLOGY_MISMATCH",
        "severity": "HIGH",
        "short": "The main analysis hard-assumes a column dist_km exists wi...",
        "file": "03_main_analysis.R",
        "lines": [
          21,
          45
        ],
        "github_url": "/apep_0183/code/03_main_analysis.R#L21-L45"
      }
    ],
    "full_report_url": "/tournament/corpus_scanner/scans/apep_0183_scan.json"
  },
  "error": null
}