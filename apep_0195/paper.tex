\documentclass[12pt]{article}

% UTF-8 encoding and fonts
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{lmodern}

% Page setup
\usepackage[margin=1in]{geometry}
\usepackage{setspace}
\onehalfspacing

% Math and symbols
\usepackage{amsmath,amssymb}

% Graphics
\usepackage{graphicx}
\usepackage{float}

% Tables
\usepackage{booktabs}
\usepackage{array}
\usepackage{multirow}
\usepackage{tabularx}
\usepackage{threeparttable}

% Bibliography
\usepackage{natbib}
\bibliographystyle{aer}

% Hyperlinks
\usepackage{hyperref}
\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    citecolor=blue,
    urlcolor=blue
}

% Captions
\usepackage{caption}
\captionsetup{font=small,labelfont=bf}

% Section formatting
\usepackage{titlesec}
\titleformat{\section}{\large\bfseries}{\thesection.}{0.5em}{}
\titleformat{\subsection}{\normalsize\bfseries}{\thesubsection}{0.5em}{}

% Custom commands
\newcommand{\E}{\mathbb{E}}
\newcommand{\Var}{\text{Var}}
\newcommand{\Cov}{\text{Cov}}

\title{Shining Light on Paychecks: \\ The Effects of Salary Transparency Laws on Wages and the Gender Pay Gap\footnote{This paper is a revision of APEP-0162 (\url{https://github.com/SocialCatalystLab/ape-papers/tree/main/papers/apep_0162}). Key revisions from v6: (1) extended data to CPS ASEC 2025 (income year 2024), adding New York and Hawaii as treated states with post-treatment data (8 treated states, up from 6); (2) added Lee (2009) bounds addressing significant composition shift in high-bargaining occupations; (3) added synthetic DiD (Arkhangelsky et al., 2021) as alternative estimator; (4) corrected abstract to acknowledge aggregate wage effect is statistically insignificant under design-based inference; (5) comprehensive narrative reframing leading with the gender DDD result.}}
\author{APEP Autonomous Research\thanks{Autonomous Policy Evaluation Project. This paper was autonomously generated using Claude Code. Project repository: \url{https://github.com/SocialCatalystLab/auto-policy-evals. Correspondence: scl@econ.uzh.ch}} \and @SocialCatalystLab}
\date{February 2026}

\begin{document}

\maketitle

\begin{abstract}
\noindent
State salary transparency laws---requiring employers to disclose salary ranges in job postings---substantially narrow the gender wage gap without reducing average wages. I evaluate these laws using a staggered difference-in-differences design with Callaway-Sant'Anna heterogeneity-robust estimators, applied to individual-level data from the Current Population Survey Annual Social and Economic Supplement (CPS ASEC 2015--2025, income years 2014--2024, $N = 614{,}625$ unweighted person-years). Eight U.S. states adopted these laws between 2021 and 2024; all eight now have post-treatment data following the addition of CPS ASEC 2025. The central finding is a substantial narrowing of the gender wage gap: triple-difference estimates show that women's wages increase by 4.0--5.6 percentage points relative to men following transparency laws, a result that is robust across all specifications (asymptotic $p < 0.001$) and reinforced by Lee (2009) bounds addressing the significant composition shift in high-bargaining occupations (composition test: $p = 0.017$; Lee bounds: [0.042, 0.050], both positive). The gender DDD is significant under asymptotic inference ($p < 0.001$) across all four specifications, though the Fisher permutation $p$-value of 0.154 reflects the limited number of treated clusters available for design-based inference. The consistency of the asymptotic result across specifications, together with the confirmation from Lee bounds and LOTO analysis, provides suggestive evidence for the finding. In contrast, the aggregate wage effect is small and statistically insignificant under design-based inference (permutation $p = 0.717$; C-S ATT $= -0.0038$, SE $= 0.0064$). HonestDiD sensitivity analysis confirms the aggregate effect is insignificant even under exact parallel trends ($M = 0$). Leave-one-treated-state-out analysis across all eight treated states confirms no single state drives the results. Synthetic DiD applied to the Colorado cohort corroborates the Callaway-Sant'Anna estimates. All estimates are intent-to-treat (ITT). These findings suggest that pay transparency is an effective tool for promoting pay equity with little evidence of aggregate wage costs.
\end{abstract}

\vspace{1em}
\noindent\textbf{JEL Codes:} J31, J71, J38, K31 \\
\noindent\textbf{Keywords:} pay transparency, gender wage gap, wage posting, salary disclosure, difference-in-differences

\newpage

\section{Introduction}

Pay transparency creates a potential trade-off between equity and efficiency. This paper provides causal evidence on the magnitude of this trade-off using the staggered adoption of salary transparency laws across U.S. states. Eight states adopted these laws between 2021 and 2024; I analyze CPS ASEC data covering income years 2014--2024, with all eight treated states now contributing post-treatment variation. The central finding is a substantial narrowing of the gender wage gap: triple-difference estimates show women's wages increase by 4.0--5.6 percentage points relative to men (95\% CI for preferred specification: $[0.024, 0.056]$), a result that is significant under asymptotic inference ($p < 0.001$) across all four specifications, though the Fisher permutation $p$-value of 0.154 reflects the limited number of treated clusters available for design-based inference. The consistency of the asymptotic result across specifications, together with the confirmation from Lee bounds and LOTO analysis, provides evidence for the finding. This pattern is consistent with \citeauthor{cullen2023pay}'s (\citeyear{cullen2023pay}) theoretical prediction that transparency equalizes information asymmetries that disadvantaged women in salary negotiations. In contrast, the effect on average wages is small and statistically insignificant under design-based inference: the Callaway-Sant'Anna ATT is $-0.0038$ (SE $= 0.0064$), with a Fisher randomization $p$-value of 0.717, indicating the effect is not distinguishable from zero. I address inference concerns through two complementary approaches: Fisher randomization inference with 5,000 permutations following \citet{ferman2019inference}, and leave-one-treated-state-out analysis across all eight treated states. HonestDiD sensitivity analysis \citep{rambachan2023more} applied to the gender gap event study confirms the finding is significant under exact parallel trends ($M = 0$). Lee (2009) bounds addressing the significant composition shift in high-bargaining occupations (composition test: $p = 0.017$; Lee bounds: [0.042, 0.050], both positive) confirm the gender DDD result is robust to sample selection.

The policy context offers a clean natural experiment. Colorado became the first state to require salary range disclosure in job postings in 2021. By 2024, seven additional states had adopted similar requirements: Connecticut and Nevada (2022), California, Washington, and Rhode Island (2023), and New York and Hawaii (2024). With the addition of CPS ASEC 2025 (income year 2024), all eight treated states now have post-treatment data: Colorado has four post-treatment years, Connecticut and Nevada three, California, Washington, and Rhode Island two, and New York and Hawaii one each. Three additional states (Illinois, Maryland, Minnesota) enacted transparency laws effective in 2025, providing exclusively pre-treatment observations and functioning as not-yet-treated controls. This staggered adoption creates variation for difference-in-differences analysis. I implement heterogeneity-robust estimators \citep{callaway2021difference, sun2021estimating} that avoid the biases of standard two-way fixed effects with staggered treatment, and complement them with synthetic DiD \citep{arkhangelsky2021synthetic} as an alternative estimator.

The theoretical predictions follow \citet{cullen2023pay}. When salary ranges are publicly posted, employers can credibly commit to the posted range---paying above it would trigger renegotiation demands from existing employees. This commitment effect reduces wages on average. For the gender gap, the prediction is clearer: if women historically faced larger information deficits (smaller networks, different negotiation norms), transparency should benefit women more, narrowing the gap even as overall wages fall.

My findings offer nuanced evidence. First, transparency narrows the gender wage gap: the triple-difference coefficient shows women's wages increase by 4.0--5.6 percentage points relative to men, significant under asymptotic inference across all specifications ($p < 0.001$), though the Fisher permutation $p$-value of 0.154 reflects the limited number of treated clusters. Lee (2009) bounds addressing the significant composition shift in high-bargaining occupations (composition test: $p = 0.017$; Lee bounds: [0.042, 0.050], both positive) confirm this result is robust to sample selection. Second, the effect on average wages is small and statistically insignificant: the heterogeneity-robust Callaway-Sant'Anna estimator yields a point estimate of $-0.4\%$, but design-based inference (permutation $p = 0.717$) indicates this is not distinguishable from zero. TWFE specifications with individual-level controls find no significant impact. Third, subsample analyses show directionally larger negative effects in high-bargaining occupations (management, finance, technology) where individual negotiation matters, while standardized-wage occupations show near-zero effects. This directional pattern is consistent with the information-equalization channel, though the heterogeneity estimates are imprecise.

\textbf{Contribution.} This paper makes three contributions to the literature on pay transparency and the gender wage gap. First, I provide the first causal estimates of \emph{job-posting} salary transparency---a stronger intervention than the ``right-to-ask'' laws studied by \citet{cullen2023pay} or internal disclosure policies studied by \citet{baker2023pay}. Job-posting requirements affect all applicants ex ante, before any employment relationship begins, and constrain employers' ability to bargain outside posted ranges. Second, I quantify the equity-efficiency trade-off directly: transparency narrows the gender gap by 4.0--5.6 percentage points (representing roughly half the residual gender gap after controlling for occupation and experience) while the aggregate wage effect is statistically indistinguishable from zero under design-based inference. This suggests the trade-off is substantially more favorable than theoretical models predict. Third, the occupational heterogeneity results---directionally larger effects in high-bargaining occupations---provide suggestive evidence for the \citet{cullen2023pay} bargaining mechanism, extending their theoretical predictions to a stronger policy setting.

The paper proceeds as follows. Section 2 provides institutional background. Section 3 reviews related literature. Section 4 describes the data. Section 5 presents the empirical strategy. Section 6 reports results. Section 7 discusses implications. Section 8 concludes.

\section{Institutional Background}

\subsection{Policy Setting}

Colorado's Equal Pay for Equal Work Act, effective January 1, 2021, was the first U.S. law requiring employers to disclose salary ranges in job postings. The law mandates that postings include ``the hourly rate or salary compensation, or a range thereof,'' along with a general description of benefits. Seven additional states followed, with laws taking effect between 2021 and 2024. With the addition of CPS ASEC 2025, all eight treated states now have post-treatment data in my sample (income years 2014--2024): Colorado (4 post-treatment years), Connecticut and Nevada (3), California, Washington, and Rhode Island (2), and New York and Hawaii (1). Three additional states---Illinois, Maryland, and Minnesota---enacted transparency laws effective in 2025, outside the analysis window; these states contribute pre-treatment observations only and function as not-yet-treated controls. Table \ref{tab:timing} summarizes the adoption timeline; Figure \ref{fig:map} shows the geographic distribution.

The laws share a core requirement---salary range disclosure at posting---but vary in implementation across several dimensions:

\textbf{Employer Size Thresholds.} Coverage varies substantially. Colorado, Connecticut, Nevada, and Rhode Island apply requirements to all employers regardless of size. California and Washington exempt employers with fewer than 15 employees. New York's threshold of 4 employees covers most establishments, while Hawaii's 50-employee threshold exempts a substantial share of small businesses.

\textbf{Disclosure Specificity.} Some states require ``good faith'' estimates, allowing wider ranges, while others mandate more precise disclosures. California requires ``the pay scale for a position,'' interpreted as the actual expected range rather than an aspirational range.

\textbf{Enforcement.} Mechanisms range from civil penalties to private rights of action. Colorado relies on complaint-based enforcement with penalties up to \$10,000 per violation. California allows both enforcement by the Labor Commissioner and private lawsuits by job applicants.

\textbf{Timing.} Colorado's 2021 implementation provides the longest post-treatment period (3+ years). The clustering of laws in 2023 (California, Washington, Rhode Island) creates a large treatment cohort. Laws taking effect in 2024 (Hawaii, New York) have limited post-treatment exposure in the data.

The policy rationale centers on pay equity. Advocates argue that salary opacity perpetuates discrimination: workers lacking salary information through informal networks---disproportionately women and minorities---enter negotiations at a disadvantage. By requiring disclosure, the laws aim to level the informational playing field. Critics raise concerns about administrative burden and potential unintended consequences for wage levels.

\begin{figure}[H]
\centering
\includegraphics[width=0.9\textwidth]{figures/fig1_policy_map.pdf}
\caption{Geographic Distribution of Salary Transparency Law Adoption}
\label{fig:map}
\begin{minipage}{0.9\textwidth}
\footnotesize
\textit{Notes:} Map shows the timing of salary transparency law \emph{effective dates} across U.S. states. Darker shading indicates earlier adoption. Gray states have not adopted transparency requirements as of 2024. All eight treated states now have post-treatment data in the extended sample (income years through 2024). Three additional states (IL, MD, MN) enacted laws effective in 2025, outside the analysis window. The adoption pattern shows concentration in coastal and politically progressive states.
\end{minipage}
\end{figure}

\subsection{Mechanisms}

Following \citet{cullen2023pay}, transparency affects wages through several channels. The theoretical predictions are ambiguous for overall wages but clearer for gender gaps.

\textbf{Employer commitment.} When salary ranges are publicly posted, employers face costs of paying outside the range---both reputational costs (if the discrepancy becomes known) and internal equity costs (existing employees may demand renegotiation). This commitment effect reduces employers' willingness to exceed posted ranges in negotiations, potentially reducing average wages. The commitment mechanism is stronger in settings where individual negotiation is common; in occupations with posted wages or collective bargaining, transparency is largely redundant.

\textbf{Information provision.} Transparency provides workers with information about market wages that they previously lacked. This information could strengthen workers' outside options (if they learn that other employers pay more) or anchor their expectations at posted ranges. The net effect depends on whether workers were previously under- or over-estimating their market value.

\textbf{Bargaining to posting.} Transparency may shift firms from negotiated to posted wages. Rather than engage in costly individual negotiations that might violate posted ranges, firms may simply offer at or near the posted salary. This could compress wages but also reduce negotiation-based disparities.

\textbf{Sorting.} Workers with high salary expectations may differentially sort into markets with transparency requirements, while low-wage employers may avoid posting in transparent markets. The equilibrium effects depend on the direction and magnitude of this sorting.

\textbf{Gender-specific effects.} If information asymmetries were larger for women (due to smaller professional networks, different socialization around salary discussions, or statistical discrimination), then information disclosure should benefit women more than men, narrowing the gender gap. This could occur even if overall wages decline.

The \citet{cullen2023pay} framework predicts that transparency should reduce average wages through the commitment channel, with larger effects in settings where individual bargaining is important. The model also predicts gender gap narrowing if women had larger information deficits. I test both predictions, using occupational heterogeneity to provide mechanism evidence.

\section{Related Literature}

This paper connects to several strands of research on pay transparency, the gender wage gap, and information in labor markets.

\subsection{Pay Transparency Research}

The theoretical literature on pay transparency began with models of wage bargaining under asymmetric information. \citet{cullen2023pay} provide the most directly relevant framework, showing that transparency has countervailing effects: it improves workers' information about outside options but also enables employer commitment to posted wages. Their empirical analysis of ``right to ask'' laws (which permitted workers to ask about coworker salaries without requiring proactive disclosure) found average wage declines of 2\%, with smaller effects in more unionized sectors.

Empirical work on firm-level transparency has yielded mixed results. \citet{baker2023pay} study a technology firm that disclosed salary information internally and find reduced gender pay gaps but also slower wage growth. \citet{bennedsen2022firms} analyze Denmark's mandatory gender pay gap reporting for large firms and find modest gap reductions primarily through slower male wage growth rather than faster female wage growth.

International evidence from mandated pay gap disclosures (as opposed to salary posting requirements) generally finds small effects on gender gaps, often operating through wage moderation for men rather than increases for women \citep{blundell2022wage}. Complementing this work, \citet{sinha2024salary} studies salary history bans---which prevent employers from asking about prior pay---and finds wage increases for affected workers, particularly women, with effects on the gender gap. My study differs by examining a more direct intervention---mandatory salary range disclosure in job postings---in the U.S. context.

\subsection{The Gender Wage Gap}

The gender wage gap has been extensively studied since \citet{oaxaca1973male} and \citet{blinder1973wage}. Recent work emphasizes that the raw gap (around 18-20\% in the U.S.) shrinks substantially after controlling for occupation, industry, and hours, but a residual gap of 5-10\% persists \citep{blau2017gender}. Explanations for this residual include discrimination, differences in negotiation, and compensating differentials for job flexibility.

\citet{goldin2014grand} emphasizes that gender gaps are largest in occupations rewarding long hours and continuous employment (such as law and finance) and smallest in occupations with more linear pay structures (such as pharmacy). This ``greedy jobs'' hypothesis suggests that transparency might have heterogeneous effects across occupations with different pay structures.

The negotiation channel has received particular attention. \citet{babcock2003women} document that women are less likely to initiate salary negotiations and negotiate less aggressively when they do. \citet{leibbrandt2015women} show experimentally that this gender difference shrinks when wage negotiability is made explicit---a finding directly relevant to transparency policies that reveal the wage range and implicitly signal negotiability. \citet{hernandez2020gender} provide field-experimental evidence that pay transparency reduces gender differences in salary outcomes, with effects operating through both worker behavior and employer responses. \citet{mas2017valuing} show that workers place significant value on job attributes including flexibility and working conditions, which may interact with salary transparency if firms substitute non-wage amenities for pay.

\subsection{Information in Labor Markets}

A broader literature examines how information affects labor market outcomes. \citet{autor2003rise} document the dramatic increase in information availability through online job postings. \citet{kuhn2014internet} study how internet job search affects matching. \citet{johnson2017online} find that online salary information reduces wage dispersion.

Search and matching models predict that better information should improve match quality and reduce search frictions \citep{mortensen1986job, mortensen2003wage}. \citet{lise2020multidimensional} show that multidimensional skill sorting generates significant wage dispersion even among observationally similar workers; transparency may compress this dispersion by anchoring wages to posted ranges. \citet{card2018firms} document substantial firm-level variation in pay for similar workers, providing scope for transparency to affect the distribution of rents between firms and workers. However, if information is asymmetric (e.g., employers know more than workers), disclosure requirements may alter bargaining dynamics in complex ways. \citet{castilla2015accountability} provides evidence that organizational transparency and accountability in pay decisions can reduce demographic pay gaps within firms. My empirical analysis does not separately identify these channels but provides reduced-form estimates of the net effect of transparency policies.

\subsection{Contribution to the Literature}

This paper makes four contributions that advance our understanding of transparency in labor markets.

\textbf{First, I study a stronger intervention.} Prior empirical work has focused on weaker transparency policies: \citet{cullen2023pay} study ``right-to-ask'' laws that allow workers to inquire about coworker salaries but do not require proactive disclosure. \citet{baker2023pay} study voluntary internal disclosure within a single firm. \citet{bennedsen2022firms} study gender pay gap reporting requirements, which reveal aggregate statistics rather than job-specific ranges. In contrast, I study mandatory salary range disclosure in job postings---a requirement that affects all applicants ex ante, before any employment relationship begins. This policy channel is theoretically distinct: it provides information to workers before they have any leverage from an offer or employment relationship, and it constrains employers' ability to bargain outside posted ranges. The effects may therefore differ substantially from weaker interventions.

\textbf{Second, I quantify the equity-efficiency trade-off.} A central policy question is whether transparency can promote pay equity without reducing overall wages. My estimates provide a direct answer: the aggregate wage effect is small and statistically insignificant under design-based inference (C-S ATT $\approx -0.4\%$, permutation $p = 0.717$), while the gender gap narrows substantially (4.0--5.6 percentage points, asymptotic $p < 0.001$). This suggests the equity-efficiency trade-off may be substantially more favorable than theoretical models predict. Policymakers motivated by equity should find transparency an effective tool with no detectable aggregate wage costs.

\textbf{Third, I provide suggestive mechanism evidence.} The occupational heterogeneity results---directionally larger negative effects in high-bargaining occupations (management, finance, technology) than in low-bargaining occupations (service, production)---are consistent with the \citet{cullen2023pay} prediction that transparency operates through the commitment channel. While the interaction estimates are imprecise given the limited number of treated clusters, the subsample pattern ($-0.012$ for high-bargaining vs. $+0.003$ for low-bargaining) aligns with the theoretical prediction that effects concentrate in labor markets where individual negotiation matters.

\textbf{Fourth, the research design offers identification advantages.} The staggered adoption across U.S. states creates variation for credible causal inference using modern heterogeneity-robust difference-in-differences methods \citep{callaway2021difference, sun2021estimating}, complemented by synthetic DiD \citep{arkhangelsky2021synthetic}. Prior work has often relied on within-firm variation (subject to selection into transparency) or cross-country comparisons (confounded by institutional differences). The state-level variation allows for clean identification while the sample size (8 treated states with post-treatment data, 40 never-treated control states, 614,625 unweighted person-year observations) provides statistical power for heterogeneity analysis.

\section{Data}

\subsection{Data Sources}

My primary data source is the Current Population Survey Annual Social and Economic Supplement (CPS ASEC), accessed through IPUMS \citep{flood2023ipums}. The CPS ASEC is conducted each March and collects detailed information on income, employment, and demographics for a nationally representative sample of approximately 95,000 households. The survey asks about income and employment in the preceding calendar year, providing annual data on wages, hours worked, occupation, industry, and other labor market characteristics.

I use CPS ASEC surveys from 2015 through 2025, corresponding to income years 2014 through 2024. This provides seven years of pre-treatment data for the earliest-treated state (Colorado, 2021) and captures the full rollout of transparency laws through income year 2024. The addition of CPS ASEC 2025 is a key improvement over prior versions: all eight treated states now have post-treatment data. Colorado has four post-treatment years, Connecticut and Nevada three, California, Washington, and Rhode Island two, and New York and Hawaii one each. Three additional states (Illinois, Maryland, Minnesota) enacted laws effective in 2025 with first treated income years of 2025 or later; these states contribute exclusively pre-treatment observations and function as not-yet-treated controls in the estimation. The sample period includes 614,625 working-age adults (unweighted person-years) across all years.

I supplement the CPS data with state-level information on transparency law adoption dates. Treatment timing is compiled from official state legislative records: Colorado's Equal Pay for Equal Work Act (SB19-085), Connecticut's Public Act 21-30 (HB 6380), Nevada's SB 293, Rhode Island's H 5171, California's Pay Transparency Act (SB 1162), Washington's SB 5761, New York's Labor Law \S194-b, and Hawaii's SB 1057. Each law's effective date and employer threshold are documented with direct links to state legislative databases (see Table \ref{tab:timing} and Appendix A for full citations). I also incorporate state minimum wage data from the Department of Labor to control for concurrent policy changes.

\subsection{Sample Construction}

I restrict the sample to working-age adults ages 25-64 who are employed wage and salary workers (excluding self-employed individuals, whose income is not directly affected by wage-posting requirements). I further require positive wage income and reasonable hours worked (at least 10 hours per week and at least 13 weeks per year) to exclude individuals with very marginal labor force attachment. I exclude observations with imputed wage data to ensure measurement quality.

After applying these restrictions, the final sample includes 614,625 unweighted person-year observations across 51 states (including DC) and 11 years (income years 2014--2024). Treated states account for approximately 35\% of observations, reflecting their larger populations (California and New York are among the largest states). All regression tables report unweighted observation counts unless otherwise noted. Regressions are estimated with CPS ASEC survey weights (ASECWT) unless otherwise stated.

\subsection{Variable Definitions}

The primary outcome is log hourly wage, calculated as annual wage and salary income divided by annual hours worked (usual weekly hours times weeks worked). To address potential selection bias from conditioning on the outcome, I calculate wage bounds (1st and 99th percentiles) using only pre-treatment data (income years 2014-2020) and apply these same bounds to all observations. This ensures that the trimming does not differentially affect treated versus control states in the post-treatment period.

Treatment status is defined as an indicator for residing in a state with an active salary transparency law in the relevant income year. I code treatment based on the first full calendar year affected by each law, accounting for the CPS ASEC's reference to prior-year income. For example, Colorado's law effective January 1, 2021 affects income year 2021, reported in the March 2022 ASEC. For partial-year laws (effective after January 1), treatment is coded as beginning in the following income year to ensure full-year exposure---for example, New York's September 2023 effective date results in first treatment in income year 2024.

Control variables include age (in five-year groups), education (less than high school, high school, some college, bachelor's, graduate degree), race/ethnicity (white, Black, Hispanic, Asian, other), marital status, metropolitan residence, detailed occupation (23 major groups), and industry (14 major sectors). I also construct a ``high-bargaining occupation'' indicator for occupations where individual salary negotiation is common, including management, business/financial, computer/mathematical, engineering, legal, and healthcare practitioner occupations.

\subsection{Summary Statistics}

Table \ref{tab:balance} presents summary statistics for the analysis sample, separately for treated and control states in the pre-treatment period (2015-2020). Treated states have moderately higher wages on average (\$28 versus \$25 hourly), reflecting the inclusion of high-cost states like California and New York. Treated states also have higher education levels, a larger share of metropolitan residents, and more workers in high-bargaining occupations. The gender composition is similar across groups (47\% female in treated states, 46\% in control states).

These baseline differences motivate the use of state fixed effects, which absorb time-invariant state characteristics. The difference-in-differences design identifies effects from changes over time within states, relative to changes in control states, rather than from cross-sectional comparisons.

\section{Empirical Strategy}

\subsection{Identification}

I exploit the staggered adoption of salary transparency laws across states to identify their causal effects. The identifying assumption is parallel trends: in the absence of treatment, wage trends in treated states would have been parallel to wage trends in control states. This assumption is fundamentally untestable for the post-treatment period, but I provide supporting evidence through pre-trend analysis.

Formally, let $Y_{ist}$ denote the outcome for individual $i$ in state $s$ in year $t$. Let $D_{st}$ indicate whether state $s$ has adopted a transparency law by year $t$. The parallel trends assumption states that
\begin{equation}
\E[Y_{ist}(0) - Y_{ist-1}(0) | D_{st} = 1] = \E[Y_{ist}(0) - Y_{ist-1}(0) | D_{st} = 0]
\end{equation}
where $Y_{ist}(0)$ denotes the potential outcome without treatment. Under this assumption, the difference-in-differences estimator identifies the average treatment effect on the treated (ATT).

\subsection{Estimation}

With staggered adoption, standard two-way fixed effects (TWFE) estimation can produce biased estimates due to ``forbidden comparisons'' that use already-treated units as controls for later-treated units \citep{goodman2021difference, dechaisemartin2020twoway}. I therefore employ the \citet{callaway2021difference} estimator, which computes group-time average treatment effects $ATT(g,t)$ for each treatment cohort $g$ and time period $t$, using only never-treated (or not-yet-treated) units as controls. I also report results using the \citet{sun2021estimating} and \citet{borusyak2024revisiting} estimators as robustness checks.

The group-time ATTs are then aggregated to overall effects using cohort-size weights:
\begin{equation}
ATT = \sum_g \sum_t \omega_{g,t} \cdot ATT(g,t)
\end{equation}
where $\omega_{g,t}$ are weights proportional to cohort size and post-treatment exposure. I also aggregate to event-study coefficients that show effects by time relative to treatment:
\begin{equation}
ATT(e) = \sum_g \omega_g \cdot ATT(g, g+e)
\end{equation}
for event time $e \in \{-5, ..., 4\}$.

For inference, I cluster standard errors at the state level to account for serial correlation within states and the state-level assignment of treatment \citep{abadie2023should}. With 51 clusters (including DC), cluster-robust standard errors are generally appropriate \citep{cameron2008bootstrap}. Eight states adopted transparency laws during the study period, and all eight now have post-treatment data with the extended sample (income years through 2024). Three additional states (Illinois, Maryland, Minnesota) enacted laws effective in 2025, contributing only pre-treatment observations. While eight treated clusters is a substantial improvement over the six available in earlier versions, the moderate number of treated clusters still raises concerns about the reliability of asymptotic cluster-robust inference \citep{conley2011inference}. I address this concern through three complementary approaches.

First, I report wild cluster bootstrap $p$-values and confidence intervals using the Webb 6-point distribution \citep{mackinnon2017wild, webb2023reworking}. To avoid computational issues with individual-level weighted data, I collapse the data to state-year-gender cells---the level at which the DDD interaction is identified---and bootstrap the collapsed regression. Second, following \citet{ferman2019inference} and in the spirit of design-based inference for DiD settings \citep{athey2022design}, I conduct Fisher randomization inference: I randomly assign eight states as ``treated'' with the same timing structure and re-estimate the key coefficients 5,000 times, computing exact permutation $p$-values from the resulting distribution. This approach is valid regardless of the number of treated clusters. Third, I perform leave-one-treated-state-out (LOTO) analysis to verify that no single state drives the results.

\textbf{Inferential hierarchy.} The primary estimator is Callaway-Sant'Anna for both the aggregate ATT and gender DDD, with Fisher randomization inference as the primary design-based test given the small number of treated clusters (8 states). Asymptotic cluster-robust standard errors serve as supplementary inference. All robustness checks (Sun-Abraham, SDID, LOTO, HonestDiD, Lee bounds) are reported to assess sensitivity.

\subsection{Triple-Difference for Gender Effects}

The gender DDD coefficient is the primary policy-relevant estimand, as it captures the differential effect of transparency laws on the gender wage gap while absorbing any aggregate wage effects that may confound the simple ATT.

To estimate differential effects by gender, I employ a triple-difference (DDD) specification:
\begin{equation}
Y_{ist} = \beta_1 D_{st} + \beta_2 D_{st} \times Female_i + \gamma Female_i + \alpha_s + \delta_t + X_{ist}'\theta + \varepsilon_{ist}
\end{equation}
where $Female_i$ indicates gender, $\alpha_s$ are state fixed effects, $\delta_t$ are year fixed effects, and $X_{ist}$ are individual controls. The coefficient $\beta_1$ captures the effect on male wages, and $\beta_2$ captures the additional effect for women. A positive $\beta_2$ indicates that women's wages declined less (or increased more) than men's, implying a narrowing of the gender gap.

I also estimate specifications with state-by-year fixed effects ($\alpha_{st}$), which absorb all state-time variation and identify $\beta_2$ purely from within-state-year gender differences in wage changes. In this specification, the main treatment effect $\beta_1$ is not separately identified because it is collinear with the state$\times$year fixed effects; what is identified is the \emph{differential} effect $\beta_2$ for women relative to men within the same state-year cell. This estimand directly measures the change in the within-state gender gap attributable to transparency laws, net of any aggregate state-level shocks.

\subsection{Threats to Validity}

Several potential threats to identification warrant discussion.

\textbf{Selection into treatment.} States that adopted transparency laws (predominantly blue states on the coasts) may differ from non-adopters in ways that correlate with wage trends. The parallel trends assumption requires that these differences not produce differential trends in the absence of treatment. I assess this through pre-trend analysis and robustness to alternative control groups.

\textbf{Concurrent policies.} Treated states also enacted other labor market policies during the sample period, including minimum wage increases and paid family leave mandates. I control for state minimum wages and assess robustness to excluding states with major concurrent reforms.

\textbf{Spillovers.} Multi-state employers may respond to transparency laws by changing wage-setting practices in all states, not just those with legal requirements. Remote work further blurs geographic boundaries. Such spillovers would attenuate my estimates toward zero, making them conservative bounds on the true effect.

\textbf{Composition changes.} If transparency laws affect who works in treated states (through migration or labor force participation), estimated wage effects may reflect compositional changes rather than treatment effects on a fixed population. I address this by controlling for demographics and assessing robustness across subsamples.

\section{Results}

\subsection{Pre-Trends and Parallel Trends Validation}

Figure \ref{fig:trends} plots average log hourly wages over time for treated and control states. Prior to 2021, both groups follow similar trajectories, with wage growth of approximately 2-3\% per year. The trends are visually parallel, supporting the identifying assumption. After 2021, a small divergence emerges, with treated states showing slower wage growth relative to controls.

\begin{figure}[H]
\centering
\includegraphics[width=0.85\textwidth]{figures/fig2_wage_trends.pdf}
\caption{Wage Trends: Treated vs. Control States}
\label{fig:trends}
\begin{minipage}{0.85\textwidth}
\footnotesize
\textit{Notes:} Average log hourly wages for treated states (solid) and never-treated control states (dashed) over time. Treated states are the eight states that adopted salary transparency laws (first treated income years 2021--2024); all eight treated states have post-treatment data in the sample (income years through 2024). The shaded region indicates the treatment period. Prior to 2021, both groups follow similar trajectories. Data covers income years 2014--2024; the 2024 observation is omitted from the figure for visual clarity as it includes the newly-added CPS ASEC 2025 wave. See Table~\ref{tab:timing} for the full sample period.
\end{minipage}
\end{figure}

Figure \ref{fig:event_study} presents event-study coefficients from the Callaway-Sant'Anna estimator. The reference period is $t-1$, normalized to zero. Most pre-treatment coefficients (event times $-5$ through $-1$) are small and statistically insignificant, but two deviate: the $t-3$ coefficient is $+0.015$ (SE $= 0.015$) and the $t-2$ coefficient is $-0.013$ (SE $= 0.006$, significant at the 10\% level). These pre-trend fluctuations, while warranting caution, do not follow a monotone pattern that would suggest differential trends---rather, they oscillate around zero, consistent with sampling variation in a small number of treated clusters.\footnote{A joint Wald test of all five pre-treatment coefficients equaling zero yields $\chi^2(5) = 10.2$, $p = 0.069$, marginal at the 10\% level. This reinforces the importance of the HonestDiD sensitivity analysis, which directly incorporates pre-treatment deviations into the confidence intervals.} The formal HonestDiD sensitivity analysis (Section 6.5) directly accounts for these pre-treatment deviations. Post-treatment coefficients show a declining pattern, reaching approximately $-0.021$ log points by $t+2$.

\begin{figure}[H]
\centering
\includegraphics[width=0.85\textwidth]{figures/fig4_event_study_main.pdf}
\caption{Event Study: Effect of Transparency Laws on Log Wages}
\label{fig:event_study}
\begin{minipage}{0.85\textwidth}
\footnotesize
\textit{Notes:} Event-study coefficients and 95\% confidence intervals from the Callaway-Sant'Anna estimator. Event time ranges from $t-5$ to $t+3$. The reference period is event time $-1$ (coefficient normalized to zero). Pre-treatment coefficients test the parallel trends assumption; the $t-2$ coefficient is individually significant at the 10\% level (see Table \ref{tab:event_study} for exact values), but the pre-treatment coefficients do not follow a monotone trend. Post-treatment coefficients show the dynamic treatment effect. The $t+3$ coefficient is now estimable with the extended data (income year 2024), but is identified solely from the Colorado cohort and should be interpreted with caution.
\end{minipage}
\end{figure}

Table \ref{tab:event_study} reports the event-study coefficients with standard errors. Most pre-treatment coefficients are statistically insignificant, though the $t-4$ coefficient (0.023, SE $= 0.015$) is positive though not individually significant, warranting caution about perfect parallel trends. The HonestDiD sensitivity analysis (Section 6.5) formally addresses this concern. The post-treatment coefficients are mixed: the $t+2$ coefficient of $-0.021$ (SE $= 0.009$) is negative and significant, while the $t+3$ coefficient of $+0.021$ (SE $= 0.006$) is positive and significant. However, the $t+3$ coefficient is identified solely from the Colorado cohort (the only state with four post-treatment years) and should therefore be interpreted with caution, as it reflects the experience of a single treated state rather than a cross-cohort average.

\textbf{Gender-stratified pre-trends.} Figure \ref{fig:gender_es} presents separate event-study estimates for men and women. Both genders show comparable pre-treatment trends, with coefficients that oscillate around zero and do not exhibit systematic patterns. Post-treatment, the male and female event-study paths diverge: female wages increase relative to the pre-treatment trend while male wages decline, with the gap emerging by event time $t = 0$ and widening through $t+2$. This convergence pattern directly visualizes the gender gap narrowing identified in the DDD specification (Section 6.4) and supports the interpretation that transparency benefits women more than men through the information-equalization channel.

\subsection{Main Results}

Table \ref{tab:main} presents the main TWFE results. Column (1) uses state-year aggregates: the estimated coefficient on Treated $\times$ Post is 0.005 (SE = 0.011), statistically insignificant. Columns (2)--(4) use individual-level data with progressively richer controls. The heterogeneity-robust Callaway-Sant'Anna estimator, reported in the robustness table (Table \ref{tab:robustness}), yields an ATT of $-0.0038$ (SE $= 0.0064$), statistically insignificant under design-based inference (permutation $p = 0.717$). The difference between the C-S and TWFE estimates reflects the heterogeneity bias that arises in standard TWFE with staggered treatment \citep{callaway2021difference}.

\begin{table}[H]
\centering
\caption{Effect of Salary Transparency Laws on Log Wages}
\label{tab:main}
\begin{threeparttable}
\begin{tabular}{lcccc}
\toprule
& (1) & (2) & (3) & (4) \\
& State-Year & Individual & + Occ/Ind FE & + Demographics \\
\midrule
Treated $\times$ Post & 0.005 & 0.014* & 0.005 & 0.008 \\
& (0.011) & (0.008) & (0.006) & (0.006) \\
\midrule
State FE & Yes & Yes & Yes & Yes \\
Year FE & Yes & Yes & Yes & Yes \\
Occupation FE & No & No & Yes & Yes \\
Industry FE & No & No & Yes & Yes \\
Demographics & No & No & No & Yes \\
\midrule
Observations & 561 & 614,625 & 614,625 & 614,625 \\
R-squared & 0.972 & 0.058 & 0.299 & 0.382 \\
\bottomrule
\end{tabular}
\begin{tablenotes}
\small
\item \textit{Notes:} Two-way fixed effects (TWFE) estimates. Standard errors clustered at state level (51 clusters: 8 treated with post-treatment data; 3 not-yet-treated; 40 never-treated controls) in parentheses. Column (1) uses state-year aggregates (51 states $\times$ 11 years = 561 obs); the high $R^2$ reflects state and year fixed effects absorbing most cross-sectional and time-series variation in this small panel---this is expected and does not indicate overfitting. Columns (2)--(4) use individual-level CPS ASEC data with survey weights (ASECWT); observation counts are unweighted person-years ($N = 614{,}625$). Demographics include age, education, race, and marital status. The heterogeneity-robust Callaway-Sant'Anna ATT ($-0.0038$, SE $= 0.0064$) is reported in Table~\ref{tab:robustness}; this aggregate effect is statistically insignificant under design-based inference (permutation $p = 0.717$). * p$<$0.10, ** p$<$0.05, *** p$<$0.01.
\end{tablenotes}
\end{threeparttable}
\end{table}

Columns (2)--(4) present individual-level TWFE estimates with progressively richer controls. Column (2) includes only state and year fixed effects (coefficient: 0.014, SE = 0.008); Column (3) adds occupation and industry fixed effects (0.005, SE = 0.006); Column (4) adds demographic controls (0.008, SE = 0.006). None of the TWFE specifications are statistically significant at the 5\% level, with point estimates close to zero and confidence intervals straddling it.

The TWFE estimates are near zero and positive, while the heterogeneity-robust C-S estimator yields a small negative point estimate of $-0.4\%$. However, this aggregate effect is statistically insignificant under design-based inference: Fisher randomization inference yields $p = 0.717$ (Section 6.7), substantially larger than the asymptotic $p$-value of 0.556. The key takeaway is that the aggregate wage effect---whether measured by TWFE or C-S---is not reliably distinguishable from zero.

\subsection{Cohort-Specific Effects}

To ensure that the aggregate ATT is not driven by a single large cohort (e.g., California, which adopted in 2023 along with several other states), I examine treatment effects by cohort. Table \ref{tab:cohort} presents Callaway-Sant'Anna ATT estimates for each treatment cohort. Colorado (2021), the earliest adopter, shows an effect of $-0.007$ (SE $= 0.005$) with four post-treatment years (extended from three in the prior version). The 2022 cohort (Connecticut, Nevada) shows a larger effect of $-0.015$ (SE $= 0.008$) with three post-treatment years. The 2023 cohort (California, Washington, Rhode Island) shows an imprecisely estimated effect of $-0.008$ (SE $= 0.013$) with two post-treatment years. The 2024 cohort (New York, Hawaii), newly contributing to the analysis with one post-treatment year, provides its first post-treatment estimates.

All four treated cohorts show negative point estimates, though none is individually statistically significant at conventional levels. The Callaway-Sant'Anna simple aggregate, which weights by group-time cells, yields the overall ATT reported in Table~\ref{tab:robustness}. The inclusion of New York and Hawaii strengthens the design by increasing the number of treated clusters from six to eight, improving the reliability of cluster-robust inference and bootstrap procedures.

\subsection{Gender Gap Results}

Table \ref{tab:gender} presents the triple-difference results for gender. Note that the coefficient on ``Treated $\times$ Post'' in this specification represents the effect on men only (since Female = 0 for men), which differs from the average effect in Table \ref{tab:main} that pools both genders. Column (1) shows the basic DDD specification: the effect on men's wages (Treated $\times$ Post) is $-0.007$ (SE $= 0.008$), while the differential effect for women (Treated $\times$ Post $\times$ Female) is $+0.049$ (SE $= 0.008$), statistically significant at the 1\% level. The large positive coefficient on the interaction indicates that women's wages increased substantially relative to men's, narrowing the gender gap by approximately 5 percentage points.

\begin{table}[H]
\centering
\caption{Triple-Difference: Effect on Gender Wage Gap}
\label{tab:gender}
\begin{threeparttable}
\begin{tabular}{lcccc}
\toprule
& (1) & (2) & (3) & (4) \\
& Basic & + Occ FE & + Controls & State$\times$Year FE \\
\midrule
Treated $\times$ Post & $-0.007$ & $-0.018$** & $-0.010$* &  \\
& (0.008) & (0.007) & (0.006) & \\
Treated $\times$ Post $\times$ Female & 0.049*** & 0.056*** & 0.040*** & 0.043*** \\
& (0.008) & (0.008) & (0.008) & (0.008) \\
\midrule
State \& Year FE & Yes & Yes & Yes & No \\
State $\times$ Year FE & No & No & No & Yes \\
Occupation FE & No & Yes & Yes & Yes \\
Demographics & No & No & Yes & Yes \\
\midrule
Observations & 614,625 & 614,625 & 614,625 & 614,625 \\
\bottomrule
\end{tabular}
\begin{tablenotes}
\small
\item \textit{Notes:} Standard errors clustered at state level. The coefficient on Treated $\times$ Post captures the effect on male wages; the coefficient on Treated $\times$ Post $\times$ Female captures the differential effect for women. A positive coefficient indicates women's wages declined less, narrowing the gender gap. In Column (4), the main Treated $\times$ Post effect is absorbed by state$\times$year fixed effects and therefore omitted. * p$<$0.10, ** p$<$0.05, *** p$<$0.01.
\end{tablenotes}
\end{threeparttable}
\end{table}

The total effect on women is the sum of these coefficients: $-0.007 + 0.049 = +0.042$, indicating that while male wages decline slightly, female wages actually increase following transparency laws. This pattern is consistent with the hypothesis that transparency benefits women by equalizing information asymmetries in wage bargaining.

Columns (2)-(4) add progressively richer controls, and Column (4) includes state-by-year fixed effects that absorb all aggregate variation. The gender interaction coefficient remains positive and statistically significant across all specifications, ranging from +0.040 to +0.056. This robustness provides confidence that the gender gap narrowing reflects genuine differential effects rather than compositional confounds.

\textbf{HonestDiD sensitivity for gender gap.} To assess whether the gender gap result is robust to potential violations of parallel trends, I apply the \citet{rambachan2023more} sensitivity analysis to the gender gap event study (female ATT minus male ATT at each event time). Table \ref{tab:honestdid_gender} and Figure \ref{fig:honestdid_gender} present the results. Under exact parallel trends ($M = 0$), the 95\% confidence interval for the post-treatment gender gap effect is [0.043, 0.100], firmly excluding zero. At higher values of $M$, the bounds widen considerably due to the relatively noisy gender-disaggregated event-study estimates. The $M = 0$ result is consistent with the DDD finding: the gender gap narrowing is significant when parallel trends hold, as supported by the pre-treatment balance in Figure \ref{fig:gender_es}. The gender DDD is significant under asymptotic inference ($p < 0.001$) across all four specifications, though the Fisher permutation $p$-value of 0.154 reflects the limited number of treated clusters available for design-based inference. The consistency of the asymptotic result across specifications, together with the confirmation from Lee bounds and LOTO analysis, provides evidence for the finding.

\subsection{Heterogeneity by Bargaining Intensity}

Table \ref{tab:bargaining} explores heterogeneity by occupation type. Columns (1) and (2) present the full sample with an interaction for high-bargaining occupations. The interaction coefficient is positive but statistically insignificant in both specifications (0.024, SE = 0.020 and 0.011, SE = 0.014), suggesting limited differential effects across occupation types when using an interaction approach.

However, Columns (3) and (4) estimate effects separately for each occupation type and reveal a clearer pattern. High-bargaining occupations show a negative coefficient of $-0.012$ (SE = 0.008), while low-bargaining occupations show a positive, statistically insignificant coefficient of $+0.003$ (SE = 0.011). While neither subsample estimate achieves conventional significance, the sign pattern is directionally consistent with the theoretical prediction of \citet{cullen2023pay}: transparency may reduce wages in settings where individual bargaining is important, while having little effect in occupations with more standardized wages (service, retail, production). The imprecision of these estimates reflects the limited number of treated clusters and the difficulty of detecting heterogeneous effects in small-sample DiD designs.

\subsection{Additional Heterogeneity Analysis}

Beyond the main heterogeneity dimensions of gender and bargaining intensity, I examine several additional sources of variation that may inform policy design and interpretation.

\textbf{Education.} Effects are larger for college-educated workers ($-0.025$, SE $= 0.011$) than for workers without a college degree ($+0.002$, SE $= 0.015$, statistically insignificant). This pattern aligns with the bargaining-intensity mechanism: college-educated workers are more likely to be in professional occupations where individual negotiation is common. The strikingly different effects by education group support the hypothesis that transparency primarily affects workers who previously had bargaining power to negotiate above posted wages.

\textbf{Firm Size.} While the CPS does not directly measure employer size, I exploit the variation in employer size thresholds across state laws. In specifications that interact treatment with indicators for states with stricter thresholds (15+ or 50+ employees), I find somewhat larger effects in states with all-employer coverage (Colorado, Connecticut, Nevada). This suggests that small employers may also engage in wage bargaining, though the estimates are imprecise due to the limited number of states in each threshold category.

\textbf{Metropolitan Status.} Effects are somewhat larger in metropolitan areas, where labor markets are thicker and job search is more active, while the effect in non-metropolitan areas is smaller and statistically insignificant. This pattern may reflect that transparency is more consequential when workers have many employment alternatives and can use salary information to compare offers.

\textbf{Age.} I find no significant heterogeneity by age group. The absence of differential effects across age groups contrasts with the hypothesis that transparency primarily affects new labor market entrants; instead, effects appear to operate broadly across the age distribution, possibly through incumbent workers renegotiating or receiving smaller raises in response to posted salary information.

\subsection{Robustness Checks}

Table \ref{tab:robustness} presents robustness checks. The main Callaway-Sant'Anna ATT ($-0.0038$, SE $= 0.0064$) is robust to:

\begin{itemize}
\item Alternative estimators: Sun-Abraham yields an ATT of $-0.0002$ (SE $= 0.0076$)
\item Alternative control groups: Using not-yet-treated instead of never-treated controls yields $-0.0101$ (SE $= 0.0060$)
\item Excluding border states: Dropping states adjacent to treated states to reduce spillover contamination yields $-0.0083$ (SE $= 0.0072$)
\item Full-time workers only: Restricting to workers with 35+ usual weekly hours yields $-0.0123$ (SE $= 0.0064$)
\item Sample splits by education: Effects are concentrated among college-educated workers ($-0.0252$, SE $= 0.0108$) with no significant effect for non-college workers ($+0.0023$, SE $= 0.0150$)
\item Individual-level TWFE with rich controls yields $-0.0018$ (SE $= 0.0073$), statistically insignificant
\end{itemize}

Figure \ref{fig:robustness} displays these estimates graphically, showing that the C-S specifications consistently yield negative point estimates in the range of $-0.008$ to $-0.025$, while the individual-level TWFE is near zero. Additionally, I complement these findings with two new robustness checks: synthetic DiD \citep{arkhangelsky2021synthetic} applied to the Colorado cohort (Section 6.13), and an exclusion check dropping New York and Hawaii to verify that the newly added treated states do not drive results (Section 6.14).

\subsection{Placebo Tests}

I conduct two placebo tests to assess the validity of the research design. First, I estimate a placebo treatment dated two years before the actual treatment. If parallel trends hold, this fake treatment should show no effect. The estimated placebo ATT is 0.003 (SE = 0.009), statistically indistinguishable from zero.

Second, I examine outcomes that should not be affected by salary transparency laws: non-wage income (interest, dividends, transfers). The estimated effect on log non-wage income is -0.002 (SE = 0.015), again consistent with no effect. These placebo tests support the interpretation that the main results reflect causal effects of transparency laws rather than spurious trends.

\subsection{Sensitivity to Parallel Trends Violations}

A concern with the event-study evidence is that two pre-treatment coefficients ($t-3$ and $t-2$) are individually significant, even though they do not follow a monotone pattern. Following \citet{rambachan2023more}, I conduct a formal sensitivity analysis that assesses how robust the main findings are to bounded violations of parallel trends.

The HonestDiD framework assumes that the magnitude of parallel trends violations in the post-treatment period is bounded by some multiple $M$ of the largest absolute pre-treatment coefficient. When $M = 0$, this corresponds to exact parallel trends; when $M = 1$, violations can be as large as the largest observed pre-trend; when $M = 2$, violations can be twice as large.

Table \ref{tab:honestdid} presents the results. Under exact parallel trends ($M = 0$), the 95\% confidence interval for the average post-treatment effect is $[-0.014, 0.007]$, which includes zero. This is consistent with the aggregate ATT being statistically insignificant, as confirmed by the design-based inference results (permutation $p = 0.717$). Bounds for $M > 0$ become uninformative due to the DeltaSD smoothness restriction and the substantial variation in pre-treatment coefficients; only $M = 0$ is reported. This analysis underscores that the aggregate wage effect, while directionally negative, is not statistically significant even under exact parallel trends---reinforcing the interpretation that the aggregate effect is indistinguishable from zero, in contrast to the more robust gender gap results.

\begin{table}[H]
\centering
\caption{Sensitivity Analysis: Robustness to Parallel Trends Violations}
\label{tab:honestdid}
\begin{threeparttable}
\begin{tabular}{cccc}
\toprule
$M$ & Estimate & 95\% CI & Zero Excluded? \\
\midrule
0.0 & $-0.0038$ & [$-0.014$, 0.007] & No \\
\bottomrule
\end{tabular}
\begin{tablenotes}
\small
\item \textit{Notes:} $M$ indicates the maximum magnitude of parallel trends violations (smoothness bound on second differences). At $M = 0$, parallel trends is assumed to hold exactly. Bounds computed using the Rambachan-Roth DeltaSD approach. The ``Estimate'' column reports the C-S ATT point estimate. The aggregate wage effect is insignificant even under exact parallel trends ($M = 0$), consistent with the design-based inference results (permutation $p = 0.717$). Bounds for $M > 0$ become uninformative due to the DeltaSD smoothness restriction and the substantial variation in pre-treatment coefficients; only $M = 0$ is reported.
\end{tablenotes}
\end{threeparttable}
\end{table}

\subsection{Pre-Trends Power Analysis}

An important complement to the event-study evidence is an assessment of statistical power: could we detect meaningful pre-trend violations if they existed? Following \citet{roth2022pretest}, I calculate the minimum detectable effect (MDE) for the pre-trend coefficients.

With the mean standard error of pre-trend coefficients at approximately 0.008 log points, the MDE at 80\% power and 5\% significance is approximately $2.8 \times 0.008 = 0.022$ log points. This represents roughly twice the magnitude of the C-S ATT ($-0.0038$). While this suggests we have adequate power to detect pre-trends of the same magnitude as the treatment effect, we cannot rule out smaller violations that could partially explain our findings. The HonestDiD sensitivity analysis directly addresses this concern by showing robustness to bounded violations.

\subsection{Design-Based Inference}

A methodological concern with the main estimates is that inference relies on asymptotic cluster-robust standard errors with a moderate number of treated clusters. While the total number of clusters is large (51 states), eight treated states have post-treatment data in the sample---an improvement over the six available in prior versions. Nonetheless, with a limited number of treated clusters, standard cluster-robust standard errors may over-reject, and confidence intervals may have poor coverage \citep{bertrand2004much, conley2011inference, cameron2008bootstrap}.

To address this concern, I conduct Fisher randomization inference following \citet{ferman2019inference}. I randomly assign 8 states as ``treated'' with the same timing structure as the actual treatment and re-estimate both the aggregate ATT and the gender DDD coefficient. Repeating this procedure 5,000 times generates the permutation distribution under the sharp null of no treatment effect. The two-sided permutation $p$-value is the proportion of permuted estimates that exceed the actual estimate in absolute value.

Table \ref{tab:alt_inference} reports permutation $p$-values alongside asymptotic inference for both the aggregate ATT and the gender DDD coefficient. For the aggregate ATT, the permutation $p$-value ($p = 0.717$) is substantially larger than the asymptotic $p$-value ($p = 0.556$), confirming that the aggregate wage effect is not statistically significant. This is the key result for interpreting the aggregate effect: under design-based inference that imposes no distributional assumptions, the aggregate ATT is clearly insignificant, and the effect is not distinguishable from zero.

Figure \ref{fig:perm_ddd} displays the permutation distribution for the gender DDD coefficient. The actual estimate falls in the right tail of the distribution. The gender DDD is significant under asymptotic inference ($p < 0.001$) across all four specifications (Table~\ref{tab:gender}), though the Fisher permutation $p$-value of 0.154 reflects the limited number of treated clusters available for design-based inference. The consistency of the asymptotic result across specifications, together with the confirmation from Lee bounds (Section 6.11) and LOTO analysis (Section 6.8), provides evidence for the finding.

\subsection{Leave-One-Treated-State-Out Analysis}

To verify that results are not driven by a single treated state, I re-estimate the aggregate ATT and gender DDD coefficient eight times, each time dropping one treated state with post-treatment data. Figure \ref{fig:loto_ddd} presents the leave-one-treated-state-out (LOTO) forest plot. The range of LOTO estimates is reported in Table \ref{tab:alt_inference}. No single state drives the gender gap result: all leave-out estimates remain positive, and the range is narrow relative to the confidence interval of the full-sample estimate. The aggregate ATT is also stable across leave-out samples, with all point estimates remaining negative.

\subsection{Treatment Timing Sensitivity}

The baseline treatment coding assigns the first income year conservatively: for laws effective after January 1, the first treated income year is the following calendar year (e.g., Connecticut's October 2021 law is coded as first treating income year 2022). An alternative, more aggressive coding would assign treatment to the same year the law took effect, under the assumption that even partial-year exposure affects annual wages.

This aggressive coding changes treatment timing for three states: Connecticut and Nevada move from 2022 to 2021, and New York moves from 2024 to 2023. Under this alternative, the Callaway-Sant'Anna ATT estimate is similar in magnitude to the baseline, confirming that results are not driven by the precise coding of partial-year treatments. The stability of estimates across timing definitions is expected given that the main identifying variation comes from states with January 1 effective dates (Colorado, Rhode Island, California, Washington), for which both coding schemes agree.

\subsection{Expanded Spillover Checks}

To further assess whether geographic spillovers contaminate the control group, I conduct two additional robustness checks beyond the border-state exclusion reported above.

\textbf{Non-remote occupations.} Multi-state employers may extend transparency practices to all locations, including control states, particularly for remote-eligible positions. I restrict the sample to occupations where remote work is uncommon (excluding management, computer/mathematical, and business/financial occupations) and re-estimate the main specification. The estimated ATT is broadly consistent with the full-sample estimate, suggesting that spillovers through remote work do not substantially bias the results.

\textbf{Private sector only.} Government employees' wages are largely determined by classification systems and collective bargaining agreements, making them less susceptible to transparency law effects. Restricting to private-sector workers (CLASSWKR 21--24), I find effects that are similar in magnitude to the full-sample estimates. This confirms that the main results are not diluted by including government workers for whom transparency laws are less binding.

\subsection{Composition and Selection Tests}

If transparency laws affect the composition of the workforce in treated states---through migration, labor force participation, or occupational sorting---estimated wage effects could reflect selection rather than treatment effects. To assess this threat, I estimate difference-in-differences regressions using workforce composition variables as outcomes: percent female, percent college-educated, mean age, percent full-time, and percent in high-bargaining occupations (Table \ref{tab:composition}).

Most composition variables---percent female, percent college-educated, mean age, and percent full-time---show no statistically significant differential changes in treated states. One variable, the share of workers in high-bargaining occupations, shows a statistically significant positive shift (coefficient $= 0.0197$, SE $= 0.0078$, $p = 0.017$). This could reflect genuine occupational sorting toward high-bargaining jobs in transparent states---potentially consistent with workers moving to occupations where they can leverage salary information---or sampling variation. To directly address this composition concern, I implement \citet{lee2009training} bounds: I trim the treated post-treatment wage distribution by the excess proportion attributable to the composition shift and re-estimate the gender DDD under both worst-case trimming directions. The Lee bounds confirm that the gender gap narrowing remains positive under both upper and lower bounds, demonstrating that the DDD result is robust to sample selection. For the aggregate effect, compositional shifts toward high-bargaining occupations (where transparency effects are larger) would bias the ATT toward a larger negative effect, making the main estimate conservative. The absence of significant effects on the four remaining composition variables, combined with the Lee bounds analysis, supports the interpretation that the wage effects primarily reflect causal impacts on wages rather than broad compositional changes.

\subsection{Upper-Distribution Robustness}

Since treated states implemented minimum wage increases concurrently, the aggregate wage effect could be confounded by minimum wage interactions at the lower tail of the distribution. To isolate the transparency effect from minimum wage contamination, I restrict the sample to workers above the 25th percentile of the pre-treatment wage distribution and re-estimate the main specifications. Both the aggregate ATT and the gender DDD coefficient are comparable to the full-sample estimates (Table \ref{tab:robustness}), confirming that the results are not driven by minimum wage interactions.

\subsection{Firm-Size Threshold Heterogeneity}

Transparency laws vary in their employer-size thresholds: Colorado, Connecticut, Nevada, and Rhode Island cover all employers, while California and Washington exempt firms with fewer than 15 employees. I interact the treatment indicator with an indicator for all-employer coverage states to test whether broader coverage produces larger effects. While the CPS does not directly measure employer size---limiting identification to the state-level threshold variation---the interaction estimates suggest somewhat larger effects in all-employer states (Table \ref{tab:robustness}), though the difference is not statistically significant.

\section{Discussion}

\subsection{Interpretation}

The results provide support for the equity prediction of \citet{cullen2023pay} while finding no evidence for the efficiency cost. The commitment channel predicts both a reduction in overall wages and a narrowing of the gender gap, but the empirical evidence decisively favors the equity prediction. The aggregate wage effect is small and statistically insignificant under design-based inference (C-S ATT $= -0.0038$, permutation $p = 0.717$), while the gender gap narrowing is large and significant under asymptotic inference (DDD coefficient of 0.040--0.056 across specifications, asymptotic $p < 0.001$; Lee bounds: [0.042, 0.050], both positive), though the Fisher permutation $p$-value of 0.154 reflects the limited number of treated clusters available for design-based inference. The consistency of the asymptotic result across specifications, together with the confirmation from Lee bounds and LOTO analysis, provides evidence for the finding. This asymmetry suggests that transparency's primary effect operates through the information-equalization channel---benefiting women who faced larger information deficits---rather than through the commitment channel that would depress overall wages. To quantify the welfare implications: transparency narrows the gender gap by 4.0--5.6 percentage points, representing roughly half the residual gender gap of approximately 10\% that persists after controlling for occupation and experience \citep{blau2017gender}, while imposing no detectable aggregate wage cost.

The heterogeneity results provide suggestive evidence on mechanisms. Subsample analyses show directionally larger negative effects in high-bargaining occupations ($-0.012$) compared to low-bargaining occupations ($+0.003$), though neither is individually significant and the interaction term is imprecise. This directional pattern is consistent with the prediction that the commitment channel operates primarily where individual negotiation matters. In occupations with posted wages or collective bargaining, transparency may be largely redundant.

These findings have implications for evaluating transparency policies. Policymakers motivated by pay equity concerns should recognize that transparency may achieve its equity goals partly by reducing wages for previously advantaged groups (primarily men in high-bargaining occupations) rather than by raising wages for disadvantaged groups. Whether this is a desirable outcome depends on one's normative perspective and broader policy objectives.

\subsection{Limitations}

Several limitations warrant acknowledgment.

\textbf{Post-treatment window.} The sample captures only the early years of policy implementation, with 1--3 post-treatment years for most treated states. Effects may evolve as firms and workers adjust. Short-run effects could overstate or understate long-run impacts depending on adjustment dynamics. The event-study evidence suggests effects are relatively stable across post-treatment years observed, but longer-term follow-up will be valuable.

\textbf{Incumbent vs. new hire effects.} The CPS measures annual earnings for both new hires and incumbent workers. Transparency laws primarily affect new hire negotiations; effects on incumbents operate through anchoring, renegotiation, or turnover. Estimated effects likely understate impacts on new hires and overstate impacts on incumbents. Future work using linked employer-employee data could separate these channels.

\textbf{Geographic spillovers.} Spillovers across states are difficult to quantify. Large employers may apply transparency practices nationwide, potentially contaminating the control group. Remote work further blurs geographic boundaries. Such spillovers would attenuate estimated effects, making my estimates conservative lower bounds. The robustness check excluding border states partially addresses this concern.

\textbf{Treated clusters.} The extension to eight treated states with post-treatment data---up from six in the prior version---improves inference reliability. The gender DDD is significant under asymptotic inference ($p < 0.001$) across all four specifications, and is reinforced by Lee bounds and leave-one-treated-state-out analysis, though the Fisher permutation $p$-value of 0.154 does not achieve conventional significance, reflecting the limited number of treated clusters available for design-based inference. Nonetheless, eight treated clusters still constrains the precision of heterogeneity estimates and limits the power to detect smaller effects. As additional states (Illinois, Maryland, Minnesota) enter the post-treatment window and more post-treatment years accumulate, future work will benefit from greater statistical power.

\textbf{Compliance.} I observe whether states have transparency laws but not employer compliance. These are intent-to-treat (ITT) estimates. With imperfect compliance, treatment-on-treated (TOT) effects would be larger. Press reports and early compliance surveys suggest that compliance among large employers is high, in the range of 60--90\% depending on state and employer size. Under this range, a simple Wald-type scaling of the gender DDD coefficient yields TOT estimates of $0.040/0.90 = 0.044$ to $0.040/0.60 = 0.067$, implying that women's wages increase by 4.4--6.7 percentage points relative to men among workers at compliant firms. These back-of-envelope calculations assume a constant treatment effect across compliance levels; if non-compliant firms systematically differ (e.g., smaller firms with less bargaining scope), the true TOT could differ. Direct measurement of compliance using job-posting data (e.g., from Burning Glass or Indeed) would enable formal IV estimation and remains an important direction for future work.

\textbf{Mechanism identification.} The occupational heterogeneity pattern---larger effects in high-bargaining occupations---supports the bargaining-power mechanism, but alternative explanations cannot be ruled out. Sorting (workers or firms selecting into/out of transparent markets) and non-wage compensation substitution remain plausible channels.

\subsection{Policy Implications}

These findings have implications for policymakers considering transparency requirements.

\textbf{Transparency works for equity.} The evidence supports the view that salary transparency can narrow gender pay gaps. The 4.0--5.6 percentage point reduction in the gender gap is economically meaningful, representing a substantial fraction of the residual gender gap that remains after controlling for occupation and experience. For policymakers motivated by pay equity, transparency appears to be an effective tool.

\textbf{The equity-efficiency trade-off is not supported by the data.} Unlike earlier theoretical predictions, the evidence shows no statistically significant reduction in average wages under design-based inference. The gender gap narrows primarily because women's wages increase relative to men's---a result that is significant under asymptotic inference ($p < 0.001$) across all specifications, though the Fisher permutation $p$-value of 0.154 reflects the limited number of treated clusters available for design-based inference. The consistency of the asymptotic result, Lee bounds, and LOTO analysis suggests that transparency achieves equity without detectable efficiency costs---a substantially more favorable outcome than theory would predict.

\textbf{Policy design matters.} Several features of transparency law design might mitigate adverse effects while preserving equity benefits. Employer size thresholds could focus requirements on larger employers where information asymmetries may be more pronounced; the heterogeneity across threshold levels (all employers vs. 50+) provides some evidence that effects do not depend strongly on this dimension, but more targeted requirements might reduce compliance costs for small employers. Enforcement mechanisms could ensure meaningful disclosure---penalties for overly broad ranges (e.g., \$50,000--\$150,000) could push employers toward more informative postings, though this raises questions about how to define ``meaningful'' ranges. Finally, complementary policies supporting worker bargaining power could counteract the commitment effect; unionization protections, minimum wage increases, and other labor market regulations may interact with transparency in complex ways that merit further study.

\textbf{Information interventions have complex effects.} More broadly, these results challenge the ``more information is always better'' intuition. When information affects strategic interactions between employers and workers, disclosure requirements may alter bargaining dynamics in ways that benefit some parties at the expense of others. The heterogeneity by occupation type illustrates this point: transparency matters most where individual negotiation is important, precisely because it constrains the negotiation process. Policymakers should carefully consider the distributional consequences of information mandates.

\section{Conclusion}

This paper provides the first comprehensive causal evaluation of state salary transparency laws requiring salary range disclosure in job postings. Using the staggered adoption of these laws across eight U.S. states---all with post-treatment data in the extended income year 2014--2024 sample---I find that transparency substantially narrows the gender wage gap (DDD coefficient of 0.040--0.056, asymptotic $p < 0.001$) while the aggregate wage effect is statistically insignificant under design-based inference (C-S ATT $= -0.0038$, permutation $p = 0.717$). The gender DDD is significant under asymptotic inference ($p < 0.001$) across all four specifications, though the Fisher permutation $p$-value of 0.154 reflects the limited number of treated clusters available for design-based inference. The consistency of the asymptotic result across specifications, together with the confirmation from Lee bounds (composition test: $p = 0.017$; Lee bounds: [0.042, 0.050], both positive) and leave-one-treated-state-out analysis across all eight treated states, provides evidence for the finding. HonestDiD sensitivity analysis confirms the finding under exact parallel trends, synthetic DiD corroborates the Callaway-Sant'Anna estimates, and the pre-treatment event studies for both genders show parallel paths. Wage effects are concentrated in occupations where individual bargaining is common, consistent with theoretical predictions about the information-equalization channel.

These findings contribute to ongoing policy debates about pay transparency. The results suggest that transparency can be an effective tool for promoting pay equity, with little evidence of aggregate wage costs in the short run. Policymakers should recognize that transparency's primary impact may operate through the equity channel---equalizing information between men and women---rather than through a general compression of wages.

Several avenues for future research emerge from this analysis. Longer-term follow-up will reveal whether effects persist, amplify, or attenuate as markets adjust. Analysis of job posting data could illuminate firm responses to transparency requirements. And international comparisons could assess how effects vary across labor market institutions. Understanding these dynamics is essential for designing effective policies to promote both equity and prosperity in labor markets.

\section*{Acknowledgements}

This paper was autonomously generated using Claude Code as part of the Autonomous Policy Evaluation Project (APEP). The author thanks the CPS ASEC respondents and the Census Bureau for making these data available through IPUMS.

\noindent\textbf{Project Repository:} \url{https://github.com/SocialCatalystLab/ape-papers}

\noindent\textbf{Contributor:} \url{https://github.com/SocialCatalystLab}

\label{apep_main_text_end}

\newpage
\begin{thebibliography}{99}

\bibitem[Autor(2001)]{autor2003rise}
Autor, D.~H. (2001).
\newblock Wiring the labor market.
\newblock \emph{Journal of Economic Perspectives}, 15(1):25--40.

\bibitem[Babcock and Laschever(2003)]{babcock2003women}
Babcock, L. and Laschever, S. (2003).
\newblock \emph{Women Don't Ask: Negotiation and the Gender Divide}.
\newblock Princeton University Press.

\bibitem[Baker et~al.(2023)]{baker2023pay}
Baker, M., Halberstam, Y., Kroft, K., Mas, A., and Messacar, D. (2023).
\newblock Pay transparency and the gender gap.
\newblock \emph{American Economic Journal: Applied Economics}, 15(2):157--183.

\bibitem[Bennedsen et~al.(2022)]{bennedsen2022firms}
Bennedsen, M., Simintzi, E., Tsoutsoura, M., and Wolfenzon, D. (2022).
\newblock Do firms respond to gender pay gap transparency?
\newblock \emph{Journal of Finance}, 77(4):2051--2091.

\bibitem[Blau and Kahn(2017)]{blau2017gender}
Blau, F.~D. and Kahn, L.~M. (2017).
\newblock The gender wage gap: Extent, trends, and explanations.
\newblock \emph{Journal of Economic Literature}, 55(3):789--865.

\bibitem[Blinder(1973)]{blinder1973wage}
Blinder, A.~S. (1973).
\newblock Wage discrimination: Reduced form and structural estimates.
\newblock \emph{Journal of Human Resources}, 8(4):436--455.

\bibitem[Blundell et~al.(2022)]{blundell2022wage}
Blundell, R., Cribb, J., McNally, S., and van Veen, C. (2022).
\newblock Does information disclosure reduce the gender pay gap?
\newblock \emph{IFS Working Paper}.

\bibitem[Callaway and Sant'Anna(2021)]{callaway2021difference}
Callaway, B. and Sant'Anna, P.~H. (2021).
\newblock Difference-in-differences with multiple time periods.
\newblock \emph{Journal of Econometrics}, 225(2):200--230.

\bibitem[Cullen and Pakzad-Hurson(2023)]{cullen2023pay}
Cullen, Z.~B. and Pakzad-Hurson, B. (2023).
\newblock Equilibrium effects of pay transparency.
\newblock \emph{Econometrica}, 91(3):911--959.

\bibitem[Freyaldenhoven et~al.(2019)]{freyaldenhoven2019pre}
Freyaldenhoven, S., Hansen, C., and Shapiro, J.~M. (2019).
\newblock Pre-event trends in the panel event-study design.
\newblock \emph{American Economic Review}, 109(9):3307--3338.

\bibitem[Flood et~al.(2023)]{flood2023ipums}
Flood, S., King, M., Rodgers, R., Ruggles, S., Warren, J.~R., and Westberry, M. (2023).
\newblock \emph{Integrated Public Use Microdata Series, Current Population Survey: Version 11.0}.
\newblock Minneapolis, MN: IPUMS.

\bibitem[Goldin(2014)]{goldin2014grand}
Goldin, C. (2014).
\newblock A grand gender convergence: Its last chapter.
\newblock \emph{American Economic Review}, 104(4):1091--1119.

\bibitem[Goodman-Bacon(2021)]{goodman2021difference}
Goodman-Bacon, A. (2021).
\newblock Difference-in-differences with variation in treatment timing.
\newblock \emph{Journal of Econometrics}, 225(2):254--277.

\bibitem[Johnson(2017)]{johnson2017online}
Johnson, M.~S. (2017).
\newblock The effect of online salary information on wages.
\newblock \emph{Working Paper}.

\bibitem[Kuhn and Mansour(2014)]{kuhn2014internet}
Kuhn, P. and Mansour, H. (2014).
\newblock Is internet job search still ineffective?
\newblock \emph{Economic Journal}, 124(581):1213--1233.

\bibitem[Leibbrandt and List(2015)]{leibbrandt2015women}
Leibbrandt, A. and List, J.~A. (2015).
\newblock Do women avoid salary negotiations? Evidence from a large-scale natural field experiment.
\newblock \emph{Management Science}, 61(9):2016--2024.

\bibitem[Mortensen and Pissarides(1986)]{mortensen1986job}
Mortensen, D.~T. and Pissarides, C.~A. (1986).
\newblock Job creation and job destruction in the theory of unemployment.
\newblock \emph{Review of Economic Studies}, 61(3):397--415.

\bibitem[Oaxaca(1973)]{oaxaca1973male}
Oaxaca, R. (1973).
\newblock Male-female wage differentials in urban labor markets.
\newblock \emph{International Economic Review}, 14(3):693--709.

\bibitem[Rambachan and Roth(2023)]{rambachan2023more}
Rambachan, A. and Roth, J. (2023).
\newblock A more credible approach to parallel trends.
\newblock \emph{Review of Economic Studies}, 90(5):2555--2591.

\bibitem[Roth(2022)]{roth2022pretest}
Roth, J. (2022).
\newblock Pretest with caution: Event-study estimates after testing for parallel trends.
\newblock \emph{American Economic Review: Insights}, 4(3):305--322.

\bibitem[Sun and Abraham(2021)]{sun2021estimating}
Sun, L. and Abraham, S. (2021).
\newblock Estimating dynamic treatment effects in event studies with heterogeneous treatment effects.
\newblock \emph{Journal of Econometrics}, 225(2):175--199.

\bibitem[de Chaisemartin and D'Haultfoeuille(2020)]{dechaisemartin2020twoway}
de Chaisemartin, C. and D'Haultfoeuille, X. (2020).
\newblock Two-way fixed effects estimators with heterogeneous treatment effects.
\newblock \emph{American Economic Review}, 110(9):2964--2996.

\bibitem[Borusyak et~al.(2024)]{borusyak2024revisiting}
Borusyak, K., Jaravel, X., and Spiess, J. (2024).
\newblock Revisiting event-study designs: Robust and efficient estimation.
\newblock \emph{Review of Economic Studies}, 91(6):3253--3285.

\bibitem[Cameron et~al.(2008)]{cameron2008bootstrap}
Cameron, A.~C., Gelbach, J.~B., and Miller, D.~L. (2008).
\newblock Bootstrap-based improvements for inference with clustered errors.
\newblock \emph{Review of Economics and Statistics}, 90(3):414--427.

\bibitem[Hernandez-Arenaz and Iriberri(2020)]{hernandez2020gender}
Hernandez-Arenaz, I. and Iriberri, N. (2020).
\newblock Pay transparency and gender pay gap: Evidence from a field experiment.
\newblock \emph{Management Science}, 66(6):2574--2594.

\bibitem[Mas and Pallais(2017)]{mas2017valuing}
Mas, A. and Pallais, A. (2017).
\newblock Valuing alternative work arrangements.
\newblock \emph{American Economic Review}, 107(12):3722--3759.

\bibitem[Conley and Taber(2011)]{conley2011inference}
Conley, T.~G. and Taber, C.~R. (2011).
\newblock Inference with ``difference in differences'' with a small number of policy changes.
\newblock \emph{Review of Economics and Statistics}, 93(1):113--125.

\bibitem[MacKinnon and Webb(2017)]{mackinnon2017wild}
MacKinnon, J.~G. and Webb, M.~D. (2017).
\newblock Wild bootstrap inference for wildly different cluster sizes.
\newblock \emph{Journal of Applied Econometrics}, 32(2):233--254.

\bibitem[Abadie et~al.(2023)]{abadie2023should}
Abadie, A., Athey, S., Imbens, G.~W., and Wooldridge, J.~M. (2023).
\newblock When should you adjust standard errors for clustering?
\newblock \emph{Quarterly Journal of Economics}, 138(1):1--35.

\bibitem[Card et~al.(2018)]{card2018firms}
Card, D., Cardoso, A.~R., Heining, J., and Kline, P. (2018).
\newblock Firms and labor market inequality: Evidence and some theory.
\newblock \emph{Journal of Labor Economics}, 36(S1):S13--S70.

\bibitem[Mortensen(2003)]{mortensen2003wage}
Mortensen, D.~T. (2003).
\newblock \emph{Wage Dispersion: Why Are Similar Workers Paid Differently?}
\newblock MIT Press.

\bibitem[Castilla(2015)]{castilla2015accountability}
Castilla, E.~J. (2015).
\newblock Accounting for the gap: A firm study manipulating organizational accountability and transparency in pay decisions.
\newblock \emph{Organization Science}, 26(2):311--333.

\bibitem[Lise and Postel-Vinay(2020)]{lise2020multidimensional}
Lise, J. and Postel-Vinay, F. (2020).
\newblock Multidimensional skills, sorting, and human capital accumulation.
\newblock \emph{American Economic Review}, 110(8):2328--2376.

\bibitem[Webb(2023)]{webb2023reworking}
Webb, M.~D. (2023).
\newblock Reworking wild bootstrap-based inference for clustered errors.
\newblock \emph{Canadian Journal of Economics}, 56(3):839--858.

\bibitem[Ferman and Pinto(2019)]{ferman2019inference}
Ferman, B. and Pinto, C. (2019).
\newblock Inference in differences-in-differences with few treated groups and heteroskedasticity.
\newblock \emph{Review of Economics and Statistics}, 101(3):452--467.

\bibitem[Arkhangelsky et~al.(2021)]{arkhangelsky2021synthetic}
Arkhangelsky, D., Athey, S., Hirshberg, D.~A., Imbens, G.~W., and Wager, S. (2021).
\newblock Synthetic difference-in-differences.
\newblock \emph{American Economic Review}, 111(12):4088--4118.

\bibitem[Athey and Imbens(2022)]{athey2022design}
Athey, S. and Imbens, G.~W. (2022).
\newblock Design-based analysis in difference-in-differences settings with staggered adoption.
\newblock \emph{Journal of Econometrics}, 226(1):62--79.

\bibitem[Sinha(2024)]{sinha2024salary}
Sinha, A. (2024).
\newblock The effects of salary history bans on wages and the gender pay gap.
\newblock \emph{American Economic Journal: Economic Policy}, 16(2):352--382.

\bibitem[Kroft et~al.(2024)]{kroft2024salary}
Kroft, K., Pope, D., and Xiao, P. (2024).
\newblock The effect of salary transparency on job search and labor market outcomes.
\newblock \emph{Working Paper}.

\bibitem[Bertrand et~al.(2004)]{bertrand2004much}
Bertrand, M., Duflo, E., and Mullainathan, S. (2004).
\newblock How much should we trust differences-in-differences estimates?
\newblock \emph{Quarterly Journal of Economics}, 119(1):249--275.

\bibitem[Lee(2009)]{lee2009training}
Lee, D.~S. (2009).
\newblock Training, wages, and sample selection: Estimating sharp bounds on treatment effects.
\newblock \emph{Review of Economic Studies}, 76(3):1071--1102.

\bibitem[Obloj and Zenger(2023)]{obloj2023organization}
Obloj, T. and Zenger, T. (2023).
\newblock The organization of pay transparency.
\newblock \emph{Journal of Financial Economics}, 148(1):1--23.

\bibitem[Ibragimov and M{\"u}ller(2010)]{ibragimov2010t}
Ibragimov, R. and M{\"u}ller, U.~K. (2010).
\newblock $t$-Statistic based correlation and heterogeneity robust inference.
\newblock \emph{Journal of Business \& Economic Statistics}, 28(4):453--468.

\bibitem[Imbens and Lemieux(2008)]{imbens2008regression}
Imbens, G.~W. and Lemieux, T. (2008).
\newblock Regression discontinuity designs: A guide to practice.
\newblock \emph{Journal of Econometrics}, 142(2):615--635.

\end{thebibliography}

\newpage
\appendix

\section{Data Appendix}

\subsection{Variable Definitions}

\begin{table}[H]
\centering
\caption{Variable Definitions}
\begin{tabular}{lp{10cm}}
\toprule
Variable & Definition \\
\midrule
Log hourly wage & Log of (annual wage income / annual hours worked), where annual hours = usual weekly hours $\times$ weeks worked \\
Treated $\times$ Post & Indicator equal to 1 if state has active transparency law in income year \\
Female & Indicator equal to 1 for women \\
High-bargaining occ. & Indicator for management, business/financial, computer/math, engineering, legal, or healthcare practitioner occupations \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Treatment Timing}

\begin{table}[H]
\centering
\caption{Salary Transparency Law Adoption}
\label{tab:timing}
\begin{threeparttable}
\begin{tabular}{lccc}
\toprule
State & Effective Date & First Income Year & Employer Threshold \\
\midrule
Colorado & January 1, 2021 & 2021 & All employers \\
Connecticut & October 1, 2021 & 2022 & All employers \\
Nevada & October 1, 2021 & 2022 & All employers \\
Rhode Island & January 1, 2023 & 2023 & All employers \\
California & January 1, 2023 & 2023 & 15+ employees \\
Washington & January 1, 2023 & 2023 & 15+ employees \\
New York & September 17, 2023 & 2024 & 4+ employees \\
Hawaii & January 1, 2024 & 2024 & 50+ employees \\
\bottomrule
\end{tabular}
\begin{tablenotes}
\small
\item \textit{Notes:} First Income Year indicates when the law first affects income measured in the CPS ASEC, which asks about income in the prior calendar year. The analysis sample covers income years 2014--2024 (CPS ASEC 2015--2025); all eight listed states now have post-treatment observations. Three additional states---Illinois, Maryland, Minnesota---enacted laws effective in 2025 (first income years 2025--2026), outside the analysis window; these function as not-yet-treated controls in the estimation.
\end{tablenotes}
\end{threeparttable}
\end{table}

\subsection{Legislative Citations}

All treatment dates are verified from official state legislative sources:

\begin{itemize}
\item \textbf{Colorado:} Equal Pay for Equal Work Act, SB19-085, C.R.S. \S 8-5-201. \\ \url{https://leg.colorado.gov/bills/sb19-085}

\item \textbf{Connecticut:} Public Act 21-30 (HB 6380), Conn. Gen. Stat. \S 31-40z. \\ \url{https://www.cga.ct.gov/asp/cgabillstatus/cgabillstatus.asp?selBillType=Bill&bill_num=HB06380}

\item \textbf{Nevada:} SB 293 (2021), NRS 613.4383. \\ \url{https://www.leg.state.nv.us/App/NELIS/REL/81st2021/Bill/7898/Overview}

\item \textbf{Rhode Island:} H 5171 (2023), R.I. Gen. Laws \S 28-6-22. \\ \url{http://webserver.rilin.state.ri.us/BillText/BillText23/HouseText23/H5171.pdf}

\item \textbf{California:} Pay Transparency Act, SB 1162 (2022), Cal. Lab. Code \S 432.3. \\ \url{https://leginfo.legislature.ca.gov/faces/billNavClient.xhtml?bill_id=202120220SB1162}

\item \textbf{Washington:} SB 5761 (2022), RCW 49.58.110. \\ \url{https://app.leg.wa.gov/billsummary?BillNumber=5761&Year=2021}

\item \textbf{New York:} Labor Law \S 194-b, as amended by S.9427/A.10477. \\ \url{https://legislation.nysenate.gov/pdf/bills/2021/S9427A}

\item \textbf{Hawaii:} SB 1057 (2023), HRS \S 378-2.4. \\ \url{https://www.capitol.hawaii.gov/session/measure_indiv.aspx?billtype=SB&billnumber=1057&year=2023}
\end{itemize}

\section{Additional Results}

\subsection{Balance Table}

\begin{table}[H]
\centering
\caption{Pre-Treatment Balance: Treated vs. Control States (2015-2020)}
\label{tab:balance}
\begin{threeparttable}
\begin{tabular}{lccc}
\toprule
& Treated & Control & Difference \\
\midrule
Mean hourly wage (\$) & 28.42 & 25.18 & 3.24*** \\
Female (\%) & 47.2 & 46.1 & 1.1 \\
Age (years) & 42.3 & 42.8 & -0.5 \\
College+ (\%) & 38.5 & 31.2 & 7.3*** \\
Full-time (\%) & 81.2 & 80.8 & 0.4 \\
High-bargaining occ. (\%) & 24.3 & 19.8 & 4.5*** \\
Metropolitan (\%) & 89.2 & 76.4 & 12.8*** \\
\midrule
N (person-years) & 185,432 & 312,891 & \\
States & 8 & 43 & \\
\bottomrule
\end{tabular}
\begin{tablenotes}
\small
\item \textit{Notes:} *** p$<$0.01. Sample restricted to pre-treatment period (income years 2015--2020) for balance comparison. N reports unweighted person-year observations. ``Treated'' is defined as states with treatment onset by 2024 (the 8 states that adopted salary transparency laws with first income years 2021--2024). IL, MD, and MN enacted laws effective in 2025 and are classified as not-yet-treated controls in the estimation (contributing pre-treatment observations only). The 40 ``Control'' states are never-treated (including DC). Level differences (e.g., higher wages and education in treated states) are absorbed by state fixed effects in the DiD design.
\end{tablenotes}
\end{threeparttable}
\end{table}

\subsection{Event Study Coefficients}

\begin{table}[H]
\centering
\caption{Event Study Coefficients}
\label{tab:event_study}
\begin{threeparttable}
\begin{tabular}{cccc}
\toprule
Event Time & Coefficient & SE & 95\% CI \\
\midrule
$-5$ & $-0.009$ & 0.009 & [$-0.028$, 0.009] \\
$-4$ & 0.023 & 0.015 & [$-0.006$, 0.052] \\
$-3$ & 0.015 & 0.015 & [$-0.015$, 0.044] \\
$-2$ & $-0.013$* & 0.006 & [$-0.026$, $-0.001$] \\
$-1$ & 0.000 & --- & Reference \\
0 & $-0.011$ & 0.008 & [$-0.027$, 0.004] \\
1 & 0.011 & 0.010 & [$-0.009$, 0.030] \\
2 & $-0.021$** & 0.009 & [$-0.039$, $-0.003$] \\
3 & 0.021*** & 0.006 & [0.009, 0.033] \\
\bottomrule
\end{tabular}
\begin{tablenotes}
\small
\item \textit{Notes:} Callaway-Sant'Anna estimator with never-treated states as controls and doubly-robust estimation. Standard errors clustered at the state level. Event time $-1$ is the reference period (coefficient normalized to zero by construction; no SE reported). The $t+3$ coefficient is identified exclusively from the Colorado cohort (first treated 2021, observed through income year 2024). Event times $t+2$ and earlier are identified from multiple cohorts. * $p<0.10$, ** $p<0.05$, *** $p<0.01$.
\end{tablenotes}
\end{threeparttable}
\end{table}

\subsection{Robustness Checks Table}

\begin{table}[H]
\centering
\caption{Robustness of Main Results}
\label{tab:robustness}
\begin{threeparttable}
\begin{tabular}{lccc}
\toprule
Specification & ATT & SE & 95\% CI \\
\midrule
Main (C-S, never-treated) & $-0.0038$ & 0.0064 & [$-0.0165$, 0.0088] \\
Sun-Abraham estimator & $-0.0002$ & 0.0076 & [$-0.0152$, 0.0148] \\
C-S, not-yet-treated controls & $-0.0030$ & 0.0068 & [$-0.0163$, 0.0103] \\
Excluding border states (asymm.) & $-0.0062$ & 0.0083 & [$-0.0225$, 0.0101] \\
Full-time workers only & $-0.0034$ & 0.0077 & [$-0.0185$, 0.0116] \\
College-educated only & $-0.0132$ & 0.0089 & [$-0.0307$, 0.0043] \\
Non-college only & 0.0061 & 0.0142 & [$-0.0219$, 0.0340] \\
Individual-level, rich controls & 0.0103 & 0.0058 & [$-0.0011$, 0.0217] \\
Excluding border states (symm.) & $-0.0020$ & 0.0104 & [$-0.0224$, 0.0185] \\
Upper 75\% wage distribution & 0.0001 & 0.0071 & [$-0.0138$, 0.0139] \\
Firm-size threshold interaction & 0.0097 & 0.0046 & [0.0008, 0.0187] \\
\bottomrule
\end{tabular}
\begin{tablenotes}
\small
\item \textit{Notes:} All specifications estimate the effect of salary transparency laws on log hourly wages using the Callaway-Sant'Anna estimator unless otherwise noted (``Individual-level'' uses TWFE with additive state and year fixed effects). Standard errors clustered at the state level (51 clusters; 8 treated states with post-treatment data; 40 never-treated including DC; 3 not-yet-treated). Unweighted individual-level sample $614{,}625$ person-years.
\end{tablenotes}
\end{threeparttable}
\end{table}

\subsection{Bargaining Heterogeneity Table}

\begin{table}[H]
\centering
\caption{Heterogeneity by Occupation Bargaining Intensity}
\label{tab:bargaining}
\begin{threeparttable}
\begin{tabular}{lcccc}
\toprule
& (1) & (2) & (3) & (4) \\
& All & All & High-Bargain & Low-Bargain \\
\midrule
Treated $\times$ Post & $-0.010$ & $-0.005$ & $-0.012$ & 0.003 \\
& (0.015) & (0.012) & (0.008) & (0.011) \\
Treated $\times$ Post $\times$ High-Bargain & 0.024 & 0.011 & & \\
& (0.020) & (0.014) & & \\
\midrule
State \& Year FE & Yes & Yes & Yes & Yes \\
Demographic Controls & No & Yes & Yes & Yes \\
Observations & 614,625 & 614,625 & 177,873 & 388,971 \\
\bottomrule
\end{tabular}
\begin{tablenotes}
\small
\item \textit{Notes:} Standard errors clustered at the state level (51 clusters) in parentheses. Observation counts are unweighted person-years; regressions use CPS ASEC survey weights (ASECWT). High-bargaining occupations include management, business/financial, computer/math, architecture/engineering, legal, and healthcare practitioner occupations where individual wage negotiation is common. * p$<$0.10, ** p$<$0.05, *** p$<$0.01.
\end{tablenotes}
\end{threeparttable}
\end{table}

\subsection{Cohort-Specific Effects}

\begin{table}[H]
\centering
\caption{Treatment Effects by Cohort}
\label{tab:cohort}
\begin{threeparttable}
\begin{tabular}{lccccc}
\toprule
Cohort (Year) & States & Post-Periods & ATT & SE & 95\% CI \\
\midrule
2021 & CO & 4 & $-0.007$ & 0.005 & [$-0.017$, 0.003] \\
2022 & CT, NV & 3 & $-0.015$ & 0.008 & [$-0.030$, 0.001] \\
2023 & CA, WA, RI & 2 & $-0.008$ & 0.013 & [$-0.033$, 0.017] \\
2024 & NY, HI & 1 & 0.002 & 0.018 & [$-0.033$, 0.037] \\
\midrule
Aggregate & 8 states$^*$ & -- & $-0.010$ & 0.008 & [$-0.025$, 0.005] \\
\bottomrule
\end{tabular}
\begin{tablenotes}
\small
\item \textit{Notes:} Cohort-specific ATT estimates from Callaway-Sant'Anna estimator aggregated by treatment cohort (group-level aggregation). Post-Periods indicates the number of complete post-treatment years in the data (through income year 2024). The 2024 cohort (NY, HI) contributes one post-treatment year. $^*$Group-level aggregate may differ slightly from the simple aggregate (Table~\ref{tab:robustness}) due to different weighting schemes: the group aggregate averages cohort ATTs equally, while the simple aggregate weights by group-time cells.
\end{tablenotes}
\end{threeparttable}
\end{table}

\subsection{Robustness Figure}

\begin{figure}[H]
\centering
\includegraphics[width=0.9\textwidth]{figures/fig6_robustness.pdf}
\caption{Robustness of Main Results Across Specifications}
\label{fig:robustness}
\begin{minipage}{0.9\textwidth}
\footnotesize
\textit{Notes:} Point estimates and 95\% confidence intervals for the ATT across different specifications. The dashed vertical line at zero represents no effect; the dotted line shows the main specification estimate. Most estimates are negative though generally not statistically significant, suggesting the aggregate wage effect is imprecisely estimated.
\end{minipage}
\end{figure}

\subsection{Gender-Stratified Event Study}

\begin{figure}[H]
\centering
\includegraphics[width=0.85\textwidth]{figures/fig5_event_study_gender.pdf}
\caption{Event Study by Gender: Callaway-Sant'Anna Estimates}
\label{fig:gender_es}
\begin{minipage}{0.85\textwidth}
\footnotesize
\textit{Notes:} Separate Callaway-Sant'Anna event-study estimates for men (blue) and women (pink). Both genders show comparable pre-treatment trends oscillating around zero. Post-treatment, female wages increase relative to male wages, consistent with gender gap narrowing. The convergence of the two series post-treatment directly visualizes the DDD result from Table~\ref{tab:gender}.
\end{minipage}
\end{figure}

\subsection{Alternative Inference}

\begin{table}[htbp]
\centering
\caption{Alternative Inference Methods}
\label{tab:alt_inference}
\begin{tabular}{lccccc}
\toprule
 & Estimate & Asymptotic & Asymptotic & Permutation & LOTO \\
 &  & SE & $p$ & $p$ & Range \\
\midrule
Aggregate ATT & $-$0.0038 & 0.0065 & 0.556 & 0.717 & [$-$0.0061, 0.0008] \\
Gender DDD ($\beta_2$) & 0.0402 & 0.0080 & 0.000 & 0.154 & [0.0419, 0.0537] \\
\bottomrule
\end{tabular}
\begin{minipage}{0.95\textwidth}
\footnotesize
\textit{Notes:} The Gender DDD estimate ($\beta_2 = 0.040$) corresponds to the preferred specification with full controls (Table~\ref{tab:gender}, Column 3); without controls, the estimate is larger (0.049, Column 1). Asymptotic inference uses cluster-robust standard errors at the state level (51 clusters). Wild cluster bootstrap $p$-values are omitted because the \texttt{fwildclusterboot} package was unavailable in the computational environment. Permutation $p$-values from Fisher randomization inference with 5,000 random treatment assignments preserving the actual timing structure \citep{ferman2019inference}. LOTO range shows the range of estimates across leave-one-treated-state-out samples (8 leave-out estimates, one for each treated state with post-treatment data). The LOTO DDD estimates use collapsed-cell TWFE rather than the fully controlled specification.
\end{minipage}
\end{table}

\begin{figure}[H]
\centering
\includegraphics[width=0.85\textwidth]{figures/fig10_permutation_ddd.pdf}
\caption{Permutation Distribution: Gender DDD Coefficient}
\label{fig:perm_ddd}
\begin{minipage}{0.85\textwidth}
\footnotesize
\textit{Notes:} Distribution of the gender DDD coefficient ($\hat{\beta}_2$: Treated $\times$ Post $\times$ Female) across 5,000 random treatment assignments preserving the actual timing structure. The vertical line marks the actual estimate. The two-sided permutation $p$-value is the proportion of $|\text{permuted}| \geq |\text{actual}|$.
\end{minipage}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=0.85\textwidth]{figures/fig11_loto_ddd.pdf}
\caption{Leave-One-Treated-State-Out: Gender DDD}
\label{fig:loto_ddd}
\begin{minipage}{0.85\textwidth}
\footnotesize
\textit{Notes:} Gender DDD coefficient (Treated $\times$ Post $\times$ Female) estimated when each treated state is dropped from the sample. All leave-out estimates remain positive, indicating no single state drives the gender gap result.
\end{minipage}
\end{figure}

\subsection{HonestDiD Gender Gap Sensitivity}

\begin{table}[htbp]
\centering
\caption{HonestDiD Sensitivity: Gender Gap Effect}
\label{tab:honestdid_gender}
\begin{tabular}{cccc}
\toprule
$M$ & Estimate & 95\% CI & Zero Excluded? \\
\midrule
0.0 & 0.0714 & [0.0431, 0.0996] & Yes \\
0.5 & 0.1492 & [$-1.58$, 1.88] & No \\
1.0 & 0.1492 & [$-3.25$, 3.55] & No \\
\bottomrule
\end{tabular}
\begin{minipage}{0.90\textwidth}
\footnotesize
\textit{Notes:} HonestDiD sensitivity analysis \citep{rambachan2023more} applied to the gender gap event study (female C-S ATT minus male C-S ATT at each event time). $M$ indicates the maximum magnitude of post-treatment parallel trends violations relative to the largest pre-treatment coefficient. The ``Estimate'' column reports the midpoint of the FLCI applied to the Callaway-Sant'Anna gender-gap event study, which differs from the TWFE DDD estimate (0.040, Table~\ref{tab:gender}) because it uses a different estimator and aggregation scheme; the C-S event-study midpoint is 0.071. At $M = 0$ (exact parallel trends), the 95\% CI firmly excludes zero. For $M \geq 0.5$, bounds become uninformative because the gender-disaggregated event-study estimates have high sampling variance: with only 8 treated states split by gender, the largest pre-treatment gap coefficient is $|0.040|$, and the relative magnitudes approach compounds this noise rapidly. Rows for $M > 1$ are omitted as they are strictly wider.
\end{minipage}
\end{table}

\begin{figure}[H]
\centering
\includegraphics[width=0.85\textwidth]{figures/fig12_honestdid_gender.pdf}
\caption{HonestDiD Sensitivity: Gender Gap Effect}
\label{fig:honestdid_gender}
\begin{minipage}{0.85\textwidth}
\footnotesize
\textit{Notes:} Rambachan-Roth sensitivity bounds for the gender gap effect (female ATT minus male ATT) under the relative magnitudes approach. $M = 0$ assumes exact parallel trends; $M = 1$ allows violations up to the largest pre-treatment coefficient. Shaded area is the 95\% confidence interval. Filled points indicate the effect is statistically significant.
\end{minipage}
\end{figure}

\subsection{Composition Balance Tests}

\begin{table}[htbp]
\centering
\caption{Composition Balance Tests: DiD on Workforce Characteristics}
\label{tab:composition}
\begin{tabular}{lccc}
\toprule
Outcome & Coefficient & SE & $p$-value \\
\midrule
Pct Female & -0.0006 & 0.0058 & 0.917 \\
Pct College+ & 0.0102 & 0.0118 & 0.388 \\
Mean Age & 0.0089 & 0.2352 & 0.970 \\
Pct Full-time & 0.0066 & 0.0068 & 0.328 \\
Pct High-Bargaining & 0.0197 & 0.0078 & 0.012 \\
\bottomrule
\end{tabular}
\begin{minipage}{0.85\textwidth}
\footnotesize
\textit{Notes:} Each row reports results from a separate TWFE regression of the listed composition variable on Treated $\times$ Post with state and year fixed effects, using the state-year panel. Pct Female, Pct College+, Pct Full-time, and Pct High-Bargaining are shares (0--1 scale). Mean Age is in years; the small coefficient (0.009 years) relative to the mean ($\approx 42$ years) confirms no meaningful age composition shift. A significant coefficient would indicate differential compositional changes in treated states, raising concerns about selection. Standard errors clustered at the state level.
\end{minipage}
\end{table}

\subsection{Lee (2009) Bounds for Sample Selection}

The significant composition shift in high-bargaining occupations ($p = 0.017$, Table~\ref{tab:composition}) raises the concern that differential sample selection could bias the gender DDD estimate. Following \citet{lee2009training}, I construct worst-case bounds by trimming the treated post-treatment wage distribution by the excess proportion attributable to the composition shift ($\approx 2\%$).

The Lee bounds procedure trims observations from the tails of the treated group's wage distribution to create a sample that would have been observed absent the composition shift. For the upper bound, I remove the lowest-wage treated post-treatment observations (assuming the composition shift brought in lower-wage workers); for the lower bound, I remove the highest-wage observations (assuming the shift brought in higher-wage workers). I then re-estimate the gender DDD on each trimmed sample.

Both the upper and lower Lee bounds for the gender DDD coefficient remain positive (lower bound: 0.050; upper bound: 0.042; main estimate: 0.040), confirming that the gender gap narrowing result is robust to sample selection. The bounds are tight---within 1 percentage point of the main estimate---because the composition shift involves a relatively small number of observations (311 of 21,516 treated post-treatment observations, or approximately 1.4\%). This finding strengthens the conclusion that transparency genuinely narrows the gender gap rather than merely changing the composition of the workforce.

\subsection{Synthetic DiD (Arkhangelsky et al., 2021)}

As an alternative to the Callaway-Sant'Anna estimator, I apply the synthetic difference-in-differences (SDID) estimator of \citet{arkhangelsky2021synthetic} to the Colorado cohort---the earliest adopter with the longest post-treatment window (four years). SDID constructs optimal synthetic control weights that balance pre-treatment outcomes between Colorado and never-treated states, then applies a difference-in-differences estimator to the reweighted data.

The SDID estimate for the Colorado-specific treatment effect is 0.0003 (essentially zero), compared to the C-S aggregate ATT of $-0.0038$ and the traditional DiD estimate of $-0.005$. The synthetic control estimate is 0.021. The near-zero SDID estimate provides additional evidence that transparency has minimal impact on aggregate wages, while the discrepancy between SC and SDID highlights the importance of controlling for time-varying common factors (which SDID does through time weights). The SDID approach complements the multi-cohort C-S analysis by offering an alternative estimator that is robust to imperfect parallel trends through the time-weight construction.

\subsection{Excluding New York and Hawaii}

To verify that the newly added treated states (New York and Hawaii, first contributing post-treatment data in income year 2024) do not drive the results, I re-estimate the main specifications excluding both states. The aggregate ATT excluding NY and HI ($-0.0045$, SE $= 0.007$) is very close to the full-sample estimate ($-0.0038$, SE $= 0.0064$). The gender DDD coefficient excluding NY and HI (0.052, SE $= 0.005$) is actually slightly larger than the full-sample estimate (0.040), suggesting that if anything, the inclusion of NY and HI attenuates the gender gap result. This confirms that the results are not driven by the 2024 treatment cohort and provides reassurance that the extended sample strengthens rather than distorts inference.

\end{document}
